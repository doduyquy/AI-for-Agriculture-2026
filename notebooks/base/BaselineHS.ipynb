{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "113e887d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tifffile as tiff\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "HS_DIR = r\"D:\\HocTap\\NCKH_ThayDoNhuTai\\Challenges\\data\\raw\\Kaggle_Prepared\\train\\HS\"\n",
    "\n",
    "TARGET_BANDS = 125\n",
    "TARGET_HW    = (32, 32)     # giữ đúng dataset hiện tại, muốn đổi thì đổi\n",
    "VAL_RATIO    = 0.2\n",
    "SEED         = 42\n",
    "\n",
    "BATCH_SIZE   = 32\n",
    "EPOCHS       = 30\n",
    "LR           = 1e-3\n",
    "WD           = 1e-4\n",
    "\n",
    "NUM_WORKERS  = 0  # debug trước, chạy OK rồi hãy tăng 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98f5ff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HSDataset(Dataset):\n",
    "    def __init__(self, root_dir, target_bands=125, target_hw=(32,32), normalize=\"minmax\"):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.target_bands = target_bands\n",
    "        self.target_hw = target_hw\n",
    "        self.normalize = normalize\n",
    "\n",
    "        tif_files = sorted(list(self.root_dir.rglob(\"*.tif\")) + list(self.root_dir.rglob(\"*.tiff\")))\n",
    "        if len(tif_files) == 0:\n",
    "            raise RuntimeError(f\"No .tif/.tiff found in {root_dir}\")\n",
    "\n",
    "        # ImageFolder-style: HS/class_name/*.tif\n",
    "        class_names = sorted({p.parent.name for p in tif_files})\n",
    "        self.class_to_idx = {c:i for i,c in enumerate(class_names)}\n",
    "\n",
    "        self.samples = [(p, self.class_to_idx[p.parent.name]) for p in tif_files]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    @staticmethod\n",
    "    def _to_chw(arr: np.ndarray) -> np.ndarray:\n",
    "        # chắc chắn đưa về (C,H,W) theo dim lớn nhất là band\n",
    "        if arr.ndim == 2:\n",
    "            return arr[None, :, :]  # (1,H,W)\n",
    "        if arr.ndim != 3:\n",
    "            raise ValueError(f\"Unexpected ndim={arr.ndim}, shape={arr.shape}\")\n",
    "\n",
    "        band_axis = int(np.argmax(arr.shape))      # axis có size lớn nhất (125/126)\n",
    "        arr = np.moveaxis(arr, band_axis, 0)       # đưa band về axis0 -> (C,?,?)\n",
    "        return arr\n",
    "\n",
    "    def _fix_bands(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        c, h, w = x.shape\n",
    "        tb = self.target_bands\n",
    "        if c > tb:\n",
    "            x = x[:tb]  # 126 -> 125\n",
    "        elif c < tb:\n",
    "            pad = torch.zeros((tb - c, h, w), dtype=x.dtype)\n",
    "            x = torch.cat([x, pad], dim=0)\n",
    "        return x\n",
    "\n",
    "    def _resize(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        th, tw = self.target_hw\n",
    "        if x.shape[1:] == (th, tw):\n",
    "            return x\n",
    "        x = x.unsqueeze(0)  # (1,C,H,W)\n",
    "        x = F.interpolate(x, size=(th, tw), mode=\"bilinear\", align_corners=False)\n",
    "        return x.squeeze(0)\n",
    "\n",
    "    def _normalize(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.normalize is None:\n",
    "            return x\n",
    "        if self.normalize == \"minmax\":\n",
    "            mn = x.amin(dim=(1,2), keepdim=True)\n",
    "            mx = x.amax(dim=(1,2), keepdim=True)\n",
    "            return (x - mn) / (mx - mn + 1e-6)\n",
    "        if self.normalize == \"zscore\":\n",
    "            mean = x.mean(dim=(1,2), keepdim=True)\n",
    "            std  = x.std(dim=(1,2), keepdim=True)\n",
    "            return (x - mean) / (std + 1e-6)\n",
    "        raise ValueError(\"normalize must be: 'minmax', 'zscore', or None\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, y = self.samples[idx]\n",
    "        arr = tiff.imread(str(path))\n",
    "        arr = self._to_chw(arr).astype(np.float32)  # (C,H,W)\n",
    "\n",
    "        x = torch.from_numpy(arr)\n",
    "        x = self._fix_bands(x)      # <<< ép 125\n",
    "        x = self._resize(x)\n",
    "        x = self._normalize(x)\n",
    "\n",
    "        return x, torch.tensor(y, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0051412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: {'HS': 0}\n",
      "Train size: 480 Val size: 120\n",
      "Train bands sample: Counter({125: 200})\n",
      "Val   bands sample: Counter({125: 120})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\.conda\\envs\\ocr311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  super().__init__(loader)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: torch.Size([32, 125, 32, 32]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "full_ds = HSDataset(\n",
    "    HS_DIR,\n",
    "    target_bands=TARGET_BANDS,\n",
    "    target_hw=TARGET_HW,\n",
    "    normalize=\"minmax\"\n",
    ")\n",
    "\n",
    "indices = np.arange(len(full_ds))\n",
    "labels  = np.array([full_ds.samples[i][1] for i in indices])\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    indices,\n",
    "    test_size=VAL_RATIO,\n",
    "    random_state=SEED,\n",
    "    stratify=labels\n",
    ")\n",
    "\n",
    "train_ds = Subset(full_ds, train_idx.tolist())\n",
    "val_ds   = Subset(full_ds, val_idx.tolist())\n",
    "\n",
    "print(\"Classes:\", full_ds.class_to_idx)\n",
    "print(\"Train size:\", len(train_ds), \"Val size:\", len(val_ds))\n",
    "\n",
    "# sanity: check bands (lấy sample 200)\n",
    "from collections import Counter\n",
    "def check_bands(ds, n=200):\n",
    "    cnt = Counter()\n",
    "    for i in range(min(len(ds), n)):\n",
    "        x, _ = ds[i]\n",
    "        cnt[int(x.shape[0])] += 1\n",
    "    return cnt\n",
    "\n",
    "print(\"Train bands sample:\", check_bands(train_ds))\n",
    "print(\"Val   bands sample:\", check_bands(val_ds))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "xb, yb = next(iter(train_loader))\n",
    "print(\"Batch:\", xb.shape, yb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ca7c7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "num_classes = len(full_ds.class_to_idx)\n",
    "\n",
    "model = models.resnet18(weights=None)\n",
    "model.conv1 = nn.Conv2d(TARGET_BANDS, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc7c1ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">HS_resnet18_b125_32x32_split20</strong> at: <a href='https://wandb.ai/phucga15062005/Challenges-HS/runs/l8ewp9fm' target=\"_blank\">https://wandb.ai/phucga15062005/Challenges-HS/runs/l8ewp9fm</a><br> View project at: <a href='https://wandb.ai/phucga15062005/Challenges-HS' target=\"_blank\">https://wandb.ai/phucga15062005/Challenges-HS</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20260127_161700-l8ewp9fm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\HocTap\\NCKH_ThayDoNhuTai\\Challenges\\Notebooks\\00_baseline\\wandb\\run-20260127_161816-ekxl9cmy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/phucga15062005/beyond-visible-spectrum/runs/ekxl9cmy' target=\"_blank\">baseline_hs125_resnet18</a></strong> to <a href='https://wandb.ai/phucga15062005/beyond-visible-spectrum' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/phucga15062005/beyond-visible-spectrum' target=\"_blank\">https://wandb.ai/phucga15062005/beyond-visible-spectrum</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/phucga15062005/beyond-visible-spectrum/runs/ekxl9cmy' target=\"_blank\">https://wandb.ai/phucga15062005/beyond-visible-spectrum/runs/ekxl9cmy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_acc=1.000 val_acc=1.000\n",
      "Epoch 02 | train_acc=1.000 val_acc=1.000\n",
      "Epoch 03 | train_acc=1.000 val_acc=1.000\n",
      "Epoch 04 | train_acc=1.000 val_acc=1.000\n",
      "Epoch 05 | train_acc=1.000 val_acc=1.000\n",
      "Epoch 06 | train_acc=1.000 val_acc=1.000\n",
      "Epoch 07 | train_acc=1.000 val_acc=1.000\n",
      "Epoch 08 | train_acc=1.000 val_acc=1.000\n",
      "Epoch 09 | train_acc=1.000 val_acc=1.000\n",
      "Epoch 10 | train_acc=1.000 val_acc=1.000\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>▁</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_acc</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>1</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>1</td></tr><tr><td>train_loss</td><td>0</td></tr><tr><td>val_acc</td><td>1</td></tr><tr><td>val_loss</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">baseline_hs125_resnet18</strong> at: <a href='https://wandb.ai/phucga15062005/beyond-visible-spectrum/runs/ekxl9cmy' target=\"_blank\">https://wandb.ai/phucga15062005/beyond-visible-spectrum/runs/ekxl9cmy</a><br> View project at: <a href='https://wandb.ai/phucga15062005/beyond-visible-spectrum' target=\"_blank\">https://wandb.ai/phucga15062005/beyond-visible-spectrum</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20260127_161816-ekxl9cmy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val_acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "in_channels = 125\n",
    "RUN_NAME = \"baseline_hs125_resnet18\"\n",
    "CKPT_PATH = r\"D:\\HocTap\\NCKH_ThayDoNhuTai\\Challenges\\checkpoints\\best_hs125_resnet18.pth\"\n",
    "\n",
    "wandb.init(\n",
    "    project=\"beyond-visible-spectrum\",\n",
    "    name=RUN_NAME,\n",
    "    config={\"epochs\": 10, \"batch_size\": 32, \"lr\": 1e-4, \"in_channels\": in_channels, \"wd\": 1e-4}\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=wandb.config.lr, weight_decay=wandb.config.wd)\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    model.train(train)\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += x.size(0)\n",
    "\n",
    "    return total_loss/total, correct/total\n",
    "\n",
    "best_val_acc = -1.0\n",
    "\n",
    "for epoch in range(1, wandb.config.epochs + 1):\n",
    "    tr_loss, tr_acc = run_epoch(train_loader, train=True)\n",
    "    va_loss, va_acc = run_epoch(val_loader,   train=False)\n",
    "\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch,\n",
    "        \"train_loss\": tr_loss, \"train_acc\": tr_acc,\n",
    "        \"val_loss\": va_loss,   \"val_acc\": va_acc\n",
    "    })\n",
    "\n",
    "    if va_acc > best_val_acc:\n",
    "        best_val_acc = va_acc\n",
    "        torch.save(model.state_dict(), CKPT_PATH)\n",
    "        wandb.log({\"best_val_acc\": best_val_acc})\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | train_acc={tr_acc:.3f} val_acc={va_acc:.3f}\")\n",
    "\n",
    "wandb.finish()\n",
    "print(\"Best val_acc:\", best_val_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ocr311)",
   "language": "python",
   "name": "ocr311"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
