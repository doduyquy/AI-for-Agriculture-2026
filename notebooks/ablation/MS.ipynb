{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "685c6190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS_DIR exists: True | n_files: 600\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import tifffile as tiff\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "SEED = 42\n",
    "seed_everything(SEED)\n",
    "\n",
    "MS_DIR = r\"D:\\HocTap\\NCKH_ThayDoNhuTai\\Challenges\\data\\raw\\Kaggle_Prepared\\train\\MS\"  # ✅ sửa nếu khác\n",
    "print(\"MS_DIR exists:\", os.path.isdir(MS_DIR), \"| n_files:\", len(os.listdir(MS_DIR)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4791d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_from_filename(fname: str) -> str:\n",
    "    return os.path.basename(fname).split(\"_\")[0]\n",
    "\n",
    "class MSFilenameDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None, exts=(\".tif\",\".tiff\"), band_idx=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.band_idx = band_idx\n",
    "\n",
    "        self.files = sorted([f for f in os.listdir(img_dir) if f.lower().endswith(exts)])\n",
    "        if len(self.files) == 0:\n",
    "            raise RuntimeError(f\"No tif/tiff found in {img_dir}\")\n",
    "\n",
    "        labels = sorted({label_from_filename(f) for f in self.files})\n",
    "        self.class_to_idx = {c:i for i,c in enumerate(labels)}\n",
    "        self.y = [self.class_to_idx[label_from_filename(f)] for f in self.files]\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.files[idx]\n",
    "        y = self.y[idx]\n",
    "        path = os.path.join(self.img_dir, fname)\n",
    "\n",
    "        arr = tiff.imread(path)  # (H,W,C) hoặc (C,H,W)\n",
    "\n",
    "        # đưa về (H,W,C)\n",
    "        if arr.ndim == 2:\n",
    "            arr = arr[..., None]\n",
    "        elif arr.ndim == 3 and arr.shape[0] == 5 and arr.shape[-1] != 5:\n",
    "            arr = np.transpose(arr, (1,2,0))\n",
    "\n",
    "        arr = arr.astype(np.float32)\n",
    "\n",
    "        # scale về [0,1] theo ảnh\n",
    "        mx = arr.max()\n",
    "        if mx > 0:\n",
    "            arr = arr / mx\n",
    "\n",
    "        x = torch.from_numpy(arr).permute(2,0,1)  # C,H,W (C=5)\n",
    "\n",
    "        # ablation: chọn bands\n",
    "        if self.band_idx is not None:\n",
    "            x = x[self.band_idx, :, :]\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a1c1498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([5, 64, 64]) y: 0\n",
      "per-channel mean: tensor([0.1485, 0.2388, 0.2814, 0.5638, 0.6811])\n",
      "per-channel std : tensor([0.0401, 0.0478, 0.0843, 0.0770, 0.1029])\n",
      "num classes: 3 {'Health': 0, 'Other': 1, 'Rust': 2}\n"
     ]
    }
   ],
   "source": [
    "ds_full = MSFilenameDataset(MS_DIR, band_idx=[0,1,2,3,4])\n",
    "x0, y0 = ds_full[0]\n",
    "print(\"x shape:\", x0.shape, \"y:\", y0)\n",
    "print(\"per-channel mean:\", x0.mean(dim=(1,2)))\n",
    "print(\"per-channel std :\", x0.std(dim=(1,2)))\n",
    "print(\"num classes:\", len(ds_full.class_to_idx), ds_full.class_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ccf0e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 480 | val size: 120\n"
     ]
    }
   ],
   "source": [
    "VAL_RATIO = 0.2\n",
    "\n",
    "idx_all = np.arange(len(ds_full))\n",
    "train_idx, val_idx = train_test_split(\n",
    "    idx_all,\n",
    "    test_size=VAL_RATIO,\n",
    "    random_state=SEED,\n",
    "    stratify=ds_full.y\n",
    ")\n",
    "\n",
    "print(\"train size:\", len(train_idx), \"| val size:\", len(val_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b95d3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loaders_for_case(img_dir, band_idx, train_idx, val_idx, bs=32, num_workers=0, transform=None):\n",
    "    ds = MSFilenameDataset(img_dir, transform=transform, band_idx=band_idx)\n",
    "    train_ds = Subset(ds, train_idx)\n",
    "    val_ds   = Subset(ds, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=bs, shuffle=True, num_workers=num_workers)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=bs, shuffle=False, num_workers=num_workers)\n",
    "    return train_loader, val_loader, ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5001fe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "\n",
    "def build_resnet18(in_channels: int, num_classes: int):\n",
    "    model = resnet18(weights=None)\n",
    "    model.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5e4d727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "\n",
    "    total_loss, total_correct, total = 0.0, 0, 0\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = torch.as_tensor(y, device=device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = ce(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        total_correct += (logits.argmax(1) == y).sum().item()\n",
    "        total += x.size(0)\n",
    "\n",
    "    return total_loss / total, total_correct / total\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_acc(model, loader, device):\n",
    "    model.eval()\n",
    "    total_correct, total = 0, 0\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = torch.as_tensor(y, device=device)\n",
    "        logits = model(x)\n",
    "        total_correct += (logits.argmax(1) == y).sum().item()\n",
    "        total += x.size(0)\n",
    "    return total_correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "971510ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_case(exp_name, band_idx, img_dir, train_idx, val_idx, num_classes,\n",
    "             epochs=10, bs=32, lr=1e-4, num_workers=0, transform=None):\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    train_loader, val_loader, ds = make_loaders_for_case(\n",
    "        img_dir, band_idx, train_idx, val_idx, bs=bs, num_workers=num_workers, transform=transform\n",
    "    )\n",
    "\n",
    "    model = build_resnet18(in_channels=len(band_idx), num_classes=num_classes).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "    best_path = f\"checkpoints/best_{exp_name}_resnet18.pth\"\n",
    "    best_acc = -1.0\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        tr_loss, tr_acc = train_one_epoch(model, train_loader, optimizer, device)\n",
    "        va_acc = evaluate_acc(model, val_loader, device)\n",
    "\n",
    "        print(f\"[{exp_name}] ep {ep}/{epochs} | train_acc={tr_acc:.4f} loss={tr_loss:.4f} | val_acc={va_acc:.4f}\")\n",
    "\n",
    "        if va_acc > best_acc:\n",
    "            best_acc = va_acc\n",
    "            torch.save({\n",
    "                \"model\": model.state_dict(),\n",
    "                \"band_idx\": band_idx,\n",
    "                \"best_acc\": best_acc,\n",
    "                \"exp\": exp_name,\n",
    "                \"class_to_idx\": ds.class_to_idx,\n",
    "                \"seed\": SEED\n",
    "            }, best_path)\n",
    "\n",
    "    print(f\"[{exp_name}] BEST val_acc={best_acc:.4f} saved -> {best_path}\")\n",
    "    return best_acc, best_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fed2e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_CLASSES: 3\n"
     ]
    }
   ],
   "source": [
    "ABL = {\n",
    "    \"MS_noNIR\": [0,1,2,3],  # bỏ band 4 (giả sử band4 là NIR)\n",
    "    \"drop_0\":   [1,2,3,4],  # bỏ band 0\n",
    "}\n",
    "\n",
    "NUM_CLASSES = len(ds_full.class_to_idx)  # tự lấy theo folder\n",
    "print(\"NUM_CLASSES:\", NUM_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "019997da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MS_full] ep 1/10 | train_acc=0.5708 loss=0.8968 | val_acc=0.3250\n",
      "[MS_full] ep 2/10 | train_acc=0.8063 loss=0.5725 | val_acc=0.4833\n",
      "[MS_full] ep 3/10 | train_acc=0.8896 loss=0.3504 | val_acc=0.4750\n",
      "[MS_full] ep 4/10 | train_acc=0.9313 loss=0.1963 | val_acc=0.5667\n",
      "[MS_full] ep 5/10 | train_acc=0.9688 loss=0.1085 | val_acc=0.6167\n",
      "[MS_full] ep 6/10 | train_acc=0.9667 loss=0.1084 | val_acc=0.5833\n",
      "[MS_full] ep 7/10 | train_acc=0.9646 loss=0.0862 | val_acc=0.5500\n",
      "[MS_full] ep 8/10 | train_acc=0.9771 loss=0.0875 | val_acc=0.5667\n",
      "[MS_full] ep 9/10 | train_acc=0.9646 loss=0.0683 | val_acc=0.5833\n",
      "[MS_full] ep 10/10 | train_acc=0.9750 loss=0.0592 | val_acc=0.5833\n",
      "[MS_full] BEST val_acc=0.6167 saved -> checkpoints/best_MS_full_resnet18.pth\n",
      "[drop_0] ep 1/10 | train_acc=0.5500 loss=0.9820 | val_acc=0.3000\n",
      "[drop_0] ep 2/10 | train_acc=0.7125 loss=0.6516 | val_acc=0.4583\n",
      "[drop_0] ep 3/10 | train_acc=0.8854 loss=0.3967 | val_acc=0.5083\n",
      "[drop_0] ep 4/10 | train_acc=0.9542 loss=0.1923 | val_acc=0.5500\n",
      "[drop_0] ep 5/10 | train_acc=0.9667 loss=0.1245 | val_acc=0.5417\n",
      "[drop_0] ep 6/10 | train_acc=0.9521 loss=0.1615 | val_acc=0.5083\n",
      "[drop_0] ep 7/10 | train_acc=0.9646 loss=0.1040 | val_acc=0.6000\n",
      "[drop_0] ep 8/10 | train_acc=0.9625 loss=0.0885 | val_acc=0.5833\n",
      "[drop_0] ep 9/10 | train_acc=0.9771 loss=0.0691 | val_acc=0.6083\n",
      "[drop_0] ep 10/10 | train_acc=0.9771 loss=0.0618 | val_acc=0.6083\n",
      "[drop_0] BEST val_acc=0.6083 saved -> checkpoints/best_drop_0_resnet18.pth\n",
      "[drop_1] ep 1/10 | train_acc=0.5479 loss=0.8828 | val_acc=0.3917\n",
      "[drop_1] ep 2/10 | train_acc=0.7854 loss=0.5740 | val_acc=0.4250\n",
      "[drop_1] ep 3/10 | train_acc=0.9062 loss=0.3386 | val_acc=0.4417\n",
      "[drop_1] ep 4/10 | train_acc=0.9437 loss=0.1719 | val_acc=0.4500\n",
      "[drop_1] ep 5/10 | train_acc=0.9688 loss=0.0983 | val_acc=0.5833\n",
      "[drop_1] ep 6/10 | train_acc=0.9667 loss=0.0974 | val_acc=0.5500\n",
      "[drop_1] ep 7/10 | train_acc=0.9729 loss=0.0984 | val_acc=0.5917\n",
      "[drop_1] ep 8/10 | train_acc=0.9750 loss=0.0774 | val_acc=0.5583\n",
      "[drop_1] ep 9/10 | train_acc=0.9750 loss=0.0576 | val_acc=0.5667\n",
      "[drop_1] ep 10/10 | train_acc=0.9833 loss=0.0481 | val_acc=0.5250\n",
      "[drop_1] BEST val_acc=0.5917 saved -> checkpoints/best_drop_1_resnet18.pth\n",
      "[drop_2] ep 1/10 | train_acc=0.5500 loss=0.9338 | val_acc=0.3500\n",
      "[drop_2] ep 2/10 | train_acc=0.7812 loss=0.5736 | val_acc=0.3000\n",
      "[drop_2] ep 3/10 | train_acc=0.9062 loss=0.3373 | val_acc=0.4250\n",
      "[drop_2] ep 4/10 | train_acc=0.9688 loss=0.1620 | val_acc=0.6250\n",
      "[drop_2] ep 5/10 | train_acc=0.9688 loss=0.1179 | val_acc=0.6000\n",
      "[drop_2] ep 6/10 | train_acc=0.9542 loss=0.1341 | val_acc=0.5833\n",
      "[drop_2] ep 7/10 | train_acc=0.9396 loss=0.1579 | val_acc=0.5417\n",
      "[drop_2] ep 8/10 | train_acc=0.9542 loss=0.1382 | val_acc=0.5083\n",
      "[drop_2] ep 9/10 | train_acc=0.9583 loss=0.1022 | val_acc=0.6250\n",
      "[drop_2] ep 10/10 | train_acc=0.9667 loss=0.0741 | val_acc=0.6083\n",
      "[drop_2] BEST val_acc=0.6250 saved -> checkpoints/best_drop_2_resnet18.pth\n",
      "[drop_3] ep 1/10 | train_acc=0.5771 loss=0.8854 | val_acc=0.3417\n",
      "[drop_3] ep 2/10 | train_acc=0.7396 loss=0.5937 | val_acc=0.3000\n",
      "[drop_3] ep 3/10 | train_acc=0.8500 loss=0.4076 | val_acc=0.5250\n",
      "[drop_3] ep 4/10 | train_acc=0.9417 loss=0.2089 | val_acc=0.5667\n",
      "[drop_3] ep 5/10 | train_acc=0.9646 loss=0.1371 | val_acc=0.6250\n",
      "[drop_3] ep 6/10 | train_acc=0.9771 loss=0.0947 | val_acc=0.6333\n",
      "[drop_3] ep 7/10 | train_acc=0.9604 loss=0.1155 | val_acc=0.6000\n",
      "[drop_3] ep 8/10 | train_acc=0.9771 loss=0.1052 | val_acc=0.5750\n",
      "[drop_3] ep 9/10 | train_acc=0.9667 loss=0.1074 | val_acc=0.6333\n",
      "[drop_3] ep 10/10 | train_acc=0.9708 loss=0.0877 | val_acc=0.5833\n",
      "[drop_3] BEST val_acc=0.6333 saved -> checkpoints/best_drop_3_resnet18.pth\n",
      "[drop_4] ep 1/10 | train_acc=0.5271 loss=0.8874 | val_acc=0.3333\n",
      "[drop_4] ep 2/10 | train_acc=0.7292 loss=0.6217 | val_acc=0.3250\n",
      "[drop_4] ep 3/10 | train_acc=0.8521 loss=0.4144 | val_acc=0.3750\n",
      "[drop_4] ep 4/10 | train_acc=0.9229 loss=0.2327 | val_acc=0.5000\n",
      "[drop_4] ep 5/10 | train_acc=0.9229 loss=0.2455 | val_acc=0.5583\n",
      "[drop_4] ep 6/10 | train_acc=0.9542 loss=0.1463 | val_acc=0.6167\n",
      "[drop_4] ep 7/10 | train_acc=0.9396 loss=0.1770 | val_acc=0.5417\n",
      "[drop_4] ep 8/10 | train_acc=0.9563 loss=0.1158 | val_acc=0.5583\n",
      "[drop_4] ep 9/10 | train_acc=0.9708 loss=0.0775 | val_acc=0.6167\n",
      "[drop_4] ep 10/10 | train_acc=0.9563 loss=0.0822 | val_acc=0.6000\n",
      "[drop_4] BEST val_acc=0.6167 saved -> checkpoints/best_drop_4_resnet18.pth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp</th>\n",
       "      <th>bands</th>\n",
       "      <th>n_bands</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>ckpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>drop_3</td>\n",
       "      <td>[0, 1, 2, 4]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>checkpoints/best_drop_3_resnet18.pth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drop_2</td>\n",
       "      <td>[0, 1, 3, 4]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>checkpoints/best_drop_2_resnet18.pth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MS_full</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>checkpoints/best_MS_full_resnet18.pth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>drop_4</td>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>checkpoints/best_drop_4_resnet18.pth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drop_0</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>checkpoints/best_drop_0_resnet18.pth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drop_1</td>\n",
       "      <td>[0, 2, 3, 4]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>checkpoints/best_drop_1_resnet18.pth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       exp            bands  n_bands   val_acc  \\\n",
       "4   drop_3     [0, 1, 2, 4]        4  0.633333   \n",
       "3   drop_2     [0, 1, 3, 4]        4  0.625000   \n",
       "0  MS_full  [0, 1, 2, 3, 4]        5  0.616667   \n",
       "5   drop_4     [0, 1, 2, 3]        4  0.616667   \n",
       "1   drop_0     [1, 2, 3, 4]        4  0.608333   \n",
       "2   drop_1     [0, 2, 3, 4]        4  0.591667   \n",
       "\n",
       "                                    ckpt  \n",
       "4   checkpoints/best_drop_3_resnet18.pth  \n",
       "3   checkpoints/best_drop_2_resnet18.pth  \n",
       "0  checkpoints/best_MS_full_resnet18.pth  \n",
       "5   checkpoints/best_drop_4_resnet18.pth  \n",
       "1   checkpoints/best_drop_0_resnet18.pth  \n",
       "2   checkpoints/best_drop_1_resnet18.pth  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "DROP = {\n",
    "    \"MS_full\": [0,1,2,3,4],\n",
    "    \"drop_0\":  [1,2,3,4],\n",
    "    \"drop_1\":  [0,2,3,4],\n",
    "    \"drop_2\":  [0,1,3,4],\n",
    "    \"drop_3\":  [0,1,2,4],\n",
    "    \"drop_4\":  [0,1,2,3],\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, band_idx in DROP.items():\n",
    "    acc, ckpt = run_case(\n",
    "        exp_name=name,\n",
    "        band_idx=band_idx,\n",
    "        img_dir=MS_DIR,\n",
    "        train_idx=train_idx,\n",
    "        val_idx=val_idx,\n",
    "        num_classes=NUM_CLASSES,\n",
    "        epochs=10,\n",
    "        bs=32,\n",
    "        lr=1e-4,\n",
    "        num_workers=0\n",
    "    )\n",
    "    results.append({\n",
    "        \"exp\": name,\n",
    "        \"bands\": str(band_idx),\n",
    "        \"n_bands\": len(band_idx),\n",
    "        \"val_acc\": acc,\n",
    "        \"ckpt\": ckpt\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results).sort_values(\"val_acc\", ascending=False)\n",
    "df.to_csv(\"checkpoints/ablation_drop_each.csv\", index=False)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2818d7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 480 val size: 120\n",
      "val_idx hash: -5796670799930339884\n"
     ]
    }
   ],
   "source": [
    "print(\"train size:\", len(train_idx), \"val size:\", len(val_idx))\n",
    "print(\"val_idx hash:\", hash(tuple(val_idx[:200])))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ocr311)",
   "language": "python",
   "name": "ocr311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
