{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Late fusion: RGB + MS + HS"
      ],
      "metadata": {
        "id": "ZHxNqJ75yAhf"
      },
      "id": "ZHxNqJ75yAhf"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "cb1d117d",
      "metadata": {
        "id": "cb1d117d"
      },
      "outputs": [],
      "source": [
        "# %% [code]\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from PIL import Image\n",
        "import tifffile as tiff\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to GitHub"
      ],
      "metadata": {
        "id": "iH3hvMh61Nb5"
      },
      "id": "iH3hvMh61Nb5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Clone repo (branch: HongPhuc)"
      ],
      "metadata": {
        "id": "593L3ivg1h4Y"
      },
      "id": "593L3ivg1h4Y"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b HongPhuc https://github.com/doduyquy/AI-for-Agriculture-2026.git\n",
        "\n",
        "# move to AI-for-Agriculture-2026 directory\n",
        "%cd AI-for-Agriculture-2026\n",
        "\n",
        "!git branch # check current branch\n",
        "\n",
        "\n",
        "print(\"[OK] Clone repo successfully\")"
      ],
      "metadata": {
        "id": "aMxU5HwC1Tou",
        "outputId": "7dea8600-a8ac-4ce8-ff12-cda5ee574d80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "aMxU5HwC1Tou",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AI-for-Agriculture-2026'...\n",
            "remote: Enumerating objects: 3045, done.\u001b[K\n",
            "remote: Total 3045 (delta 0), reused 0 (delta 0), pack-reused 3045 (from 2)\u001b[K\n",
            "Receiving objects: 100% (3045/3045), 515.84 MiB | 13.48 MiB/s, done.\n",
            "Resolving deltas: 100% (98/98), done.\n",
            "Updating files: 100% (2912/2912), done.\n",
            "/content/AI-for-Agriculture-2026\n",
            "* \u001b[32mHongPhuc\u001b[m\n",
            "[OK] Clone repo successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Config git user"
      ],
      "metadata": {
        "id": "uxyge_qY1jfC"
      },
      "id": "uxyge_qY1jfC"
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name \"doduyquy\"\n",
        "!git config --global user.email \"doduyquy211@gmail.com\""
      ],
      "metadata": {
        "id": "bWI8JfbB1kxz"
      },
      "id": "bWI8JfbB1kxz",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***!!! WARNING !!!***"
      ],
      "metadata": {
        "id": "I-lqInUZ1jcP"
      },
      "id": "I-lqInUZ1jcP"
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GITHUB_TOKEN\"] = \"\""
      ],
      "metadata": {
        "id": "j6R-Dc9d1p7D"
      },
      "id": "j6R-Dc9d1p7D",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config"
      ],
      "metadata": {
        "id": "IjE9JvsB1u8n"
      },
      "id": "IjE9JvsB1u8n"
    },
    {
      "cell_type": "code",
      "source": [
        "# print working dir\n",
        "!pwd"
      ],
      "metadata": {
        "id": "rO7OyeSI15cm",
        "outputId": "fff5eb02-c789-430c-f62f-6daf843835e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "rO7OyeSI15cm",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AI-for-Agriculture-2026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "current_challenge_dir= Path.cwd()\n",
        "notebooks_dir = current_challenge_dir.resolve() / \"notebooks\"\n",
        "checkpoint_dir = current_challenge_dir / 'checkpoints'\n",
        "\n",
        "ROOT_DATASET_TRAIN = current_challenge_dir.resolve() / 'data' / 'raw' / 'train'\n",
        "RGB_DIR = ROOT_DATASET_TRAIN / \"RGB\"\n",
        "MS_DIR  = ROOT_DATASET_TRAIN / \"MS\"\n",
        "HS_DIR  = ROOT_DATASET_TRAIN / \"HS\"\n",
        "\n",
        "\n",
        "SPLIT_DIR = notebooks_dir / 'split' / 'splits'\n",
        "VAL_IDX_PATH = SPLIT_DIR / 'val_idx.npy'\n",
        "TRAIN_IDX_FILE = SPLIT_DIR / \"train_idx.npy\"\n",
        "\n",
        "\n",
        "CKPT_069 = checkpoint_dir / '069_kaggle'\n",
        "CKPT_RGB = CKPT_069 / 'best_rgb_resnet18_224.pth'\n",
        "CKPT_MS  = CKPT_069 / 'best_ms_resnet18_224.pth'\n",
        "CKPT_HS  = CKPT_069 / 'best_hs_topK20_resnet18_224.pth'\n",
        "\n",
        "ROOT_DATASET_VAL = current_challenge_dir.resolve() / 'data' / 'raw' / 'val'\n",
        "TEST_RGB_DIR = os.path.join(ROOT_DATASET_VAL, \"RGB\")\n",
        "TEST_MS_DIR  = os.path.join(ROOT_DATASET_VAL, \"MS\")\n",
        "TEST_HS_DIR  = os.path.join(ROOT_DATASET_VAL, \"HS\")\n",
        "\n",
        "OUT_SUB_DIR = notebooks_dir / 'LateFusion'\n",
        "\n",
        "\n",
        "# Check\n",
        "print(f\"Val idx: {VAL_IDX_PATH}\")\n",
        "print(f\"Checkpoint RGB: {CKPT_RGB}\")\n",
        "print(f\"Checkpoint MS: {CKPT_MS}\")\n",
        "print(f\"Checkpoint HS: {CKPT_HS}\")\n",
        "print(f\"Training data RGB: {RGB_DIR}\")\n",
        "print(f\"Testing data MS: {TEST_MS_DIR}\")\n",
        "print(f\"Train split idx file: {TRAIN_IDX_FILE}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "8j2zc9SkyI8h",
        "outputId": "f718e29e-5d09-472e-ba7c-8ec7a34a2d14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8j2zc9SkyI8h",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val idx: /content/AI-for-Agriculture-2026/notebooks/split/splits/val_idx.npy\n",
            "Checkpoint RGB: /content/AI-for-Agriculture-2026/checkpoints/069_kaggle/best_rgb_resnet18_224.pth\n",
            "Checkpoint MS: /content/AI-for-Agriculture-2026/checkpoints/069_kaggle/best_ms_resnet18_224.pth\n",
            "Checkpoint HS: /content/AI-for-Agriculture-2026/checkpoints/069_kaggle/best_hs_topK20_resnet18_224.pth\n",
            "Training data RGB: /content/AI-for-Agriculture-2026/data/raw/train/RGB\n",
            "Testing data MS: /content/AI-for-Agriculture-2026/data/raw/val/MS\n",
            "Train split idx file: /content/AI-for-Agriculture-2026/notebooks/split/splits/train_idx.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get checkpoint file name (without extension)\n",
        "ckpt_rgb_fn = Path(CKPT_RGB).stem\n",
        "ckpt_ms_fn = Path(CKPT_MS).stem\n",
        "ckpt_hs_fn = Path(CKPT_HS).stem\n",
        "\n",
        "submission_fn = f\"submission_latefusion_{ckpt_rgb_fn}_{ckpt_ms_fn}_{ckpt_hs_fn}.csv\"\n",
        "\n",
        "print(f\"Submission file name: {submission_fn}\")"
      ],
      "metadata": {
        "id": "lt7DfjPO7f3J",
        "outputId": "6bb438c8-adff-47c8-c848-dd6d0b9e4cb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "lt7DfjPO7f3J",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file name: submission_latefusion_best_rgb_resnet18_224_best_ms_resnet18_224_best_hs_topK20_resnet18_224.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUT_SUB_PATH = OUT_SUB_DIR / submission_fn\n",
        "print(f\"Submission path: {OUT_SUB_PATH}\")"
      ],
      "metadata": {
        "id": "QlJHFB_X7YMP",
        "outputId": "92993c1d-f510-4ed5-c0ec-70c6eb9ffeaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "QlJHFB_X7YMP",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission path: /content/AI-for-Agriculture-2026/notebooks/LateFusion/submission_latefusion_best_rgb_resnet18_224_best_ms_resnet18_224_best_hs_topK20_resnet18_224.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "cf7e5b55",
      "metadata": {
        "id": "cf7e5b55",
        "outputId": "31785ef3-09c6-4a3e-8ddd-44eabb1dcd05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE: cuda\n"
          ]
        }
      ],
      "source": [
        "# %% [code]\n",
        "# ====== CONFIG ======\n",
        "\n",
        "IMG_SIZE = 224     # phải giống baseline bạn train (nếu baseline dùng 64)\n",
        "BATCH_SIZE = 8\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "CLASSES = [\"Health\", \"Other\", \"Rust\"]\n",
        "CLASS_TO_IDX = {c:i for i,c in enumerate(CLASSES)}\n",
        "IDX_TO_CLASS = {i:c for c,i in CLASS_TO_IDX.items()}\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def seed_everything(seed=1):\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(1)\n",
        "\n",
        "print(\"DEVICE:\", DEVICE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3861b923",
      "metadata": {
        "id": "3861b923"
      },
      "outputs": [],
      "source": [
        "# %% [code]\n",
        "def label_from_filename(fname: str) -> str:\n",
        "    # lấy prefix class theo list CLASSES\n",
        "    for c in CLASSES:\n",
        "        if fname.lower().startswith(c.lower()):\n",
        "            return c\n",
        "    raise ValueError(f\"Cannot parse label from filename: {fname}\")\n",
        "\n",
        "def key_from_filename(fname: str) -> str:\n",
        "    # bỏ extension + normalize\n",
        "    base = os.path.splitext(fname)[0]\n",
        "    return base.strip().lower()\n",
        "\n",
        "def resize_np_chw(x_chw: np.ndarray, out_hw: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    x_chw: (C,H,W) float32\n",
        "    Resize theo từng channel bằng PIL (bilinear) để đơn giản và ổn định.\n",
        "    \"\"\"\n",
        "    C, H, W = x_chw.shape\n",
        "    out = np.empty((C, out_hw, out_hw), dtype=np.float32)\n",
        "    for c in range(C):\n",
        "        img = Image.fromarray(x_chw[c].astype(np.float32), mode=\"F\")\n",
        "        img = img.resize((out_hw, out_hw), resample=Image.BILINEAR)\n",
        "        out[c] = np.array(img, dtype=np.float32)\n",
        "    return out\n",
        "\n",
        "def normalize_chw(x_chw: np.ndarray, mean: np.ndarray, std: np.ndarray) -> np.ndarray:\n",
        "    # mean,std: shape (C,)\n",
        "    return (x_chw - mean[:, None, None]) / (std[:, None, None] + 1e-6)\n",
        "\n",
        "def clip_per_band(x: torch.Tensor, ql=0.01, qh=0.99) -> torch.Tensor:\n",
        "    \"\"\"Clip mỗi band theo quantile q1/q99. Input/output: (C, H, W).\"\"\"\n",
        "    C = x.shape[0]\n",
        "    flat = x.view(C, -1)\n",
        "    lo = torch.quantile(flat, ql, dim=1).view(-1, 1, 1)\n",
        "    hi = torch.quantile(flat, qh, dim=1).view(-1, 1, 1)\n",
        "    return torch.clamp(x, lo, hi)\n",
        "\n",
        "def ensure_chw_hs(arr):\n",
        "    \"\"\"Đảm bảo HS array có shape (C, H, W) với C=125.\"\"\"\n",
        "    if arr.ndim == 2:\n",
        "        return arr[None, :, :]\n",
        "    if arr.ndim == 3:\n",
        "        if arr.shape[0] in (125, 126):\n",
        "            return arr\n",
        "        if arr.shape[-1] in (125, 126):\n",
        "            return np.transpose(arr, (2, 0, 1))\n",
        "        band_axis = np.argmax(arr.shape)\n",
        "        if band_axis == 2:\n",
        "            return np.transpose(arr, (2, 0, 1))\n",
        "    return arr\n",
        "\n",
        "def fix_bands_125(arr):\n",
        "    \"\"\"Đảm bảo đúng 125 bands.\"\"\"\n",
        "    if arr.shape[0] > 125:\n",
        "        arr = arr[:125]\n",
        "    elif arr.shape[0] < 125:\n",
        "        pad = 125 - arr.shape[0]\n",
        "        arr = np.pad(arr, ((0, pad), (0, 0), (0, 0)), mode=\"edge\")\n",
        "    return arr\n",
        "\n",
        "# ====== NORMALIZATION STATS ======\n",
        "RGB_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
        "RGB_STD  = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
        "\n",
        "# MS: global mean/std computed on TRAIN split after dividing by 65535\n",
        "MS_MEAN = np.array([0.00651217, 0.01202489, 0.01260268, 0.03442739, 0.04236133], dtype=np.float32)\n",
        "MS_STD  = np.array([0.00558527, 0.00672570, 0.00985042, 0.01149776, 0.01547735], dtype=np.float32)\n",
        "\n",
        "# ====== HS TopK-20 config ======\n",
        "# Bands từ Hard-Concrete L0 Gate (sorted)\n",
        "HS_SELECTED_BANDS = [7, 32, 43, 48, 50, 58, 72, 84, 92, 97, 98, 99,\n",
        "                     101, 105, 110, 111, 112, 114, 117, 122]\n",
        "HS_IMG_SIZE = 224   # TopK model dùng 64x64\n",
        "\n",
        "# HS global mean/std sẽ được tính ở cell tiếp theo\n",
        "HS_GLOBAL_MEAN = None  # shape (125,) - tính từ train data\n",
        "HS_GLOBAL_STD  = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "114e9e20",
      "metadata": {
        "id": "114e9e20",
        "outputId": "013d0efb-595e-4128-9678-fa69a87476cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RGB files: 600 | MS: 600 | HS: 600\n",
            "Intersection keys (RGB∩MS∩HS): 600\n",
            "Val keys: 116\n",
            "rust_hyper_131 -> Rust\n",
            "other_hyper_85 -> Other\n",
            "health_hyper_62 -> Health\n",
            "other_hyper_137 -> Other\n",
            "rust_hyper_74 -> Rust\n"
          ]
        }
      ],
      "source": [
        "# %% [code]\n",
        "def list_files(dir_path, exts):\n",
        "    return sorted([f for f in os.listdir(dir_path) if f.lower().endswith(exts)])\n",
        "\n",
        "rgb_files = list_files(RGB_DIR, (\".png\", \".jpg\", \".jpeg\"))\n",
        "ms_files  = list_files(MS_DIR,  (\".tif\", \".tiff\"))\n",
        "hs_files  = list_files(HS_DIR,  (\".tif\", \".tiff\"))\n",
        "\n",
        "rgb_map = {key_from_filename(f): f for f in rgb_files}\n",
        "ms_map  = {key_from_filename(f): f for f in ms_files}\n",
        "hs_map  = {key_from_filename(f): f for f in hs_files}\n",
        "\n",
        "# lấy intersection keys có đủ 3 modality\n",
        "all_keys = sorted(set(rgb_map.keys()) & set(ms_map.keys()) & set(hs_map.keys()))\n",
        "print(\"RGB files:\", len(rgb_files), \"| MS:\", len(ms_files), \"| HS:\", len(hs_files))\n",
        "print(\"Intersection keys (RGB∩MS∩HS):\", len(all_keys))\n",
        "\n",
        "# ---- Load val_idx.npy ----\n",
        "val_idx = np.load(VAL_IDX_PATH)\n",
        "val_idx = np.array(val_idx, dtype=int)\n",
        "\n",
        "# CỰC QUAN TRỌNG:\n",
        "# val_idx này phải được tạo dựa trên một list \"chuẩn\" tương thích với all_keys.\n",
        "# Ở đây mình assume val_idx được tạo từ list HS đã sorted theo filename và sau đó key cũng theo sorted.\n",
        "# Nếu split của bạn trước đây dựa trên HS sorted list -> cách này sẽ match tốt khi all_keys cũng được sorted theo key giống HS.\n",
        "#\n",
        "# Nếu bạn muốn chắc chắn tuyệt đối: hãy dùng HS sorted list làm chuẩn split và map sang all_keys theo key.\n",
        "# Ở đây, để chạy ngay, ta sẽ áp val_idx trực tiếp lên all_keys (phổ biến khi bạn đã làm split chung).\n",
        "val_keys = [all_keys[i] for i in val_idx if 0 <= i < len(all_keys)]\n",
        "print(\"Val keys:\", len(val_keys))\n",
        "\n",
        "# sanity check xem label parse ổn\n",
        "for k in val_keys[:5]:\n",
        "    print(k, \"->\", label_from_filename(rgb_map[k]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "19e9bf1c",
      "metadata": {
        "id": "19e9bf1c",
        "outputId": "44a10e3b-3d69-4308-f726-9d30444e8da5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing HS global stats on 461 train samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "HS stats:   0%|          | 0/461 [00:00<?, ?it/s]/tmp/ipython-input-1033403914.py:22: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  img = Image.fromarray(x_chw[c].astype(np.float32), mode=\"F\")\n",
            "HS stats: 100%|██████████| 461/461 [00:36<00:00, 12.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HS Global Mean[0:5]: [274.3455  332.6265  360.58398 378.07227 391.33524]\n",
            "HS Global Std [0:5]: [339.35507 356.85617 362.94418 366.08926 372.1717 ]\n",
            "HS Global Mean shape: (125,)\n",
            "\n",
            "TopK-20 Mean: [ 418.35373  801.88074  822.2426   824.4453   821.0045   864.8435\n",
            " 2158.5493  2650.9592  2661.891   2651.898   2650.8445  2649.2334\n",
            " 2646.5251  2629.0483  2583.6165  2569.705   2554.261   2513.4543\n",
            " 2420.1072  2168.3499 ]\n",
            "TopK-20 Std:  [ 382.75912  558.85504  637.6406   665.5828   675.47906  703.4112\n",
            "  836.3498  1097.4891  1100.9491  1098.0469  1097.3914  1097.047\n",
            " 1096.5469  1089.5834  1074.8004  1070.0128  1064.4393  1050.5374\n",
            " 1016.6683   916.6341 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ====== Tính HS global mean/std trên TRAIN split (giống baseline TopK) ======\n",
        "# Pipeline: load → CHW → fix 125 bands → resize 64×64 → clip per-band (q1%-q99%) → accumulate stats\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "\n",
        "# Lấy train files (tất cả trừ val)\n",
        "train_idx = np.load(TRAIN_IDX_FILE)\n",
        "train_idx = np.array(train_idx, dtype=int)\n",
        "train_keys = [all_keys[i] for i in train_idx if 0 <= i < len(all_keys)]\n",
        "\n",
        "print(f\"Computing HS global stats on {len(train_keys)} train samples...\")\n",
        "\n",
        "n_bands = 125\n",
        "pixel_count = 0\n",
        "band_sum = np.zeros(n_bands, dtype=np.float64)\n",
        "band_sum_sq = np.zeros(n_bands, dtype=np.float64)\n",
        "\n",
        "for k in tqdm(train_keys, desc=\"HS stats\"):\n",
        "    path = os.path.join(HS_DIR, hs_map[k])\n",
        "    arr = tiff.imread(path).astype(np.float32)\n",
        "    arr = ensure_chw_hs(arr)\n",
        "    arr = fix_bands_125(arr)\n",
        "    arr = resize_np_chw(arr, HS_IMG_SIZE)  # (125, 64, 64)\n",
        "\n",
        "    # clip per-band (quantile 1%-99%) giống baseline\n",
        "    x = torch.from_numpy(arr)\n",
        "    x = clip_per_band(x, ql=0.01, qh=0.99)\n",
        "    arr = x.numpy()\n",
        "\n",
        "    # accumulate per-band stats\n",
        "    for b in range(n_bands):\n",
        "        band_pixels = arr[b].ravel()\n",
        "        band_sum[b] += band_pixels.sum()\n",
        "        band_sum_sq[b] += (band_pixels ** 2).sum()\n",
        "    pixel_count += arr.shape[1] * arr.shape[2]\n",
        "\n",
        "HS_GLOBAL_MEAN = (band_sum / pixel_count).astype(np.float32)\n",
        "HS_GLOBAL_STD  = np.sqrt(band_sum_sq / pixel_count - (band_sum / pixel_count) ** 2).astype(np.float32)\n",
        "\n",
        "print(f\"HS Global Mean[0:5]: {HS_GLOBAL_MEAN[:5]}\")\n",
        "print(f\"HS Global Std [0:5]: {HS_GLOBAL_STD[:5]}\")\n",
        "print(f\"HS Global Mean shape: {HS_GLOBAL_MEAN.shape}\")\n",
        "\n",
        "# Subset cho 20 selected bands\n",
        "HS_TOPK_MEAN = HS_GLOBAL_MEAN[HS_SELECTED_BANDS]\n",
        "HS_TOPK_STD  = HS_GLOBAL_STD[HS_SELECTED_BANDS]\n",
        "print(f\"\\nTopK-20 Mean: {HS_TOPK_MEAN}\")\n",
        "print(f\"TopK-20 Std:  {HS_TOPK_STD}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "ce85fad2",
      "metadata": {
        "id": "ce85fad2",
        "outputId": "1833eaac-cdff-4061-cdfb-9f9784590981",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val dataset: 116\n"
          ]
        }
      ],
      "source": [
        "# %% [code]\n",
        "class FusionDataset(Dataset):\n",
        "    def __init__(self, keys, rgb_dir, ms_dir, hs_dir, rgb_map, ms_map, hs_map,\n",
        "                 img_size=IMG_SIZE, hs_img_size=IMG_SIZE,\n",
        "                 ms_mean=None, ms_std=None,\n",
        "                 hs_global_mean=None, hs_global_std=None,\n",
        "                 hs_selected_bands=None):\n",
        "        self.keys = keys\n",
        "        self.rgb_dir = rgb_dir\n",
        "        self.ms_dir = ms_dir\n",
        "        self.hs_dir = hs_dir\n",
        "        self.rgb_map = rgb_map\n",
        "        self.ms_map = ms_map\n",
        "        self.hs_map = hs_map\n",
        "        self.img_size = img_size\n",
        "        self.hs_img_size = hs_img_size\n",
        "\n",
        "        self.ms_mean = ms_mean\n",
        "        self.ms_std = ms_std\n",
        "        self.hs_global_mean = hs_global_mean  # shape (125,)\n",
        "        self.hs_global_std = hs_global_std    # shape (125,)\n",
        "        self.hs_selected_bands = hs_selected_bands  # list of 20 indices\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.keys)\n",
        "\n",
        "    def load_rgb(self, path):\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        img = img.resize((self.img_size, self.img_size), resample=Image.BILINEAR)\n",
        "        arr = np.array(img, dtype=np.float32) / 255.0  # HWC 0..1\n",
        "        x = arr.transpose(2,0,1)  # CHW\n",
        "        x = normalize_chw(x, RGB_MEAN, RGB_STD)\n",
        "        return x\n",
        "\n",
        "    def load_ms(self, path):\n",
        "        arr = tiff.imread(path)\n",
        "        if arr.ndim == 2:\n",
        "            arr = arr[None, :, :]\n",
        "        elif arr.ndim == 3:\n",
        "            if arr.shape[0] != 5 and arr.shape[-1] == 5:\n",
        "                arr = np.transpose(arr, (2,0,1))\n",
        "        else:\n",
        "            raise ValueError(f\"MS tif shape not supported: {arr.shape} | {path}\")\n",
        "        arr = arr.astype(np.float32)\n",
        "        arr = arr / 65535.0\n",
        "        arr = resize_np_chw(arr, self.img_size)\n",
        "        if self.ms_mean is not None and self.ms_std is not None:\n",
        "            arr = normalize_chw(arr, self.ms_mean, self.ms_std)\n",
        "        return arr\n",
        "\n",
        "    def load_hs(self, path):\n",
        "        \"\"\"Load HS theo pipeline TopK: 125 bands → resize → clip → Z-score → select 20 bands.\"\"\"\n",
        "        arr = tiff.imread(path).astype(np.float32)\n",
        "        arr = ensure_chw_hs(arr)\n",
        "        arr = fix_bands_125(arr)\n",
        "\n",
        "        # Resize → 64x64\n",
        "        arr = resize_np_chw(arr, self.hs_img_size)\n",
        "\n",
        "        # Clip per-band (quantile 1%-99%)\n",
        "        x = torch.from_numpy(arr)\n",
        "        x = clip_per_band(x, ql=0.01, qh=0.99)\n",
        "        arr = x.numpy()\n",
        "\n",
        "        # Global Z-score normalize (125 bands)\n",
        "        if self.hs_global_mean is not None and self.hs_global_std is not None:\n",
        "            arr = normalize_chw(arr, self.hs_global_mean, self.hs_global_std)\n",
        "\n",
        "        # Select 20 TopK bands\n",
        "        if self.hs_selected_bands is not None:\n",
        "            arr = arr[self.hs_selected_bands]  # (20, 64, 64)\n",
        "\n",
        "        return arr\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        k = self.keys[idx]\n",
        "\n",
        "        rgb_path = os.path.join(self.rgb_dir, self.rgb_map[k])\n",
        "        ms_path  = os.path.join(self.ms_dir,  self.ms_map[k])\n",
        "        hs_path  = os.path.join(self.hs_dir,  self.hs_map[k])\n",
        "\n",
        "        x_rgb = self.load_rgb(rgb_path)\n",
        "        x_ms  = self.load_ms(ms_path)\n",
        "        x_hs  = self.load_hs(hs_path)\n",
        "\n",
        "        y = CLASS_TO_IDX[label_from_filename(self.rgb_map[k])]\n",
        "\n",
        "        return (\n",
        "            torch.from_numpy(x_rgb).float(),\n",
        "            torch.from_numpy(x_ms).float(),\n",
        "            torch.from_numpy(x_hs).float(),\n",
        "            torch.tensor(y, dtype=torch.long),\n",
        "            k\n",
        "        )\n",
        "\n",
        "val_ds = FusionDataset(\n",
        "    keys=val_keys,\n",
        "    rgb_dir=RGB_DIR, ms_dir=MS_DIR, hs_dir=HS_DIR,\n",
        "    rgb_map=rgb_map, ms_map=ms_map, hs_map=hs_map,\n",
        "    img_size=IMG_SIZE,\n",
        "    hs_img_size=HS_IMG_SIZE,\n",
        "    ms_mean=MS_MEAN, ms_std=MS_STD,\n",
        "    hs_global_mean=HS_GLOBAL_MEAN,\n",
        "    hs_global_std=HS_GLOBAL_STD,\n",
        "    hs_selected_bands=HS_SELECTED_BANDS\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(\"Val dataset:\", len(val_ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "c941fa56",
      "metadata": {
        "id": "c941fa56",
        "outputId": "9fb8818a-1509-448d-b8ee-383512c22506",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RGB ckpt loaded | missing: [] | unexpected: []\n",
            "MS ckpt loaded | missing: [] | unexpected: []\n",
            "HS ckpt loaded | missing: [] | unexpected: []\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(20, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# %% [code]\n",
        "import torchvision\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "def build_resnet18(num_classes=3, in_channels=3, pretrained=False):\n",
        "    \"\"\"\n",
        "    pretrained=False vì checkpoint của bạn là từ baseline đã train rồi.\n",
        "    Nếu bạn muốn init conv1 từ imagenet khi in_channels != 3 thì phải làm thêm logic riêng.\n",
        "    \"\"\"\n",
        "    if pretrained and in_channels == 3:\n",
        "        model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "    else:\n",
        "        model = resnet18(weights=None)\n",
        "\n",
        "    # sửa conv1 nếu in_channels khác 3\n",
        "    if in_channels != 3:\n",
        "        old = model.conv1\n",
        "        model.conv1 = nn.Conv2d(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=old.out_channels,\n",
        "            kernel_size=old.kernel_size,\n",
        "            stride=old.stride,\n",
        "            padding=old.padding,\n",
        "            bias=(old.bias is not None)\n",
        "        )\n",
        "\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "def load_ckpt(model, ckpt_path, device):\n",
        "    ckpt = torch.load(ckpt_path, map_location=device)\n",
        "    # nhiều notebook lưu kiểu {\"model_state\": ...} hoặc lưu thẳng state_dict\n",
        "    if isinstance(ckpt, dict) and \"state_dict\" in ckpt:\n",
        "        state = ckpt[\"state_dict\"]\n",
        "    elif isinstance(ckpt, dict) and \"model_state_dict\" in ckpt:\n",
        "        state = ckpt[\"model_state_dict\"]\n",
        "    elif isinstance(ckpt, dict) and \"model\" in ckpt and isinstance(ckpt[\"model\"], dict):\n",
        "        state = ckpt[\"model\"]\n",
        "    else:\n",
        "        state = ckpt\n",
        "\n",
        "    missing, unexpected = model.load_state_dict(state, strict=True)\n",
        "    return missing, unexpected\n",
        "\n",
        "# build models\n",
        "model_rgb = build_resnet18(num_classes=3, in_channels=3,   pretrained=False).to(DEVICE)\n",
        "model_ms  = build_resnet18(num_classes=3, in_channels=5,   pretrained=False).to(DEVICE)\n",
        "model_hs  = build_resnet18(num_classes=3, in_channels=20,  pretrained=False).to(DEVICE)\n",
        "\n",
        "# load checkpoints\n",
        "miss, unexp = load_ckpt(model_rgb, CKPT_RGB, DEVICE)\n",
        "print(\"RGB ckpt loaded | missing:\", miss, \"| unexpected:\", unexp)\n",
        "\n",
        "miss, unexp = load_ckpt(model_ms, CKPT_MS, DEVICE)\n",
        "print(\"MS ckpt loaded | missing:\", miss, \"| unexpected:\", unexp)\n",
        "\n",
        "miss, unexp = load_ckpt(model_hs, CKPT_HS, DEVICE)\n",
        "print(\"HS ckpt loaded | missing:\", miss, \"| unexpected:\", unexp)\n",
        "\n",
        "model_rgb.eval()\n",
        "model_ms.eval()\n",
        "model_hs.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "147ed663",
      "metadata": {
        "id": "147ed663",
        "outputId": "b40edd0d-0224-4892-a4d3-440b4fabd7e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1033403914.py:22: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  img = Image.fromarray(x_chw[c].astype(np.float32), mode=\"F\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== RGB-only =====\n",
            "Acc     : 0.8707\n",
            "F1-macro: 0.8718\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Health     0.8140    0.8537    0.8333        41\n",
            "       Other     0.9722    0.8750    0.9211        40\n",
            "        Rust     0.8378    0.8857    0.8611        35\n",
            "\n",
            "    accuracy                         0.8707       116\n",
            "   macro avg     0.8747    0.8715    0.8718       116\n",
            "weighted avg     0.8757    0.8707    0.8720       116\n",
            "\n",
            "Confusion matrix:\n",
            " [[35  1  5]\n",
            " [ 4 35  1]\n",
            " [ 4  0 31]]\n",
            "\n",
            "===== MS-only =====\n",
            "Acc     : 0.8534\n",
            "F1-macro: 0.8541\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Health     0.7778    0.8537    0.8140        41\n",
            "       Other     0.9000    0.9000    0.9000        40\n",
            "        Rust     0.9032    0.8000    0.8485        35\n",
            "\n",
            "    accuracy                         0.8534       116\n",
            "   macro avg     0.8603    0.8512    0.8541       116\n",
            "weighted avg     0.8578    0.8534    0.8540       116\n",
            "\n",
            "Confusion matrix:\n",
            " [[35  4  2]\n",
            " [ 3 36  1]\n",
            " [ 7  0 28]]\n",
            "\n",
            "===== HS-only =====\n",
            "Acc     : 0.5690\n",
            "F1-macro: 0.5681\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Health     0.4722    0.4146    0.4416        41\n",
            "       Other     0.7895    0.7500    0.7692        40\n",
            "        Rust     0.4524    0.5429    0.4935        35\n",
            "\n",
            "    accuracy                         0.5690       116\n",
            "   macro avg     0.5714    0.5692    0.5681       116\n",
            "weighted avg     0.5756    0.5690    0.5702       116\n",
            "\n",
            "Confusion matrix:\n",
            " [[17  7 17]\n",
            " [ 4 30  6]\n",
            " [15  1 19]]\n",
            "\n",
            "===== Fusion (Equal Avg 1/3) =====\n",
            "Acc     : 0.8362\n",
            "F1-macro: 0.8376\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Health     0.7857    0.8049    0.7952        41\n",
            "       Other     0.9167    0.8250    0.8684        40\n",
            "        Rust     0.8158    0.8857    0.8493        35\n",
            "\n",
            "    accuracy                         0.8362       116\n",
            "   macro avg     0.8394    0.8385    0.8376       116\n",
            "weighted avg     0.8399    0.8362    0.8368       116\n",
            "\n",
            "Confusion matrix:\n",
            " [[33  3  5]\n",
            " [ 5 33  2]\n",
            " [ 4  0 31]]\n",
            "\n",
            "===== Fusion Weighted (RGB=0.3, MS=0.5, HS=0.2) =====\n",
            "Acc     : 0.8793\n",
            "F1-macro: 0.8818\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Health     0.7872    0.9024    0.8409        41\n",
            "       Other     0.9459    0.8750    0.9091        40\n",
            "        Rust     0.9375    0.8571    0.8955        35\n",
            "\n",
            "    accuracy                         0.8793       116\n",
            "   macro avg     0.8902    0.8782    0.8818       116\n",
            "weighted avg     0.8873    0.8793    0.8809       116\n",
            "\n",
            "Confusion matrix:\n",
            " [[37  2  2]\n",
            " [ 5 35  0]\n",
            " [ 5  0 30]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8793103448275862, 0.8818407960199005)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# %% [code]\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Custom collate fn\n",
        "def fusion_collate_fn(batch):\n",
        "    x_rgb_list, x_ms_list, x_hs_list, y_list, k_list = [], [], [], [], []\n",
        "    for rgb, ms, hs, y, k in batch:\n",
        "        x_rgb_list.append(rgb)\n",
        "        x_ms_list.append(ms)\n",
        "        x_hs_list.append(hs)\n",
        "        y_list.append(y)\n",
        "        k_list.append(k)\n",
        "    return (\n",
        "        torch.stack(x_rgb_list),\n",
        "        torch.stack(x_ms_list),\n",
        "        torch.stack(x_hs_list),\n",
        "        torch.stack(y_list),\n",
        "        k_list\n",
        "    )\n",
        "\n",
        "# Rebuild DataLoader with custom collate\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True,\n",
        "    collate_fn=fusion_collate_fn\n",
        ")\n",
        "\n",
        "# ====== Thu thập logits thô để dùng cho tối ưu trọng số ======\n",
        "@torch.no_grad()\n",
        "def collect_logits(loader, model_rgb, model_ms, model_hs, device):\n",
        "    \"\"\"Thu thập raw logits từ 3 model + ground truth label.\"\"\"\n",
        "    y_true_all = []\n",
        "    logits_rgb_all = []\n",
        "    logits_ms_all  = []\n",
        "    logits_hs_all  = []\n",
        "\n",
        "    model_rgb.eval(); model_ms.eval(); model_hs.eval()\n",
        "\n",
        "    for x_rgb, x_ms, x_hs, y, keys in loader:\n",
        "        x_rgb = x_rgb.to(device, non_blocking=True)\n",
        "        x_ms  = x_ms.to(device, non_blocking=True)\n",
        "        x_hs  = x_hs.to(device, non_blocking=True)\n",
        "\n",
        "        logits_rgb_all.append(model_rgb(x_rgb).cpu())\n",
        "        logits_ms_all.append(model_ms(x_ms).cpu())\n",
        "        logits_hs_all.append(model_hs(x_hs).cpu())\n",
        "        y_true_all.append(y)\n",
        "\n",
        "    return (\n",
        "        torch.cat(y_true_all).numpy(),\n",
        "        torch.cat(logits_rgb_all).numpy(),\n",
        "        torch.cat(logits_ms_all).numpy(),\n",
        "        torch.cat(logits_hs_all).numpy(),\n",
        "    )\n",
        "\n",
        "y_true, logits_rgb_val, logits_ms_val, logits_hs_val = collect_logits(\n",
        "    val_loader, model_rgb, model_ms, model_hs, DEVICE\n",
        ")\n",
        "\n",
        "# ====== Eval từng model đơn lẻ ======\n",
        "def summarize(name, y_true, y_pred):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1m = f1_score(y_true, y_pred, average=\"macro\")\n",
        "    print(f\"\\n===== {name} =====\")\n",
        "    print(f\"Acc     : {acc:.4f}\")\n",
        "    print(f\"F1-macro: {f1m:.4f}\")\n",
        "    print(classification_report(y_true, y_pred, target_names=CLASSES, digits=4))\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(\"Confusion matrix:\\n\", cm)\n",
        "    return acc, f1m\n",
        "\n",
        "p_rgb = np.argmax(logits_rgb_val, axis=1)\n",
        "p_ms  = np.argmax(logits_ms_val,  axis=1)\n",
        "p_hs  = np.argmax(logits_hs_val,  axis=1)\n",
        "\n",
        "summarize(\"RGB-only\", y_true, p_rgb)\n",
        "summarize(\"MS-only\",  y_true, p_ms)\n",
        "summarize(\"HS-only\",  y_true, p_hs)\n",
        "\n",
        "# ====== Fusion equal average (baseline) ======\n",
        "p_fus_avg = np.argmax((logits_rgb_val + logits_ms_val + logits_hs_val) / 3.0, axis=1)\n",
        "summarize(\"Fusion (Equal Avg 1/3)\", y_true, p_fus_avg)\n",
        "\n",
        "# ====== Weighted fusion: w_MS=0.5, w_RGB=0.3, w_HS=0.2 ======\n",
        "W_RGB, W_MS, W_HS = 0.3, 0.5, 0.2\n",
        "logits_weighted = W_RGB * logits_rgb_val + W_MS * logits_ms_val + W_HS * logits_hs_val\n",
        "p_fus_w = np.argmax(logits_weighted, axis=1)\n",
        "summarize(f\"Fusion Weighted (RGB={W_RGB}, MS={W_MS}, HS={W_HS})\", y_true, p_fus_w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "e3a57f32",
      "metadata": {
        "id": "e3a57f32",
        "outputId": "56fd00cd-b1fe-4b65-b510-c45b9dfca609",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid search done! 231 combinations tested.\n",
            "\n",
            "==================================================\n",
            "BEST WEIGHTS: RGB=0.45, MS=0.55, HS=0.0\n",
            "Best F1-macro: 0.9400 | Best Acc: 0.9397\n",
            "==================================================\n",
            "\n",
            "Top 10 weight combinations (by F1-macro):\n",
            "   RGB     MS     HS      Acc   F1-macro\n",
            "  0.45   0.55   0.00   0.9397     0.9400 <-- BEST\n",
            "  0.50   0.45   0.05   0.9397     0.9400\n",
            "  0.50   0.50   0.00   0.9397     0.9400\n",
            "  0.55   0.40   0.05   0.9397     0.9400\n",
            "  0.55   0.45  -0.00   0.9397     0.9400\n",
            "  0.40   0.60   0.00   0.9310     0.9319\n",
            "  0.45   0.50   0.05   0.9310     0.9319\n",
            "  0.60   0.35   0.05   0.9310     0.9313\n",
            "  0.60   0.40   0.00   0.9310     0.9313\n",
            "  0.65   0.35   0.00   0.9310     0.9313\n",
            "\n",
            "===== Fusion BEST (RGB=0.45, MS=0.55, HS=0.0) =====\n",
            "Acc     : 0.9397\n",
            "F1-macro: 0.9400\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Health     0.8889    0.9756    0.9302        41\n",
            "       Other     0.9737    0.9250    0.9487        40\n",
            "        Rust     0.9697    0.9143    0.9412        35\n",
            "\n",
            "    accuracy                         0.9397       116\n",
            "   macro avg     0.9441    0.9383    0.9400       116\n",
            "weighted avg     0.9425    0.9397    0.9399       116\n",
            "\n",
            "Confusion matrix:\n",
            " [[40  1  0]\n",
            " [ 2 37  1]\n",
            " [ 3  0 32]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9396551724137931, 0.9400423258152397)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# %% [code]\n",
        "# ====== GRID SEARCH tìm trọng số tối ưu trên val set ======\n",
        "from itertools import product\n",
        "\n",
        "best_f1 = -1\n",
        "best_acc = -1\n",
        "best_weights = (0.3, 0.5, 0.2)\n",
        "results = []\n",
        "\n",
        "# Grid search với step = 0.05, tổng = 1.0\n",
        "step = 0.05\n",
        "for w_rgb_i in range(0, 21):          # 0.0 -> 1.0\n",
        "    for w_ms_i in range(0, 21 - w_rgb_i):\n",
        "        w_rgb = round(w_rgb_i * step, 2)\n",
        "        w_ms  = round(w_ms_i * step, 2)\n",
        "        w_hs  = round(1.0 - w_rgb - w_ms, 2)\n",
        "        if w_hs < 0:\n",
        "            continue\n",
        "\n",
        "        logits_fus = w_rgb * logits_rgb_val + w_ms * logits_ms_val + w_hs * logits_hs_val\n",
        "        preds = np.argmax(logits_fus, axis=1)\n",
        "        acc = accuracy_score(y_true, preds)\n",
        "        f1m = f1_score(y_true, preds, average=\"macro\")\n",
        "        results.append((w_rgb, w_ms, w_hs, acc, f1m))\n",
        "\n",
        "        if f1m > best_f1 or (f1m == best_f1 and acc > best_acc):\n",
        "            best_f1 = f1m\n",
        "            best_acc = acc\n",
        "            best_weights = (w_rgb, w_ms, w_hs)\n",
        "\n",
        "print(f\"Grid search done! {len(results)} combinations tested.\")\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"BEST WEIGHTS: RGB={best_weights[0]}, MS={best_weights[1]}, HS={best_weights[2]}\")\n",
        "print(f\"Best F1-macro: {best_f1:.4f} | Best Acc: {best_acc:.4f}\")\n",
        "print(f\"{'='*50}\")\n",
        "\n",
        "# Show top 10\n",
        "results_sorted = sorted(results, key=lambda x: (-x[4], -x[3]))\n",
        "print(\"\\nTop 10 weight combinations (by F1-macro):\")\n",
        "print(f\"{'RGB':>6} {'MS':>6} {'HS':>6} {'Acc':>8} {'F1-macro':>10}\")\n",
        "for w_rgb, w_ms, w_hs, acc, f1m in results_sorted[:10]:\n",
        "    marker = \" <-- BEST\" if (w_rgb, w_ms, w_hs) == best_weights else \"\"\n",
        "    print(f\"{w_rgb:>6.2f} {w_ms:>6.2f} {w_hs:>6.2f} {acc:>8.4f} {f1m:>10.4f}{marker}\")\n",
        "\n",
        "# Eval best weights\n",
        "BEST_W_RGB, BEST_W_MS, BEST_W_HS = best_weights\n",
        "logits_best = BEST_W_RGB * logits_rgb_val + BEST_W_MS * logits_ms_val + BEST_W_HS * logits_hs_val\n",
        "p_fus_best = np.argmax(logits_best, axis=1)\n",
        "summarize(f\"Fusion BEST (RGB={BEST_W_RGB}, MS={BEST_W_MS}, HS={BEST_W_HS})\", y_true, p_fus_best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "a8d15314",
      "metadata": {
        "id": "a8d15314",
        "outputId": "13b264e0-9421-4048-dbe1-028e99eb919f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x400 with 3 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABUEAAAGGCAYAAABVOkC/AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAb+9JREFUeJzt3Xd4FPXaxvF7d9NITwgtdAi9BWkqShEsIArHhgooIiio2EFF8RWl2MF68IiABRVUQBEQlaLAQURpSkfpvaQSUnb39/7ByUogQAJJJpl8P9e1l2ZmdvaZSZh755nmMMYYAQAAAAAAAIBNOa0uAAAAAAAAAAAKE01QAAAAAAAAALZGExQAAAAAAACArdEEBQAAAAAAAGBrNEEBAAAAAAAA2BpNUAAAAAAAAAC2RhMUAAAAAAAAgK3RBAUAAAAAAABgazRBAQAAAAAAANgaTVDY1uTJkxUfH291GT6//PKLLr74YqvLuGDnWq9TpkxRr169iq4gAECuatSooZkzZ55xvMfjUdOmTfXnn38WXVFAARg1apSefvppq8sAUEyFhobqjz/+OOP4yMhILVq0qOgKyie77DcC+XXVVVfpxx9/LNTPoAmKQtWhQwcFBgYqNDTU94qJibG6rBz69esnh8OhDRs2FOrnPPHEEzm+sL/99ttq2bKlAgMD1aNHj1zfs2fPHsXExMjj8WjMmDGqVauWwsPDVbFiRfXt21eJiYmFWvP5uO222/Trr79q1apVVpcCAIWiQ4cOcjgcp31Je+WVV+RwOPTwww9bU1g+ffTRR6pTp44aN24s6cRBLpfLpdDQUIWFhSkuLk5jx4497X1//vmnbrnlFpUvX16hoaGqXbu2+vbtm2OHs0aNGipTpoxCQ0MVHh6uli1bauHChedd64gRI1ShQgWFh4erV69eSk1NPeO0F5qX+fn9zp07V61bt1ZERISioqLUqlUrzZkzJ7+LJ0maOXOm6tSpo+DgYF122WXauHHjGaddtGiRHA5Hju9XDzzwQJ4/60wHNPv27Vsslu/DDz/0fW6lSpV099135/gdPvTQQ5owYYL2799/XrUAKBmWLFmirl27Kjo6WuHh4apbt64GDx6s7du3n/V9qampatKkyXl95slZGBoaqkqVKum+++5TRkbGec3vZKduY8/k1P3Gk/epo6Oj1b59e/3222+51t6mTRuFhoaqbNmyat68ucaMGaNjx45JOj07ypUrp9tvv11Hjx49r+XZu3evunbtqpCQEFWrVk3vv/9+nt73559/KiAg4LR9YIfDoeDgYF99zZo1y3Mt27dvl8PhULVq1eT1enOMa9y4sRwOh1avXi1JcrvdGjZsmGrUqOH7HXfr1k0pKSl5/rxsWVlZeuCBBxQVFaXo6GgNHjxYbrf7jNP37dtXAQEBOfJ72bJleR5/Lh06dNC4ceNOG15clv9c0z/99NMaMmRIvuvID5qgKHQvvfSSUlNTfa/Dhw9bXZJPSkqKpk2bpujoaH3wwQeF9jl//vmnNm3apK5du/qGxcbG6plnntGAAQPO+L5Zs2apS5cucrlcuummm7Rq1SolJydr8+bNyszM1OOPP15oNZ8vp9OpXr166d1337W6FAAoNPXq1dOkSZNyDJs0aZLq169vUUX598477+iuu+7KMaxJkyZKTU1VSkqKPvroIz399NNasGCBb/zvv/+uSy+9VHXr1tWqVauUmpqqFStWqF27dpo7d26OeX322WdKTU1VYmKi+vfvr+7duys9PT3fdU6aNEkffPCBFi9erJ07d+rIkSN68MEHzzh9QeRlXn6/f/31l26++WYNGzZMR48e1b59+/Tqq68qLCwsfwsoadOmTerVq5fGjh2ro0eP6oorrlD37t3PuiMRERGR4/vV22+/ne/PPRsrly8tLU0vv/yyDhw4oHXr1mnfvn267777fONDQ0PVpUuXQv3uBsBa2ftBV111lTZu3Kjk5GT99NNPqlWr1hkPqmVlZRXIZ2dnYWpqqn7//XctXbpUr776aoHM+1xy22+U/tmn3r9/v9q0aaMbbrghx/gnnnhCzz77rJ5++mnt27dPR44c0ZQpU7R//35t3brVN93J2bF582YdPnxYTzzxxHnVetttt6lixYo6ePCgvvjiCw0ZMkQ//fTTWd/j9Xo1YMAAtW3bNtfx//3vf331rVmzJt81BQcHa/78+b6ff/31V3k8nhzTvPjii/r++++1cOFC3+ecuj7zauTIkVqyZInWr1+vdevWafHixRo9evRZ33PfffflyO9LLrkkX+MvlJXLf67p27Vrp8TERC1duvS86skLmqCw1Lp163TxxRcrLCxMHTt21NChQ9WhQwdJ/xzNOfnI/8MPP6y+ffv6fu7du7diY2MVHh6uFi1a5Pssk6lTpyokJEQvvfSSPv74Y19wdu/eXc8//3yOaQcNGqR7771XkpSYmKibb75ZkZGRql+/vt566y05HI4zfs4333yjdu3ayeVy+YbdcMMN6tGjx1nPjJ01a5auv/56SVKdOnUUERHhG+d0OrVly5Yzvjc1NVUPPPCAqlWrpvLly+uOO+5QUlKSb/y51t0PP/ygNm3aKDIyUpUqVdKYMWNyjH/hhRdUvnx5VahQ4bSjTZ06ddKsWbPOWBsAlHS33nqr5s6d69uuLl++XJLUpk2bHNOdbVubfTbembanp54xkpiYKIfD4TsD5vvvv1fLli19Z8vdd999On78eJ7q37t3r1atWqX27dufcZpLL71UjRo10u+//+4b9thjj+m2227TyJEjVblyZUlSdHS0+vXrp6FDh+Y6H6fTqTvuuEMpKSnauXNnnuo72cSJE/Xggw+qbt26ioyM1AsvvKDPPvvsjMua37zMTV5+v6tWrVKFChXUo0cPuVwuBQUFqX379rr88svzu4j65JNP1LFjR3Xr1k1BQUEaPny4Dh48qMWLF+d7XgXFyuUbNGiQOnTooKCgIEVHR2vgwIFasmRJjmk6deqkb7755ryWDUDxZozRgw8+qGHDhunhhx9W+fLlJUmVKlXSI4884juAl72/OGnSJMXFxalKlSqScp715vV6NXz4cFWoUEGxsbF655138lVLbGysrr76aq1bt8437Gz7WRkZGerXr59iYmIUERGhxo0ba8WKFXrzzTc1ZcoUvfvuuwoNDVWjRo1y/bzc9htPFhAQoDvvvFO7du3SoUOHJJ04aPXaa6/p888/1/XXX+87WNWwYUO98cYbZzyjMioqSj169MixbHn1119/acmSJRozZoxCQkLUpk0b9erVSxMnTjzr+9588001aNDgrN8/LsRdd92V4yDmpEmTTjvg+8svv6h79+6qWbOmJKl8+fLq16/feR3kmzhxop555hlVqlRJlSpV0tNPP13sD9BZufznmt7hcOiKK64o1HynCQrLuN1uXX/99erUqZOOHDmi0aNHa8KECfmaR6dOnbRhwwYdOXJEt956q2666aZ8ncb9wQcfqFevXrr11lt17NgxX+OuT58++uSTT3zTZWZmatq0abrjjjskSYMHD9axY8e0Y8cOLVy4UB9//PFZP2f16tX5Pjvo2LFjWrJkia655hrfsE8//VTh4eGKiIjQjBkzznqqeL9+/XT06FGtXbtW27Zt8516nu1s627VqlXq3r27hg4dqkOHDmnjxo3q2LGj773r1q1TcHCw9uzZo6lTp2rIkCH666+/fOMbNmyoAwcOaN++fflaZgAoKSIjI3XNNdfos88+k3TiS92pX7Klc+fUubanZ1OmTBm9//77Onr0qJYuXaqFCxfq9ddfz9N7V69ercqVK5/xC68xRj///LP+/PNP1a1bV9KJs/MWL16snj175ukzsrndbk2aNEmVK1dWjRo1JEk7d+5UZGTkGV/dunXzvX/t2rU5Lt2Oj49Xenq6Nm/efMbPzE9e5iYvv98WLVpo7969GjRokL777rtcLyds2rTpWZfzTMvo7++vhg0bau3atWesMTU1VbGxsapSpYp69eqlPXv25GsZz8Xq5TvZTz/9pKZNm+YY1rBhQ1+TA4C9bN68Wdu3b89z3nzzzTf67bfftG3bttPGTZ48WZMnT9ZPP/2krVu36rfffsvX/uKuXbv03Xff5Thz8Wz7WR9++KHWrFmjrVu3KjExUdOnT1fFihX14IMPqlevXr6z/M7UeDzXfuPx48f1wQcfKCYmRlFRUZKkH3/8UbGxsbr00kvzvFySdPjwYU2fPj3Hsr344otn3a5/+umnkk5s1ytVqqQKFSr43hsfH3/W7fqOHTv0xhtv6JVXXjnjNF27dlW5cuXUqVMn/fLLL/laHunEQczvvvtOiYmJSk9P1xdffKE+ffrkmKZt27Z65513NG7cOP3222+nXZWwZMmSs66D7CsTEhIStHv37tO+o+zcuTPHyUen+uijjxQdHa1GjRrptddeO+3y/XONv1BWLX9epy/0fDdAIWrfvr0JCgoyERERvlfnzp2NMcb8/PPPJjw83GRmZvqmHzhwoGnfvr0xxpht27YZSSYhIcE3/qGHHjJ33nnnGT8vMjLSLFmyxBhjzKRJk0yzZs3OOO26deuMJLN69WpjjDG9e/c2Xbt2NcYYk56ebqKiosyyZcuMMcZMnz7d1K5d2xhjjNvtNv7+/mbFihW+eU2bNs2c7Z9T586dzSuvvJLruP/7v/8z3bt3P234jBkzzJVXXpnre3bs2GGeffZZs27dulzHHzx40DidTnP06FHfsM2bNxt/f3/jdrtzfc/J627gwIHmrrvuynW6SZMmmYoVK+YYFhcXZ7788kvfz5mZmUbSGesDgJKsffv2ZuzYseb77783rVu3NmlpaaZs2bJm37595s477zQPPfTQGd97ak6dbXt66rwSEhKMJLNt27Zc5z127FhfxhpjTPXq1c2MGTNynfaTTz4xjRo1yjFs0qRJxul0moiICBMQEGAkmaefftp4vV5jjDG7d+82ksyGDRt875k4caKJiIgwoaGhpnXr1jk+Ozg42DevwMBA8/HHH59xvZyN0+nMkbnGGBMcHGwWL158zveeKy9zk5/f7++//2569+5tKleubJxOp+ncubP566+/8vxZ2a644orTvid07drVvPDCC7lOv2/fPvPHH38Yt9tt9u3bZ2677TbTvHlz4/F48vR5J/+uT375+/sXi+U72Zw5c0x4eLhZu3ZtjuGbN282ksyxY8fyXQ+A4m3JkiVGkjl+/Lhv2HPPPWciIiJMSEiIufnmm40x/+wvrlq1Ksf7Tx52xRVXmJdeesk3bv/+/UaSWbhwYa6fffL2MTw83Egyl156qUlKSjLGnHs/a+LEiaZOnTrmv//972nb5HN9RzAm9/3Gk/epHQ6HqVChgvn5559940eOHGnatGlz2nwiIiJMmTJlzFtvvWWMMWbhwoVGkm+b73A4TP369c2uXbvOWlNuPvroo9O+R0ybNs23z5ybq6++2nz00UfGmNz3gRcsWGDS09NNamqqefXVV01YWJjZsWNHnuo5uXdw++23m3fffddMmTLFXHvttcaYnH8THo/HvP/+++aKK64wISEhJiIiwjzxxBNn3E8+k507dxpJ5tChQ75hBw8eNJLOuE5///13c/DgQeN2u82yZctM1apVzeuvv57n8eeSW/8lIiKiWCx/Xqf/z3/+Y1q1apWvWvKDM0FR6MaMGaPExETf64cffpB04lK82NhY+fv7+6atXr16nufr9Xr19NNPq06dOgoPD1dkZKSSkpLyfM/RDz74QM2aNfNdHnDnnXdq3rx52rNnjwIDA3XLLbfoo48+knTiaEz2EaTDhw8rKytLVatW9c2rWrVqZ/2sqKgoJScn53nZpJyXwp+qWrVq6tat2xnHb9++XV6vVzVr1vQdsWnVqpWcTqf2799/znW3Y8cO1alT54y1nXzET5JCQkJyHFHNXtbso5MAYEedOnXSvn379MILL+iSSy5RxYoVc4zPS06da3t6NitWrFDnzp19DwwaNmxYnjPwTLnUpEkTJSYmKiUlRcOHD9eCBQt8ZwhERUXJ6XRq7969vunvuusuJSYm6q233jrtoRFTpkzxnYmxbNkyDRkyRN99912e6jtZaGhojjME3G630tLS8nTZ1rny8mzO9fuVpIsuukgff/yxdu/erc2bN8sYo969e+f7s05dRklKSko64zJWrFhRjRs3lsvlUsWKFfWf//xHa9asOevZsafK/l2f/Lr99tuLxfJlW7BggXr37q3p06ef9pCT5ORkBQQEKDg4ON/1ACjesm8XdnLe/N///Z8SExP1+OOPKzMzM8f0Z9sX27t3b459zAoVKigwMPCsn5+9fUxKSlJKSopat27tuzrvXPtZffr0Ud++fTVw4EDFxMSob9+++XomxpnyOXufeteuXapcuXKOMy5jYmJyrCvpxK3NEhMT1bp16xxn+kVERPi2+cePH9fdd9+tdu3a5fue3fndrn/yySdyu92nnZV5so4dOyowMFAhISF67LHHVL9+/fN6GF/2JfG5XQovnbhNTv/+/TV//nwlJibq008/1fjx4/N9GXtoaKgk5VgP2f9/pvVw0UUXqVy5cnK5XLr44ov15JNPaurUqXkenxen9l9OfTikVcuf1+mTk5MLtY9AExSWiY2N1d69e3PcwPrke4Vl/yNJS0vzDTv58upPP/1Un376qWbPnq2kpCQlJiYqIiJCxphzfnZWVpY+/vhjbd68WRUrVlTFihXVq1cveTweTZ48WdKJS+KnTp2q/fv3a+7cub4NdkxMjPz9/bVr165c685NfHz8WZ+Ceiqv16vZs2efdactKytL27dvz/UG4FWrVvXtqJ688UtPT1flypXPue6qV6+e4wba+bV+/XpVqFBBlSpVOu95AEBx53Q6deedd+rFF1/M9Uv2heSUdCIHz5SB0okHEnTs2FF///23kpOTNXr06DzPOz4+Xnv27DnjU9YDAgI0YsQIHT9+3Pegu+DgYLVt21bTpk3L02dkczgcat68udq2bavZs2dLOpGbJz/59NRXly5dfO9v2rRpjsuiVq9ercDAQN9l+udytrw8m3P9fk9Vu3ZtPfTQQ/rjjz98wxo1anTW5cx26jJmZWVp/fr1eX668dnuS15Qinr5FixYoJtuukmffvqpOnXqdNr49evX5/qEewAlX926dVW9evU8543Teea2RmxsrHbs2OH7+eDBg/l60ntoaKjuvvtuLVu2TEeOHDnnfpafn5+GDRumNWvWaMOGDdq5c6dGjBhxzjqznWu/sXLlynr//ff1xBNP+BqfnTp10p49e/J9+XhgYKAGDhyobdu2+S7PHz169Fm361OmTJF0Yru+d+9eHTx40De/1atXn3G7/uOPP2r58uWKiYlRTEyMXn75Zc2dOzfXA4zZ8rK+cnPFFVfo4MGDWrNmja677rqzTuvn56euXbuqU6dOvnxbvHjxWdfBwIEDJZ1oWFepUuW07yhVq1bNcW/ysznXMp7vOsirolz+vE5f2PlOExSWufjiixUdHa0XXnhBmZmZWr58eY6jHDExMapWrZo+/PBDeb1eLVy4MMeRoOwzAGJiYpSZmannn38+z2fPfPPNN0pOTtbKlSu1evVqrV69WmvWrNHw4cM1ceJEGWPUtm1bRUVFqW/fvmrZsqVq1aolSXK5XLrlllv03HPPKSkpSfv379drr7121s/r1q2bFi9enOPJdG63W+np6XK73fJ6vUpPT/cd1fz1119VoUKFHEc1x48f7wuZv//+W08++aSuuOKKHGfSZqtYsaJ69OihBx54wHfkcf/+/ZoxY0ae1t2AAQP02WefacaMGXK73UpKSspXqC5YsEDXXnttnqcHgJLqkUce0ffff5/rl+wLySnpxNkA8+bN0759+5SSkuLbiTp5/pGRkQoJCdGGDRv073//O8/zjo2NVXx8/Fmf4upwOPT0009r9OjRvmbsq6++qilTpujZZ5/17XwlJSVp5cqVZ/28P/74Q4sXL/btHFWrVi3Hk09PfZ38pPm77rpLb775prZs2aKkpCQ9++yzuv3221WmTJlcP+tcefncc8/5HsJ4Lmf7/S5evFjvvvuubz3s379f77//fo57sq1bt+6sy5mtd+/eWrBggebMmaOMjAyNGjVKMTExateuXa51LVy4UNu2bZMxRkeOHNGgQYPUqFEj31Uc2Q8LyX6I1vmwcvkWLVqkG2+8UR9//LGuvvrqXKdZsGBBjnvHArAPh8OhN954Q6NGjdKbb77p26YfOnQo3w/xue222/TOO+9o06ZNOn78uJ566ql8NZaOHz+uSZMmKTY2VtHR0efcz1qwYIFWr14tt9utkJAQBQUFyc/PT9KJs1D//vvvsx6wzG2/8VQXXXSROnTo4HuqdlxcnB555BHdeuutmjVrllJTU2WM0ebNm7V///4zzsftduv9999XcHCwb1932LBhZ92u9+rVS9KJA2Nt27bVsGHDlJaWpl9//VVTpkzR3XffnetnjR07Vhs2bPDtew8cOFAdO3b0PXzxzz//1O+//66srCylp6frzTff1Lp163JkQI0aNXwnLJ2N0+nU7Nmz9cMPPyggICDXWn788Uffelq6dKkWLVrky7fLL7/8rOtg/PjxvnndddddGjVqlPbv36/9+/dr9OjR6t+//xlrmzZtmpKTk2WM0W+//aYXX3xRN954Y57H5+c7zJlYufx5mX7hwoWFmu80QVHonnjiidOOHhw5ckT+/v765ptvNG/ePEVHR+vJJ59Uv379crx34sSJmjRpkiIiIvTee+/p1ltv9Y2788471ahRI1WvXl21atVSmTJlfE8EPJcPPvhAt912m+rXr+87EzT7htV79+71Pb23T58+mjdvnu+BSNneeustBQYGqlq1aurQoYNuueWWXDew2Zo2bao6derk2KkbOXKkypQpo1GjRmnWrFkqU6aMrrrqKkm5Xwo/f/58NW7cWCEhIWrfvr0aNGjgOxKXm8mTJ/suzwgPD9fll1/uC5lzrbuLLrpIX331lUaNGqXo6Gg1aNDgrDvKJ/N6vZoyZYruv//+PE0PACVZdHS0OnfunOsBqQvJKelE46h9+/aqX7++4uPjTzu49N577+nVV1/1HZU/OSPz4v7778/xBNXc3HDDDYqOjtbbb78tSWrdurWWLl2qdevWqWnTpgoLC1OLFi2UmJh42kMCb7vtNl/uX3/99Ro0aJAGDBiQrxqlEw+guOuuu9S2bVtVqVJFkZGReuONN3zjR48enePM0XPl5c6dO3M8BOJszvb7jYqK0rx589SiRQuFhITooosuUlRUlD788MN8L2O9evX0ySef6KGHHlJkZKR++OEHffPNN74d5+yzMrKtWrVK7dq1U2hoqBo3biy3261vv/3W9zThnTt3qnr16qpcuXK+aykOyzdixAglJyerZ8+euZ5ZeuzYMc2ZM+esO1oASrbu3btr9uzZmjNnjurWrevbnylfvrzGjh2b5/n069dPvXv31uWXX65atWqpefPm57wVxx9//OHb7mRfej579mzfWfdn2886cOCAbrvtNkVGRqpmzZqKiIjQ//3f/0mS+vfvrz179ig6Ovq0h71ly22/MTdPP/20JkyY4Ls68dVXX9Xw4cM1YsQIlS9fXuXKlVPPnj3Vt2/fHFczJCUl+ZYtJiZGX3zxhWbNmnVelx9/9tln2rNnj8qVK6cbb7xRL7/8co6nvjdq1MiXv9lnAWa/wsPDFRQU5MupQ4cOqXfv3oqMjFTlypU1ffp0fffdd74nmGdkZOjw4cO6+OKL81Rbo0aNfLe9O1VISIiGDRumypUrKzIyUgMGDNCzzz6r2267Ld/rYPjw4brkkkvUoEEDNWjQwNcYzjZw4EDfmZOS9Pbbb6tatWoKCwvzPSjrsccey/P4/HyHORMrl/9c0y9evNj3b6qwOExer5sCisC4ceM0c+ZMLVq0yOpS8uWzzz7Ts88+qy1btpxxmmXLlumRRx7J0xmVTZo00cSJE9WqVauCLLNIZF/6ebYGLQDAeh6PR82bN9dnn32mRo0aWV1OkWnSpIkWLVqksmXLWl1KoRkxYoQqVqyoe++91+pSCsXo0aN17NgxjRo1yupSAKDA5We/sbT46aefNH78eH322WdWl2Ipu3+Hufrqq/X444/ryiuvLLTPoAmKYqWkNEGzL8lr0aKFtm7dqh49eqh79+6+SxIuRGZmpl5++WU9/fTTRXKPLwAAAAAAALvzs7oAoCQ6duyYevfurV27dikiIkI33HCDnnnmmQKZd0BAQIHNCwAAAAAAAJwJCgAAAAAAAMDmeDASAAAAAAAAAFujCQoAAAAAAADA1miCwrY6dOigwMBAhYaG+l7vvvuupk2bpksvvVTBwcGKj4+/oM/YsGGD2rZtq+DgYNWtW1fffPPNWaf/+uuv1bRpU4WHh6tmzZoaO3asb9zu3bt16aWXqmzZsoqIiFB8fLxmzJjhGz969OgcyxISEiKHw6Hp06f7pklMTFT//v0VExOj8PBwtWzZUmlpaRe0jAAAFLSSltHnGp+ZmambbrpJNWrUkMPh0MyZM0+b/4QJE1S3bl2FhYWpfv36+vTTTy9o+QAAKAzFMaM/++wzNWjQQKGhoWrVqpVWrFiR63T/+c9/5HA4NG7cuBzDZ86cqTp16ig4OFiXXXaZNm7cmK/xsBED2FT79u3N2LFjTxv+ww8/mKlTp5qRI0eaZs2anff8MzMzTe3atc3w4cPN8ePHzaxZs0xISIjZsmVLrtMfOHDABAQEmE8++cR4vV6zevVqExERYb777jtjjDGpqalm06ZNxuPxGGOMWbp0qQkODjZ///13rvP78ssvTUREhElLSzPGGOPxeEzbtm3NwIEDzZEjR4zH4zErV640mZmZ572MAAAUhpKW0ecan5GRYcaOHWt+/vlnU6VKFTNjxowc81+5cqXx9/c3CxYsMF6v1/z4448mMDDQrFu37ryXEQCAwlDcMnrJkiUmPDzc/PLLL8btdpvx48ebmJgYk5iYmGO6PXv2mLi4ONOkSZMc9W/cuNEEBwebWbNmmePHj5vhw4ebunXrmqysrDyNh71wJihKnc6dO+uWW25R5cqVL2g+P//8s44cOaLhw4crKChI3bp1U/v27fXxxx/nOv3u3btljFGvXr3kcDjUrFkztWrVSn/88YckKSQkRHXr1pXT6ZQxRk6nUx6PR9u3b891fh988IFuu+02lSlTRpI0d+5c7dy5U2+99Zaio6PldDrVvHlz+fv7X9ByAgBQVIprRp9rfEBAgB5++GFdfvnlcrlcp81/27ZtqlGjhjp27CiHw6FOnTqpatWqWr9+/QUtJwAARcWqjP7666/VvXt3tWnTRi6XS/fee69CQ0NzXDUpSffff7+GDx+u6OjoHMM/+eQTdezYUd26dVNQUJCGDx+ugwcPavHixXkaD3uhCQqc4r777lNkZOQZX0uWLJEkrV27Vo0aNcrRZIyPj9fatWtznW98fLzat2+vDz/8UB6PRytXrtSaNWt01VVX5ZiuadOmCgwM1CWXXKK2bdvq8ssvP21eu3fv1rx589S/f3/fsJ9++klxcXHq06ePypYtq0aNGunDDz8siFUCAECxYFVG5zXDz+Tqq69WWFiYfvjhB3m9Xs2bN0+JiYm67LLLLnCNAABQPBRWRnu9XhljcgwzxuSY/ssvv1RycrLuuOOO096/du3aHJfv+/v7q2HDhr73n2s87IUmKGztqaeeyrHhPXbs2Dnf8+677yoxMfGMr+wdltTUVEVGRuZ4b2RkpFJSUnKdr9PpVN++ffXII48oMDBQLVu21OOPP66mTZvmmG7t2rVKTU3VrFmz1KVLl1zPKJk0aZKaNm2qFi1a+IYdPXpUCxcuVNu2bbVv3z795z//0QMPPKCff/75nMsMAEBRK0kZndcMP5Pg4GD17t1b119/vQICAnT99ddr3LhxqlixYp7eDwBAUSpOGd21a1fNmDFDS5cuVVZWlt555x3t3LlTycnJkqSEhAQNGTJE48ePz/X95/q8/NaDko0mKGxtzJgxOTa8ISEhBTbv0NBQJSUl5RiWlJSksLCwXKdfsGCBBg4cqOnTpyszM1NbtmzRlClT9O9///u0aQMCAtStWzctXLhQU6ZMyTHOGKNJkybp7rvvPq2eKlWq6IEHHlBAQIDatm2rHj166Ntvv73AJQUAoOCVpIzOT4bnZuLEiXr11Vf1yy+/KDMzU7/++quefPJJzZ49+8IWFACAQlCcMvqKK67QuHHjNGDAAFWsWFErVqxQ586dVbZsWUnSkCFDdPfdd6tOnTrn9Xn5rQclG01Q4BQDBw7M8SS8U1/Z9wZp2rSp1q1bp6ysLN97V69erSZNmuQ635UrV6pNmzbq0KGDnE6nateurZtuuumsO0BZWVnasmVLjmHz58/Xvn371Lt37xzDmzVrdr6LDABAiWBVRp9Php9s1apV6tKli5o1ayan06lmzZrpqquu0ty5cy9wjQAAUDwUVkZLUv/+/bV+/XodOXJE77//vtavX6/27dtLkn788Ue9/vrriomJUUxMjJYuXapnnnlGN954o+/zVq9e7ZtXVlaW1q9f7/u8c42HvdAERanj8XiUnp6urKwsGWOUnp6ujIwM3/jx48crNTX1jK/se3S2a9dO0dHRGjVqlDIyMjRnzhwtWrQo1/uQSNIll1yiFStWaOnSpTLGaMeOHfrqq6/UvHlzSSfu6bls2TJlZmYqMzNTkydP1sKFC3XllVfmmM8HH3ygG2644bRT9v/1r38pPT1d48ePl8fj0fLly/X111/r+uuvL8C1BwBA4SmuGX2u8ZKUkZGh9PR0GWOUlZWl9PR0eTwe3/vnzZundevWSZLWrVunefPm5Xg/AADFmVUZnZWVpdWrV8vr9erIkSN64IEHVLNmTV1zzTWSpF9++UVr167V6tWrtXr1arVs2VJDhgzRe++9J0nq3bu3FixYoDlz5igjI0OjRo1STEyM2rVrl6fxsBkrHkkPFIX27dubsWPHnjZ80qRJRlKOV/Xq1c/rM9atW2cuvfRSExQUZOLi4szMmTNzjA8JCTE///yz7+cJEyaY+vXrm9DQUBMbG2vuu+8+c/z4cWOMMbNnzzZNmjQxoaGhJjIy0rRu3dp8+eWXOeZ35MgRExgYaBYsWJBrPcuXLzctW7Y0wcHBpm7duuajjz46r+UCAKAwlbSMzsv46tWrn1b7pEmTfONHjx5tatasaUJCQky1atXM8OHDjdfrPa9lAwCgsBS3jD527JiJj483ISEhJjo62vTr188kJCTkq/7p06ebuLg4ExQUZC699FKzYcOGfI2HfTiMOeUxWwAAAAAAAABgI1wODwAAAAAAAMDWaIICAAAAAAAAsDWaoAAAAAAAAABsjSYoAAAAAAAAAFujCQoAAAAAAADA1miCAgAAAAAAALA1P6sLKEm8Xq/27t2rsLAwORwOq8sBYCPGGKWkpCg2NlZOJ8engPwiowEUJnIauDDkNIDCkp+MpgmaD3v37lXVqlWtLgOAje3atUtVqlSxugygxCGjARQFcho4P+Q0gMKWl4ymCZoPYWFhkqSAhnfK4QqwuJrSZfW3o60uodRJy3BbXUKpkpqaovYX1fVtZwDkDxltnY3zXrS6BKDQpaQkq2m9muQ0cJ7Iaev89ePLVpdQ6vj7ccVAUUpJTlZczap5ymiaoPmQfdq+wxXAhruIhYWHW11CqeNMpwlqBS4PAs4PGW0dMhqlCTkNnB9y2jrh5HSRowlqjbxkNL8ZAAAAAAAAALZGExQAAAAAAACArdEEBQAAAAAAAGBrNEEBAAAAAAAA2BpNUAAAAAAAAAC2RhMUAAAAAAAAgK3RBAUAAAAAAABgazRBAQAAAAAAANgaTVAAAAAAAAAAtkYTFAAAAAAAAICt0QQFAAAAAAAAYGs0QQEAAAAAAADYGk1QAAAAAAAAALZGExQAAAAAAACArdEEBQAAAAAAAGBrNEEBAAAAAAAA2BpNUAAAAAAAAAC2RhMUAAAAAAAAgK3RBAUAAAAAAABgazRBAQAAAAAAANgaTVAAAAAAAAAAtkYTFAAAAAAAAICt0QQFAAAAAAAAYGs0QQEAAAAAAADYGk1QAAAAAAAAALZGExQAAAAAAACArdEEBQAAAAAAAGBrNEEBAAAAAAAA2BpNUAAAAAAAAAC2RhMUAAAAAAAAgK3RBAUAAAAAAABgazRBAQAAAAAAANgaTVAAAAAAAAAAtkYTFAAAAAAAAICt0QQFAAAAAAAAYGs0QQEAAAAAAADYGk1QAAAAAAAAALbmZ3UBKBie5O1yH1glk35U8mbK4R8qZ0RN+VVsJYcrUJLkPrhSnoQtMhnJkrxyBITLVbaRXDFN5HA4rF0AG5n//Vy9+8Zr2rJpg1JTklWxUqyuvvZ6PTL0GYVHRFhdni1Nn/qxnnp44GnDBzzwqB5/+gULKgKAnPKS0+mr3znj+wMb9ZXDP6SoyrWtr6d/qS+mfqo1q1YqKTFBtWrHacCgB3R7n758FyokrHMAJY3xZCpj46dS1jEF1L1ZzuDyvnHuI+vlObhSJjNVjsBI+VW6WK6IGtYVazN//bVVb417TSt+Xa716/5U3Xr1tfz3tVaXZXubNm7Uow8P1i/L/quwsDDd3vsOPff8SAUEBFhdWoGjCWoX7gw5QyrIWa6p5AqSST8i9/4VMulHFVD7ekknNuauyDg5gspKTpe8Kbvl3rNY8mbKr0JLixfAPhITEtS8RSv1u/d+RUVHa9P6dXr9pZHatGGdPp0+x+rybG3CpzMVFv5Po7lCxVgLqwGAk+QhpwPq3Hja27J2/ig5/WmAFpB/vz1OVavV0POjX1bZmHL6aeGPeuSBgdqze7eGDhtudXm2xDoHUNK4D/wmGe9pwz0JW+TetVCuCi3lDK0sb+JWZW2bK0edf8kZUtGCSu1n4/p1mjd3jlq2ai2v1yuv9/TfAwpWQkKCrrnqCsXF1dHnX0zX3j179MSQR5WWlqZxb75tdXkFjiaoTbii68l18oCwypLTJfeuRTJZx+TwD5F/pYtzviesqkxWijxHN9IELUA39rw9x8+XXtZeAYGBeuLh+7R/315VrERjrrA0atpc0WVjrC4DAE6Tl5w+dQfKm5Esk5Ekv9hLirJUW5sybabKxvyTE+06dNTRI0f077fH6fEnn5bTyZ2iChrrHEBJ4k1PkOfwH/KLbSv37p9yjHPv/1XOyDryr9RGkuQKqyLv8RMHNQNqX2dFubbT5drrdO113SVJAwfcpVUrf7e4Ivub8J/xSklO1tQvZyg6OlqS5Ha79dDg+zT0yWGKjbVX/8LSbx01atTQ6tWrcwzr0KGDZs6cWSDznDx5sjZu3OgbN3nyZPXo0eO8513SOFxBkiTj9Zx1GsPRlUIXFV1WkpSVlWlxJQCQN2R04TtXTnsTN0uSXJF1i6wmuzu5GZetSbN4pSQn69ixYxZUZH+sc6DgkdGFx737Z7nKNpYjMCrHcG9GkkxGolyRcTmGu6Li5E3dfdZ9buQdB8aK3rzv5qpjp86+Bqgk3XjzLfJ6vZr/w/cWVlY4bP0XdurGuzQwxivjdcubdkju/SvkDK8hZ2D46dN4MuVJ2i7P0U3yK9fUomrtzePxKD09XX+sWaVxL4/SVV26qWq1GlaXZWvdOrRUg8ph6tSmkd578xV5PHwZAYqr0pjRUt5yOpsnYYscIbFyBIQWcZWly/JlS1UptrLCwsKsLqXUYJ0DxVtpzWhP4lZ504/Ir2Kr08aZjARJkiMoZ3PUERQtGa9MZnKR1AgUtM2bNqpevfo5hkVGRqpipUratMl+24Fi2wRNSUnRgAED1Lp1azVt2lT33HOPMjNPnEX3+uuvq1WrVoqPj1erVq20bNmy094/YcIE/fbbb3rkkUcUHx+vOXNO3IsxNTVVt912m5o0aaKWLVvq77//LtLlKmwZ6z9Sxtr3lLl52olL4KtflWO8NyNRGWv+rYw/3lfWttlylWsqv/Lx1hRrc22a1lFcpQh16XCxyleoqLff/8jqkmyrXPmKGjzkGb305vt6f8oMte90tca99LxGDR9idWmALZHR5+9cOZ3Ne/ywTPpRuaI4C7Qw/fLfJZrx5TTd/9AjVpdSarDOgcJFRp8f481S1p6l8qt0sRyuXB4G486QpNPGZT/cUJ70wi4RKBQJCQmKiIw8bXhUVJQSjh4t+oIKmeVN0J49eyo+Pt73+u233yRJjz32mC6//HL9+uuvWrNmjbxer9544w1JUp8+fbRixQqtXr1ab731lu66667T5tu/f3+1bNlSY8eO1erVq9W1a1dJ0ooVKzR69Gj98ccf6ty5s1566aUz1paRkaHk5OQcr+IuoFY3BdS5UX5VO8qbnqCsbbNlTrqps8M/TAF1b5Z/7R7yq9hankOrlbVvuYUV29dHU7/W1/N+0stv/FtbN29S39tu4MzEQnJ5xyv1wKNP6fKOV+qyDp317OjX1ffewfr8owk6eGCf1eUBJRYZXfDOldPZPAmbJYdTrsjaFlRZOuzds1v97+yly9p10D2DBltdTqnAOgcKTnHOaKnk5bR7/29y+AXLFd3A6lIAFCLLH4w0depUxcfH+37u0KGDJGnmzJlatmyZXn/9dUnS8ePH5XKdeKTAqlWrNGrUKB05ckR+fn7atGmTjh8/rjJlypzz8y655BLVrFnT9/9vvfXWGacdM2aMRowYcZ5LZg1nmRP3XXKGVJQzuLwyN02VN+lv371LHE6XHMHlT0wcVllyBci9Z6n8Yhrz5NkC1rBxE0lSi9YXK755S13VrpXmfvu1unW/weLKSocu19+oif9+Qxv+XKvyFSpZXQ5QIpHRBe9cOS1Jxhh5ErbIGVZNDr8gq0q1taTERPX8VzdFR0dr8pRp3IOsCLDOgYJVnDNaKlk5bTKT5Tm0Wv41u0ieTBlJ8madGOfJkvFkSn6B//s5M8d+s/GcOENULvIaJVNUVJSSk5JOG56QkKCok+4TaheWN0HPxBijr776SnXr5rwMLDMzUzfccIMWLlyoVq1aKTk5WREREcrIyMjTxjso6J+Nk8vlktvtPuO0Tz31lB599FHfz8nJyapatep5LI01HEFlJYdTJuP0P+hszjLlJBmZzBSaoIWoQeMm8vf31/a//7K6FAC4YGR0wThTTptj+6SsVLliL7WoMns7fvy4br+5u5KTk/XdgsUKj4iwuiTbY50DRac4ZLRUsnLam5EiGa+y/p592risv2bKEVxB/tWvlPS/e4OedF9Qk54gOZxyBOR+f2+guKtbr/5p9/5MSkrS/n37TrtXqB0U20OwPXr00EsvveTbuCYkJGjr1q1KT09XZmamqlWrJklnPQIVHh6upFw62nkVGBio8PDwHK+SxKQdkIz3rBtk77ETlwqz0S5cK3/7VVlZWapeo6bVpZQac2Z+IZfLpYZNmlldCmA7ZHTBOFNOexI2S05/OSPIjILmdrt19x23afOmjZo241tViq1sdUm2xzoHilZxyGipZOW0s0yM/Gv3yPHyi71MkuRXpb38q7SXMzBCjsBIeRJzntTiSdwqZ2gVOZwuK0oHLtjV13TRwvk/KjEx0Tds+pdfyOl0qtOVud+7viQrtk3QsWPHqkyZMoqPj1fTpk3VqVMnbd++XeHh4Ro5cqRat26tFi1aKCAgl5sW/88999yj0aNH57ihs11lbpsr94HfTjzxPWWX3AdXK3PbXDmCysoZUUvGk6GMLV/JffhPeVJ2yZO8XVl7/yv3/l/lKttIDv9gqxfBNvr3uUVvvfaSfvxutpb8tED/eWecBvS5RQ0aNdHV115vdXm2dPet1+s/b7+mn+Z/p5/mf6dnhz6oyf95W737DVS58hWtLg+wHTI6/86V09mM8cqT+JecETXlcBbbC3ZKrCEPP6Dv587WI0OeVEpKsn779RffKyMjw+rybIl1DhQtMjr/HH6BcoVVzvFyZN++Jri8nMHlJEl+FVvJm7BZWfuWy5OyR1m7FskcO5Dr0+RxftLS0jRz+peaOf1L7dq5UynJyb6fDx86ZHV5ttT/noEKDQvTLTf20I8/fK+PJk/SsCeHqP89AxUbG2t1eQXOYYwxVhdRUmRfMhDYZEDuT4yzkPvA7/Ikbv3fJXVGjoBwOSNqya98czlcATJej9y7F8mbuk8m65jkdMkRGCFX2cZyRdeTw1Fs++GSpK0LX7e6hDx7e+wrmjXjC+3Y/re8Xq+qVq2ua67roYEPPKKwYnwE9FTH0s9+iUtxMvKZx7V44Q/av3ePvMarGrXidPPtfdXn7kFyOBxWl5cnqSnJalG3kpKSkor1kXKguCrOGS2dO6ezeZK2K2vbbPnX6iZXeHXrCs6H3UvGWV1CnjVvGKddO3fkOm7lui2qVr1G0RZUCthlnackJ6tmbFlyGjhPxT2nT+VJ2aOsv2YqoO7NcmY/U0OS+8h6eQ6slMlKkSMwSn6VLpYrooZ1hebBwWVvWl1Cnu3YsV1N6uf+UMjZ8+br8nYdirag8+TvV7z7K6fauGGDHn14sH5Z9l+FhYXp9t53aMQLo856sKQ4SU5OVoWyEXnKaJqg+VDSNtx2UpKaoHZRkpqgdkATFLgwZLR1SlITFDhfNEGBC0NOW6ckNUHtoqQ1QUu6/DRB+c0AAAAAAAAAsDWaoAAAAAAAAABsjSYoAAAAAAAAAFujCQoAAAAAAADA1miCAgAAAAAAALA1mqAAAAAAAAAAbI0mKAAAAAAAAABbowkKAAAAAAAAwNZoggIAAAAAAACwNZqgAAAAAAAAAGyNJigAAAAAAAAAW6MJCgAAAAAAAMDWaIICAAAAAAAAsDWaoAAAAAAAAABsjSYoAAAAAAAAAFujCQoAAAAAAADA1miCAgAAAAAAALA1mqAAAAAAAAAAbI0mKAAAAAAAAABbowkKAAAAAAAAwNZoggIAAAAAAACwNZqgAAAAAAAAAGyNJigAAAAAAAAAW6MJCgAAAAAAAMDWaIICAAAAAAAAsDWaoAAAAAAAAABsjSYoAAAAAAAAAFujCQoAAAAAAADA1miCAgAAAAAAALA1mqAAAAAAAAAAbI0mKAAAAAAAAABbowkKAAAAAAAAwNZoggIAAAAAAACwNZqgAAAAAAAAAGyNJigAAAAAAAAAW6MJCgAAAAAAAMDWaIICAAAAAAAAsDWaoAAAAAAAAABsjSYoAAAAAAAAAFujCQoAAAAAAADA1vysLqAk+u9Xzys0LNzqMkqVuI6PWl1CqbNr8TirSyhV/L0BVpcA2MIvM15QGBldpKp0ecHqEkqdhAUjrC6h1PEEstsEFISN815UeDg5XZTKd3vF6hJKnYPfDrG6hFIly+3N87ScCQoAAAAAAADA1miCAgAAAAAAALA1mqAAAAAAAAAAbI0mKAAAAAAAAABbowkKAAAAAAAAwNZoggIAAAAAAACwNZqgAAAAAAAAAGyNJigAAAAAAAAAW6MJCgAAAAAAAMDWaIICAAAAAAAAsDWaoAAAAAAAAABsjSYoAAAAAAAAAFujCQoAAAAAAADA1miCAgAAAAAAALA1mqAAAAAAAAAAbI0mKAAAAAAAAABbowkKAAAAAAAAwNZoggIAAAAAAACwNZqgAAAAAAAAAGyNJigAAAAAAAAAW6MJCgAAAAAAAMDWaIICAAAAAAAAsDWaoAAAAAAAAABsjSYoAAAAAAAAAFujCQoAAAAAAADA1miCAgAAAAAAALA1mqAAAAAAAAAAbI0mKAAAAAAAAABbowkKAAAAAAAAwNZoggIAAAAAAACwNZqgAAAAAAAAAGyNJigAAAAAAAAAW6MJCgAAAAAAAMDWzqsJunjxYvXu3VuXXHKJ9uzZI0n6+OOPtWTJkgItDgAA5A8ZDQBA8UVOA4B18t0E/eqrr3T11VerTJkyWrVqlTIyMiRJSUlJGj16dIEXCAAA8oaMBgCg+CKnAcBa+W6Cjhw5UuPHj9f7778vf39/3/C2bdtq5cqVBVocAADIOzIaAIDii5wGAGvluwm6adMmtWvX7rThERERSkxMLIiaAADAeSCjAQAovshpALBWvpugFStW1NatW08bvmTJEtWqVatAigIAAPlHRgMAUHyR0wBgrXw3QQcMGKCHHnpIy5cvl8Ph0N69ezVlyhQ9/vjjGjRoUGHUCAAA8oCMBgCg+CKnAcBafvl9w5NPPimv16tOnTopLS1N7dq1U2BgoB5//HENHjy4MGrEeZo+9WM99fDA04YPeOBRPf70CxZUZD+e5O1yH1glk35U8mbK4R8qZ0RN+VVsJYcrUJLkPrhSnoQtMhnJkrxyBITLVbaRXDFN5HA4rF0Am/h6xpf68vNPtWb1SiUlJqhm7TgNGPiAbu/Tl3WMUoWMLjm++vxjPfHQvacNv+eBxzR0OBldEDxHt8i9a6lM2mHJkyFHYJicZevJr1p7OfyCJEmZm76W9+Ca097r3+h2uaLjirpk29q0caMefXiwfln2X4WFhen23nfouedHKiAgwOrSgCJFTpccX0//UtOmfqo1q07sX9SqHad7BrF/UVA8hzfKveMnmWMHJXe6HIERcpZrKL9anX0ZnT7/yTO+P/CyYXIEhhdVubb2119b9da417Ti1+Vav+5P1a1XX8t/X2t1WYUm301Qh8Ohp59+WkOGDNHWrVuVmpqqhg0bKjQ0tDDqQwGY8OlMhYVH+H6uUDHWwmpsxp0hZ0gFOcs1lVxBMulH5N6/Qib9qAJqXy9JMp5MuSLj5AgqKzld8qbslnvPYsmbKb8KLS1eAHsY/9Y4Va1eQyNGv6yYmHJatOBHPTp4oPbu2a0hTw23ujygyJDRJc/Ez79WWNhJGV2JjC4w7uNyhleWs3Ibya+MTNrB/+1wHVJAk96+yRxBUfKv968cb3UExxR1tbaVkJCga666QnFxdfT5F9O1d88ePTHkUaWlpWncm29bXR5QpMjpkuPdt8epWrUaemH0yyobU06LFv6ohx8YqD27d2voMPYvLljWcTnDq8pZ9VLJP1gm9YDc236UOXZAAc3vliQFtLzv9Letmya5/GmAFqCN69dp3tw5atmqtbxer7xer9UlFap8N0GzBQQEqGHDhgVZCwpJo6bNFV2WL/OFwRVdT66TB4RVlpwuuXctksk6Jod/iPwrXZzzPWFVZbJS5Dm6kSZoAflk2kyVjfnnb/zy9h2VcPSI/v32OD32xNNyOvN95w+gRCOjS47GZHShcZVvmjOjI2tIDj+5t34rk5EiR2DYieFOPznDq1hQYekw4T/jlZKcrKlfzlB0dLQkye1266HB92nok8MUG0vjH6UPOV38fXrK/kW7Dh2VcOSI3n17nB5/kv2LC+Wq1FwuNf9nQFRtyekn98bpMhnJcgSGyxlRLcd7vMePyhw/LL+4LkVcrb11ufY6XXtdd0nSwAF3adXK3y2uqHDluwnasWPHs57+vWDBggsqCCjpHK4Tp+8br0dn+pficAXZ/ghLUTr5C0q2Js3i9fHkD5R27JhCw8IsqAooemQ0cHYO/zKSJGPOnNEoWPO+m6uOnTr7GqCSdOPNt2jw/QM1/4fv1efOvtYVBxQxcrrkONP+xUeTP9CxY8cUxv5FgXP4B0uSjNeda0Z7D6yR5JCrQnxRlmV7pa2hn++ljY+PV7NmzXyvhg0bKjMzUytXrlSTJk0uuKDMzEw98cQTiouLU4MGDdSkSRN9+OGHkqTt27dr/PjxOaavUaOGVq9efcGfa2fdOrRUg8ph6tSmkd578xV5PB6rS7IdY7wyXre8aYfk3r9CzvAacp5yir4xXhlPpjxJ2+U5ukl+5ZpaVG3psHzZUlWKrUwDFKVKYWe0RE4XtC7tWqpupVB1bNVQ/36DjC4MvoxO3Sf3zp/ljK4rZ1DkP+OPH1X6f19S+pKRylj1vjyHN1pXrA1t3rRR9erVzzEsMjJSFStV0qZNrGuULuxLl2zZ+xc0QAvOiX3kLHmT98i9bb6cMQ3kLBOd67Se/avliKwhR1BEruOBvMj3maBjx47Ndfhzzz2n1NTUCy6ob9++ysjI0Jo1axQSEqLt27erS5cucrvdql27tsaPH6+BA09/2M+FcLvd8vM77zsDFFvlylfU4CHPqFnzlnI4HFrw/RyNe+l5Hdi/T8+Oft3q8mwlY/1HUtYxSZIzrJr8q1+VY7w3I1GZG6b4fnZVaCm/8vFFWWKp8st/l2jGl9M0YvTLVpcCFKnCzmiJnC4o5SpU1ENDn1Gzi1rJ4XBo/rzZGvviCB3Yv1fPjcn994jzk/HrG1JmiiTJGVVb/vVv8I1zhlaUMyxWjuBykjtdnn2/KWvDNKn+TXKV41LVgpCQkKCIyMjThkdFRSnh6NGiLwiwEPvSJdcv/12i6V9O0wtj2L8oSBlLX5QykiVJzrJ15d/4tlyn86bskzl2QH71/5XreCCvCmxr1bt3b7Vu3Vqvvvrqec9jy5Ytmjlzpnbt2qWQkBBJJ45Ovfbaaxo4cKCCg4O1Y8cOxcfHq1q1avrmm28kSdOnT9egQYO0f/9+3X333XrmmWckSfv379eDDz6o7du36/jx4+revbtGjhzpm2/Pnj21cOFC1alTR1OmTMm9qBLs8o5X6vKOV/p+vqxDZwUGBenD/7ytgQ8NUfkKlSyszl4CanWTvG5504/Kvf83ZW2bLf/a18vhOHGytcM/TAF1b5bxZMkc2yv3wZWSJP9Kbaws25b27tmtAX176bJ2HXTPIJ6yCUgFk9ESOV2Q2nW8Uu1OyujLO3RWUFAZTXrvLd338FAyugAFNL5d8mSeuFpj52Jlrftc/k16y+Fwyq9yzhx2lq2nzDUT5d6xiCYogCLDvnTxtmfPbt19J/sXhSGg2V2SN1Pe1ANyb1+grDWT5d+8v28/OpvnwGrJ4ZKrfMFc2YTSq8CaoMuWLVNQUNAFzWPVqlWqU6eOypYtm2P4JZdcol27dmnatGkaNWrUaafsJyYmatmyZTp8+LBq166tu+66S5UrV9add96pYcOGqX379nK73erWrZu++OIL3XzzzZKkI0eOaPny5We8L0tGRoYyMjJ8PycnJ1/Q8hUHXa6/URP//YY2/LmWHawC5Cxz4p4xzpCKcgaXV+amqfIm/S1XZJwkyeF0yRFc/sTEYZUlV4Dce5bKL6axHP4hVpVtO0mJibr1hm6Kjo7WpE+mlbr7mwBnUhAZLRWvnLZjRne9/gZNeHccGV3AnCEVTvw3vKqcobHKXPUfeQ9vzLXJ6XA45IppcOIJtZ4sOVz+RV2u7URFRSk5Kem04QkJCYqKzv2SR6C0YV+6+EpKTFTPf53Yv/hwCvsXBc0ZduL7jjOiupzhVZT565vyHlwnV4V/mp3GGHkOrJGzbF3ffUOB85XvJugNN9yQ42djjPbt26fffvtNw4cPL7DC8uP222+XJMXExKhWrVratm2bIiMjNX/+fB04cMA3XWpqqjZt2uT7uW/fvme9MfWYMWM0YsSIwisctuQIKis5nDIZp3/hz+YsU06SkclMoQlaQI4fP67bb+6u5ORkzZ2/WOER3CsGpU9xzGipcHKajMb5cIRUOJHR6VyGXVTq1qt/2r0/k5KStH/fvtPuFQrYXXHMafalz+z48eO67X/7F98tYP+isDlCK0kOl8zxIzmGm8TtUnqiXDwVHgUg303QiFP+4TudTtWrV0/PP/+8rrrqqjO8K2+aN2+uLVu26MiRIzmOYC1btkxVq1ZVuXLlcn3fyUfNXC6X3G63jDGSpF9++eWMR9VCQ0PPWs9TTz2lRx991PdzcnKyqlatmuflKY7mzPxCLpdLDZs0s7oU2zJpByTjlSMg/IzTeI/tk6SzToO8c7vd6n/HbdqyaaNmfb9QlWIrW10SYInCzGipeOW0HTP625lfktGFzKTsOZHRQVG5jzdGnkPr5Qgux1mgBeTqa7ro5RdHKzExUZH/uzfo9C+/kNPpVKcrL3y7BJQk7EuXnJx2u926+47btHnTRn07b6Fi2b8odCZ5l2Q8cpzyYCTPgdWSK0DOGG5TgwuXryaox+PRXXfdpSZNmigqKvcvjxeiTp06uu6663TPPffo448/VnBwsLZv367HHntMw4cPV3h4uJJyuZwmN6GhoerYsaNefPFFPffcc5KkvXv3yuv1qkqVKnmaR2BgoAIDA893cSx3963Xq81l7VWvQSNJ0vx5czTtk4m6o/99Kle+osXV2UPmtrlyBpeTIyhGcp44auU+uEqOoLJyRtSS8WQo8+9v5YqqJ0dghGQ88qbulefQGrnKNuJ0/gIy9JEH9P13s/X86JeVkpys3379xTeuSbPmJfrfMZBXhZ3RUvHK6ZKe0X17Xq9LcmT0bH3+8UTdOeB+MrqAZK6fJmdopRNnfzr9ZI4dkHv3MjlCKshZtr5MeqIyN38tV7nGJ5qi/3swkkndK/8Gt1hdvm30v2eg3n3nLd1yYw8NfXKY9u7Zo2FPDlH/ewYqNjbW6vKAIsO+dMky5OEHNG/ubL0w5mWlpCRrxUn7F03Zv7hgmWs/ljO8ihyhFSWnv0zqPrl3/CxHaEU5T7pdjfF65Dn4p5zlGnFwspCkpaXp++/mSJJ27dyplORkzZz+pSTpssvbK+YMB1BKqnw1QV0ul6666ipt2LCh0HawPvroIz3zzDNq0qSJAgIC5HK5NGTIEPXr109ut1uNGjVS48aNVatWLd/NnM9kypQpevTRR9W4cWM5HA6FhITovffey/OGu6SrGVdXX332kfbv3SOv8apGrTgNe/5l9bl7kNWl2YYzuLw8iVtlMlZKMnIEhMtVtqH8yjeXw+mS8UrOwEh5Dq6WyTomOV1yBEbIr0oHuaLrWV2+bSxa8KMk6dlhQ08b9/ufW1Steo0irggoekWR0RI5XVBqx9XVF59+qP379sjr9apmrTp65oVXdEd/MrqgOMNi5Tm0Xmb3UskYOYIi5arYXH5VLj2R0a5AOVyBcu9cLP0vo52hleTf+Ha5ouKsLt82oqKiNHfefD368GDdcmMPhYWFqW+//hrxwiirSwOKFPvSJcvC/+1fDH/q9P2LVevYv7hQzvCq8hxYI7N9kSQjR1CUXLGt5Fe9nRzOf9pU3qNbpKxjclWIt6pU2zt06KDu6NUzx7Dsn2fPm6/Ly3WwoKrC4zDZ57rnUcuWLfXSSy+pU6dOhVVTsZWcnKyIiAj9vnmfQsO4jLkoNetyevigcO1aPM7qEkqVlORk1apcVklJSQoPZ/uC80NGR2jV1v0KI6OLVOObXrS6hFInYUHJvs9eSZScnKwKZSPIaVwQcjpC2/Ye4d9QEavc/TWrSyh1Dn47xOoSSpXk5GRVqRCVp4zO96PNRo4cqccff1zffvut9u3bp+Tk5BwvAABgDTIaAIDii5wGAGvl+XL4559/Xo899pi6du0qSbr++utzPA3OGCOHwyGPx1PwVQIAgDMiowEAKL7IaQAoHvLcBB0xYoQGDhyohQsXFmY9AAAgn8hoAACKL3IaAIqHPDdBs28d2r59+0IrBgAA5B8ZDQBA8UVOA0DxkK97gp58yj4AACg+yGgAAIovchoArJfnM0ElqW7duufceB89evSCCgIAAPlHRgMAUHyR0wBgvXw1QUeMGKGIiIjCqgUAAJwnMhoAgOKLnAYA6+WrCXrrrbeqfPnyhVULAAA4T2Q0AADFFzkNANbL8z1BuYcJAADFExkNAEDxRU4DQPGQ5yZo9hPtAABA8UJGAwBQfJHTAFA85PlyeK/XW5h1AACA80RGAwBQfJHTAFA85PlMUAAAAAAAAAAoiWiCAgAAAAAAALA1mqAAAAAAAAAAbI0mKAAAAAAAAABbowkKAAAAAAAAwNZoggIAAAAAAACwNZqgAAAAAAAAAGyNJigAAAAAAAAAW6MJCgAAAAAAAMDWaIICAAAAAAAAsDWaoAAAAAAAAABsjSYoAAAAAAAAAFujCQoAAAAAAADA1miCAgAAAAAAALA1mqAAAAAAAAAAbI0mKAAAAAAAAABbowkKAAAAAAAAwNZoggIAAAAAAACwNZqgAAAAAAAAAGyNJigAAAAAAAAAW6MJCgAAAAAAAMDWaIICAAAAAAAAsDWaoAAAAAAAAABsjSYoAAAAAAAAAFujCQoAAAAAAADA1miCAgAAAAAAALA1mqAAAAAAAAAAbI0mKAAAAAAAAABbowkKAAAAAAAAwNZoggIAAAAAAACwNT+rCyiJ/Pyc8vejf1yUEla8bXUJpU5U5xesLqFUMe50q0sAgPOSsGCE1SWUOlXvmWp1CaWONzPN6hIAW3B7jLI8xuoySpWE756wuoRSp8agL60uoVTJT0bTyQMAAAAAAABgazRBAQAAAAAAANgaTVAAAAAAAAAAtkYTFAAAAAAAAICt0QQFAAAAAAAAYGs0QQEAAAAAAADYGk1QAAAAAAAAALZGExQAAAAAAACArdEEBQAAAAAAAGBrNEEBAAAAAAAA2BpNUAAAAAAAAAC2RhMUAAAAAAAAgK3RBAUAAAAAAABgazRBAQAAAAAAANgaTVAAAAAAAAAAtkYTFAAAAAAAAICt0QQFAAAAAAAAYGs0QQEAAAAAAADYGk1QAAAAAAAAALZGExQAAAAAAACArdEEBQAAAAAAAGBrNEEBAAAAAAAA2BpNUAAAAAAAAAC2RhMUAAAAAAAAgK3RBAUAAAAAAABgazRBAQAAAAAAANgaTVAAAAAAAAAAtkYTFAAAAAAAAICt0QQFAAAAAAAAYGs0QQEAAAAAAADYGk1QAAAAAAAAALZGExQAAAAAAACArdEEBQAAAAAAAGBrNEEBAAAAAAAA2BpNUAAAAAAAAAC2RhMUAAAAAAAAgK3RBAUAAAAAAABgazRBAQAAAAAAANian9UFoOgcS03VlZc20/59ezXzhyVqGt/C6pJsadPGjXr04cH6Zdl/FRYWptt736Hnnh+pgIAAq0uzBc+RzXLvWiyTdkhyZ8gRGC5n2fryq9FRDr+gE9Mc3SrPgVUyybtl0hPkim0t/zrdLK4cAP7x1ecf64mH7j1t+D0PPKahw1+woKLSg5wuXJm7Vintj2/kSdwtk3VczuBoBVRvqeD4m+QMCPZNl7Hzd6WtnCpP8j45Q8oquGkPBdXpYF3hAHCSH7+fq7fHvarNGzcoNSVZFStVVpdu1+uxJ55ReESE1eXZFhlduDJ2rdSxNTPlTtwtk3lcrpBoBVZvpZCLbpYzIETG61HaH98qY9fvcifsluSVX3QNhbboqYCKDawuv0DQBC1F3np9jNxuj9Vl2FpCQoKuueoKxcXV0edfTNfePXv0xJBHlZaWpnFvvm11efbgPi5nWBU5K18s+QfLHDso9/aFMmkHFdD0TkmSN2GrTOp+OSNryHP4uMUFA8CZTfz8a4WF/bMzVaFSrIXV2B85Xfi8manyLxenMg2vkSMwVJ6EXUpb/ZU8CbsUcfXTkqSsAxuVsuA1BdW9QiFt7lTWvj+VuuQ9OfyDFFjjYouXAACkxISjuqhFK/W/935FRZfVxg3r9NqYF7Rx/TpNnTnH6vJsiYwufN70VPmXq6PgRl3lDAyTO2GnUld+IXfCLkV1GS7jydSxNTNUpm4HhTTtLjmcOr7xRyXMfk5RXZ5RQGwTqxfhgtEELSX+2rJJn3zwnoY9/6KeeXyw1eXY1oT/jFdKcrKmfjlD0dHRkiS3262HBt+noU8OU2wsO7cXylWhmVwVmv0zILKm5HTJvfkbmYxkOQLD5VfrKjlqXyNJ8iRss6hSADi3xk2bK7psjNVllBrkdOELqn25VPukAZUayeHyV+p/35cn7ahcwdFKWz1dfuXiFHppf0lSQKVG8qYcUNrKL2iCAigWburZS+r5z89tL2+vwIBAPf7QIO3ft1cVOWhZ4MjowlemTrscPwfENpJc/kpZ8p48x47KWSZCMT3fljMw9J9pKjfVka8e07E/ZtuiCco9QUuJ5556VLf37a9acXWtLsXW5n03Vx07dfZttCXpxptvkdfr1fwfvrewMntz+J24vM6YE2c6Oxxs2gAApyOnreEIDDvxPx63jCdLWfvXndbsDKh5qTxJe+RJOWhBhQBwblH/y47MzEyLK7EnMtoazuyM9rrlcLpyNEAlyeF0yS+6mrxpRy2oruCVqE5BjRo1VK9ePcXHx6tevXp68cUXz3te48aN0/79+wuwuuJrzjfTtWn9Og1+fJjVpdje5k0bVa9e/RzDIiMjVbFSJW3atNGiquzJGK+MN0velL1y71gkZ9n6cgZFWV0WUGqR0eenS7uWqlspVB1bNdS/33hFHg+3rSlM5HTRMV6vjDtT7sPblLbmKwVUbSFXWHl5Ug5IXo9cETnP6PGLqCxJ8iTttaJcwPbI6fPj8XiUnp6utatX6fWXR+nqrt1UrXoNq8uyJTK66BivR8adqazDf+vYqi8UWK2lXGHlzzht1qEt8ousUsRVFo4Sdzn81KlTFR8frz179qhhw4a64oor1Lp163zPZ9y4cerQoYMqVqxYCFUWH8fT0jTq2Sf0+NMjFBYWbnU5tpeQkKCIyMjThkdFRSnhqD2OnBQXGb+8LmUmS5KcUXHyb3CTxRUBIKPzrlyFinpo6DNqdlErORwOzZ83W2NfHKED+/fquTFjrS7PtsjpopPwxQO+s0b8KzdTWPsTt2MyGcckSY6AkBzTOwJP/OzNSC3CKoHShZzOv5aN47Rv7x5JUsfOV+vdCR9bXJF9kdFF5/Dn9/kyOqBKvCI6PnTGadPWfi3vsaMKbnJtUZVXqErUmaAnq1y5surXr68dO3aoQ4cOmjlzpm/cTTfdpMmTJ0uSJkyYoIYNGyo+Pl5NmjTR8uXL9fzzz2vv3r3q2bOn4uPjtXr1akuWoSi8/fqLiilXXjfffofVpQAFKqBJbwXE95df3e7yph1W1p9TZIzX6rIAiIzOi3Ydr9Tgx4apXccrdXmHznpuzFj1G/igPvtwgg4e2Gd1ecAFC7/yCUVc+7xC294jT9IeJf/4ioyXnAaKA3I676Z88bW+/eFnvfbmeG3ZvFF39PwXV22gxIu8epiirhupsMsGyp24RwnfvyjjPf3vOmP3GqX+Pk0hzW+Sf0ztXOZU8pS4M0Gzbdy4UUeOHFGHDh30zjvvnHG6xx57TBs3blSlSpWUlZWljIwMtWnTRhMnTvQdCTuTjIwMZWRk+H5OTk4uyEUodHt27dAH/35D/548VSnJSZKkY8dOHF1PO3ZMx1JTFRIaerZZIJ+ioqKUnJR02vCEhATfPWRQMJyhJ448OyOqyRlWWZm/vyvv4Q1ylWtkcWUAyOjz0/X6GzTh3XHa8Odala9QyepybImcLjp+0dUlSf7l68ovprYSv35CmTt/let/l9OZrLQc02efIXrqvcgAFDxyOu8aNm4qSWrZ+mLFX9RCnS5rpTmzZuq6HjdaXJn9kNFFx7/siYwOqFBP/uVq6+iMIcrY8auCal7imybr8N9Kmv+aguIuU+hFN1tVaoErcWeC9uzZUw0aNFDDhg01ePBglStX7qzTd+rUSX369NEbb7yhbdu2KTQfTb8xY8YoIiLC96pateqFll+kdu3coczMTN19+78UH1dJ8XGVNKDXiY317T2uVp+bulpcof3UrVf/tPuVJCUlaf++fafd3wQFxxFSQXK4ZI4fsboUoFQjo1HckdPWcEVVk5wueZIPyBVW4cT/J+7JMY37f/cCPfVeoQAKDjl9YRo2bip/f39t//svq0uxJTLaGn7R1f+X0f/c59edtE+J342Wf4W6Cr98oIXVFbwS1wSdOnWqNmzYoO+//15PPvmk/vjjD/n5+eU4JT09Pd33/1999ZVefPFFZWVlqWvXrvr888/z/FlPPfWUkpKSfK9du3YV6LIUtoaNm+rTmfNyvJ554WVJ0shX39LzL71hcYX2c/U1XbRw/o9KTEz0DZv+5RdyOp3qdOVV1hVmcyZlt2Q8cgRxhBCwEhl9Yb6d+aVcLpcaNmlmdSm2RU5bw31o64mHIYWVl8PlL/+KjZSxY3mOaTK3LZMrovIZH8wA4MKR0xdm5W+/KisrS9Vq1LS6FFsio62RdWjL/zK6giTJk5agxO9Gyhkao4hOj8nhLLEXkOeqxC5N586dNWjQID3zzDOKi4vT8uXLdeONN2rbtm1asmSJbrrpJrndbm3fvl0tW7ZUy5YtdfjwYf3666+69dZbFR4erqRcTrU+WWBgoAIDA4toiQpeeESkLm7bLtdxjZs1V+NmzYu4Ivvrf89AvfvOW7rlxh4a+uQw7d2zR8OeHKL+9wxUbCxnNhSEzHWfyRkaK0doRcnpJ5O6X+7dS+UIqSBnzIkjhCY9Ud6U/51h4s2SOX5UnkPrJInL5YEiQEafW9+e1+uSy9qrXoMT26T582br848n6s4B96tcefs/aMIq5HThS57/mvxiaskvuprkCpDn6E6l/TlLrqhqCqjWSpIUHH+DkuY+r9RlHyigxsXK2r9eGX8vVViHMz+YAUDBIafPrV+vm9WseQs1aNxEZYLKaN2fa/Xum6+rYeMm6tKtu9Xl2RIZXfgSf3hF/uVqnzj70xUg99HtSlv7jfyiqyuweisZd4YSvxslb3qKIi6+S+6Efw5eOJz+8o8p+QcASmwTVJKGDx+uuLg4ff/99xo4cKCaNGmiRo0aqU2bNpIkj8ejfv366ejRo/Lz81O5cuU0adIkSdKDDz6oAQMGKDg4WJMnTz7r/UyAvIqKitLcefP16MODdcuNPRQWFqa+/fprxAujrC7NNpxhleU59KfMriWSMXIERcpVsYX8qrb1HaXyJG6Te9MM33u8CVvlTdgqSXK1f96SuoHShow+u9pxdfXFpx9q/7498nq9qlmrjp554RXd0X+Q1aXZGjld+PzKxSlj2zId/+MbGeOVK7ScgupeoTKNu8nhOpHT/hXqK+yKR5W2cprSNy+UMyRGoW3vUWDNiy2uHig9yOmza96ilb6e/oXeGveKvF6vqlarrl539tN9gx9VQECA1eXZEhld+PzLxyn97//Ks2amZLxyhpVXmfqdFNzkejlc/vKkHJT76A5JUuIPL+V4rzO0nMrd+q4FVRcshzHGWF1ESZGcnKyIiAit+fuAwsLCrS6nVKkUGWR1CaVOVOcXrC6hVDHudGUsHa2kpCSFh7N9AfIrO6NXbd1PRhexytFlrC6h1Kl6z1SrSyh1vJlpOjqlHzkNnKfsnN6y67DC+DdUpCKC/a0uodSpMehLq0soVbyZaTr00Z15yugSd09QAAAAAAAAAMgPmqAAAAAAAAAAbI0mKAAAAAAAAABbowkKAAAAAAAAwNZoggIAAAAAAACwNZqgAAAAAAAAAGyNJigAAAAAAAAAW6MJCgAAAAAAAMDWaIICAAAAAAAAsDWaoAAAAAAAAABsjSYoAAAAAAAAAFujCQoAAAAAAADA1miCAgAAAAAAALA1mqAAAAAAAAAAbI0mKAAAAAAAAABbowkKAAAAAAAAwNZoggIAAAAAAACwNZqgAAAAAAAAAGyNJigAAAAAAAAAW6MJCgAAAAAAAMDWaIICAAAAAAAAsDWaoAAAAAAAAABsjSYoAAAAAAAAAFujCQoAAAAAAADA1miCAgAAAAAAALA1mqAAAAAAAAAAbI0mKAAAAAAAAABbowkKAAAAAAAAwNZoggIAAAAAAACwNZqgAAAAAAAAAGyNJigAAAAAAAAAW6MJCgAAAAAAAMDWaIICAAAAAAAAsDWaoAAAAAAAAABsjSYoAAAAAAAAAFujCQoAAAAAAADA1miCAgAAAAAAALA1mqAAAAAAAAAAbI0mKAAAAAAAAABbowkKAAAAAAAAwNZoggIAAAAAAACwNT+rCyhJjDGSpNSUFIsrKX1CnJlWl1DqGHe61SWUKsadceK//9vOAMgfMto6yX5ZVpdQ6ngz06wuodQxWcdP/JecBs5L9r+dFHK6yDnc/laXUOqQ00XLm5n3jKYJmg/ZG+y2zeIsrgSAXaWkpCgiIsLqMoASJzujL29ex+JKANgZOQ2cn+ycvqhhTYsrAWBXecloh+FwZp55vV7t3btXYWFhcjgcVpeTL8nJyapatap27dql8PBwq8spFVjn1iip690Yo5SUFMXGxsrp5E4lQH6R0cgv1nvRK8nrnJwGLkxJzemSvN0qyVjvRa8kr/P8ZDRnguaD0+lUlSpVrC7jgoSHh5e4P+iSjnVujZK43jmzBDh/ZDTOF+u96JXUdU5OA+evpOd0Sd1ulXSs96JXUtd5XjOaw5gAAAAAAAAAbI0mKAAAAAAAAABbowlaSgQGBur//u//FBgYaHUppQbr3BqsdwAlDdsta7Deix7rHEBJw3bLGqz3olda1jkPRgIAAAAAAABga5wJCgAAAAAAAMDWaIICAAAAAAAAsDWaoAAAAAAAAABsjSYoUAx4vV6rSwAAALkgowEAKJ7IaOQXTVDAQh6PR5LkdDq1Z88erVu3zuKK7MsYI54DBwDIKzK66JDRAID8IKOLjt0ymiYocsjemKBouFwuSdK3336rrl276o8//rC4Inv65ZdftGfPHjkcDmVkZMjtdltdEgCcF3K66JDRRYOMBmAXZHTRIaOLhh0z2s/qAmC9LVu2aOnSperbt69cLpd+//13RUZGqmrVqgoICJAxRg6Hw+oybcHr9crhcMjhcMgYo/T0dHXs2FHly5fXxIkT1aJFC6tLtKUVK1bo9ddfV5MmTbRkyRJNmjRJsbGxVpcFAHlCThcNMtoaZDSAkoyMLhpktDXsmNE0QUu5rKwsLVy4UB9//LHq16+vr776StOmTVPz5s3VoEEDjRkzho12AfF6vXI6T5x8vXfvXkVFRalMmTLq0aOH3nnnHQUGBuaYBucv+94w2euyefPmGjp0qPbt26fJkyeX+A03gNKDnC4aZHTRIaMB2AUZXTTI6KJTGjKav5JS6vDhw3K73fL391fHjh11+eWX65lnnlHVqlW1Y8cODRo0SGvWrNHUqVMlyVb3gLCK0+lUQkKC7rrrLvXp00ePPfaY5s+fryeffFLR0dH65Zdf2HAXAGOMnE6nnE6n1q1bp7lz58rr9erBBx+Uw+FQlSpVuFQFQLFHThctMrpokNEA7ICMLlpkdNEoLRnNX0optGbNGk2YMEF79+7Vt99+q+3bt6t169bauHGjgoKCJEmtWrVS165d9eGHHyo9PZ0jWOfh1LA7fPiwbr/9drVp00bz58/X8uXL9eabb8oYo6FDh+rdd9/Vjh07LKrWPrLvVzJo0CDdfPPN2rt3r9q2bauXXnpJ6enpev311333kOELCYDiiJwufGS0NchoACUdGV34yGhrlJaMpglaChhjdOjQId177706evSomjVrpunTp6tz584aOXKk6tWrpw4dOqh37976+eef5fV6FR0drc6dO8vf31+jRo2yehFKlOynp50adtu2bdM111yjevXqqVu3bqpdu7befvttORwO9erVS4GBgXrllVdK9AaluJg4caJCQkK0bt063X333b4jVqNHj9bEiRO1du1avfXWW5o1axbrG4DlyOmiQ0Zbj4wGUJKQ0UWHjLZeachomqClgMPhULly5bRgwQK99957OnTokOrWrSun06l3331X1apVU2RkpLp06aKMjAxNnjxZklS9enX169dPl156qbULUAIYY5ScnKxBgwb5np72559/6o033tDSpUslScnJyXrsscf06quvavDgwZo2bZqqVq2qxYsXS5Lef/993XrrrRwpzKNTN7p//vmnPvnkExljtGbNGv3555967rnn9Nxzz6lTp056/vnn1blzZ/Xq1UtDhw7V1KlT1ahRI9Y3AMuR04WLjC56ZDQAuyCjCxcZXfRKe0Y7TElt3+KcPB6PXC6X3G63/Pz89N133+nRRx/V9OnTVb9+fQ0YMECRkZG6//77VaNGDR0/flwTJkzQl19+qc8//1yVKlWyehFKjOwbMTdr1kxdu3ZVkyZNNGLECHXs2FGff/655syZo0svvVQXX3yx2rVrp5dfflmSdP/992vt2rWaMmWKqlWrZvFSlAzZf9eneu+99zR9+nS9/PLLqlGjhp5//nlVr15dzZs31/r167V06VKNGTNGMTExSkhIUMWKFS2oHgD+QU4XDTK66JDRAOyCjC4aZHTRIaNP4ExQGzLGyOv1+v7Aszv011xzjerUqaNXXnlFkjRw4EAtX75cmzdvliQdOXJEjRo1Us+ePVWmTBlrii9htm3bpr/++st3I+ZPPvlEn3zyiRYtWqRFixZp/PjxGjBggN544w2lpaVpwoQJWrx4sW644QY1b95cfn5+mjt3LhvuPPB4PHrqqaf08MMPa8aMGXK73Zo2bZpWr14tSbrnnntUtWpVffHFF3K73Xrttdf04IMP6vLLL9fhw4e1Z88ehYWFKTAwsMRvuAGUbOR00SCjiw4ZDcAuyOiiQUYXHTL6FAa2tW7dOnPttdeaJ5980rz99tvGGGPWr19vqlevbubPn2+MMebJJ580t956q2nSpInp06ePOXjwoJUllzjfffed+de//mUWLlxo/vWvf5n09HTz8MMPm8aNG5s9e/YYY4xJTk42l156qfnggw+MMcakpaWZP/74w/z1119Wll6iTJo0yVxyySVmwIAB5qWXXjJVqlQx06ZNMy1atDAvv/yyOXr0qDHGmAULFphu3bqZWbNmGY/HY8aPH28aNGhg7rnnHnP48GGLlwIAciKnCxcZXTTIaAB2REYXLjK6aJDRp6MJahMej8cYY4zX6zUej8e8/vrrpmXLlubLL780c+fONQ6Hw6xYscIYY8wjjzxiunbtajwej0lLSzPff/+9+eijj6wsv8T4+++/zeDBg83rr79uFixYYObMmWMqVapkatWqZX788UdjjDEHDhwwNWvWNLNnz/b9XsaPH2+aNm3KBvs8HD582DgcDjN9+nTfsN69e5uXXnrJ/Pjjj6Zz585m6dKlxuv1GmOMueyyy8z1119vdu3aZVatWuX7uwcAK5HThY+MLnpkNAA7IKMLHxld9Mjo3HE5fAnn9XolyXcaucPhUGZmpqpVq6bFixfL399fo0ePVrNmzXTHHXdIksaMGaPly5dr4sSJKlOmjK688kr16dPHsmUoCYwxeuqpp3TttdeqXLly2r59u1577TX16dNHV111lSIjI9WpUydJUvny5TVgwAC99tprOnLkiCTp3nvv1fDhw1WrVi0rF6NEKlu2rB577DGtXLnS9/fevn17ZWZmqlOnTqpatapmzJihXbt2yev1qkaNGipbtqyysrIUHx+vli1bWrwEAEozcrrwkdHWIaMBlGRkdOEjo61DRueOByOVUNk3aM72ww8/6LvvvtN1112nxo0bKyYmRl988YXee+89jR07VvXq1VNYWJjGjRunQYMGadasWWrUqBEbkzz6+eefNWbMGH3xxRcKDQ2VJB08eFAtWrRQ//79deTIEbndbr377ru+99SqVUsDBw7UkCFDSuyT04qL48ePq3Hjxvr000+1cOFCDRs2TPHx8apfv74uueQSrVu3TuvXr9fBgwf18MMPa+DAgVaXDKCUI6eLDhltLTIaQElDRhcdMtpaZPTpaIKWMJmZmXrhhRfUpk0bdenSRWlpaXr00Ue1Y8cO3Xbbbfriiy8UFxenN998U7fccovat2+v+++/X4sWLdLw4cN1/PhxrVixgo1JPj311FM6duyY3nzzTWVkZMjf319Op1PTpk3T3XffrenTp2vo0KGaNm2a0tPTlZmZKZfLJT8/PzVu3Njq8m3h888/18CBA9WjRw8999xzcjgceuGFF7RkyRL16dNHbdu2VVxcnKpUqWJ1qQBKMXK66JHR1iOjAZQEZHTRI6OtR0bn5HfuSVCcBAQEaMeOHTp48KAuvvhiHThwQLVr19b777+vDz74QNu2bdPtt98uSWrdurVGjRqlDRs2aMmSJZowYYJtT2kubLt27VJgYKAk+TbcktS9e3e9/vrryszM1E033aRrrrlGERERGjFihK677jorS7adnj176uWXX1avXr1Uo0YNSdKECRP0008/KSgoSG3atLG2QAAQOW0FMtp6ZDSAkoCMLnpktPXI6Jw4E7QE2Lhxo+rXr+87bT81NVXdu3fX3Xffre3bt2vZsmU6cuSI6tSpo1deeUXly5fX3r17FRsbq6lTp2rz5s269957Vb58easXpcSaOXOmnn32WX399deqWbOm0tPTFRQUpL///lvXXnutZs2apbi4OP38889q166d1eXa1u+//6777rtP06dPV+XKlWWM4UgsAMuR09Yio4sHMhpAcURGW4uMLh7I6H/wYKRi7uDBg2rfvr02b97su2/Jnj17tGHDBn3zzTcqX7685s+fr5EjR+rDDz9U+fLlNXfuXL322ms6evSoevbsqeHDh7PRvkAXX3yxGjVqpCeeeEKSFBQUJElavHix2rRpo9jYWEliw13IWrRooQoVKmjLli2SVGo33ACKD3LaemR08UBGAyhuyGjrkdHFAxn9D84ELQGGDh2qsLAw9evXT88995zWr1+ve+65R9OmTVOvXr00ceJERUVF6aKLLtLWrVu1du1aPf744+rZs6fVpdvKhg0bdM0116hBgwbq2LGjFixYoLS0NL3yyiu6+OKLrS6v1PB4PHK5XFaXAQA+5LT1yOjigYwGUNyQ0dYjo4sHMvoEmqAlwPHjx1W3bl2VKVNGd9xxh5566im5XC59/vnnmjFjhvr06SOv16sVK1YoNDTUd5QFBW/Tpk1avXq11q5dqxo1amjAgAFWlwQAsBg5XTyQ0QCAU5HRxQMZjeKCJmgJ8eWXX2rixImaM2eOJPnu4XDdddepRo0aGjdunJxOZ6k+rRkAAKuQ0wAAFE9kNIBsNEFLCGOMmjdvrmHDhumWW27xbbjXrVsnt9utZs2aWV0iAAClFjkNAEDxREYDyEYTtARZuXKlBg0apG+++UYVKlSwuhwAAHASchoAgOKJjAYg8XT4EuWiiy5ShQoVtGHDBqtLAQAApyCnAQAonshoABJngpY4PNELAIDii5wGAKB4IqMB0AQFAAAAAAAAYGtcDg8AAAAAAADA1miCAgAAAAAAALA1mqAAAAAAAAAAbI0mKAAAAAAAAABbowkKAAAAAAAAwNZoggLFSN++fdWjRw+rywAAAKcgowEAKL7IaeQFTVAgD/r27SuHwyGHw6GAgADFxcXp+eefl9vttro0AABKNTIaAIDii5xGceJndQFASXHNNddo0qRJysjI0Jw5c3T//ffL399fTz31VI7pMjMzFRAQYFGVAACUPmQ0AADFFzmN4oIzQYE8CgwMVMWKFVW9enUNGjRInTt31jfffOM77X7UqFGKjY1VvXr1JEm7du3SLbfcosjISEVHR6t79+7avn27b34ej0ePPvqoIiMjVbZsWQ0dOlTGGIuWDgCAkouMBgCg+CKnUVzQBAXOU5kyZZSZmSlJmj9/vjZt2qQffvhB3377rbKysnT11VcrLCxMixcv1tKlSxUaGqprrrnG957XXntNkydP1sSJE7VkyRIdPXpUM2bMsHKRAACwBTIaAIDii5yGVbgcHsgnY4zmz5+vefPmafDgwTp06JBCQkI0YcIE36n7n3zyibxeryZMmCCHwyFJmjRpkiIjI7Vo0SJdddVVGjdunJ566indcMMNkqTx48dr3rx5li0XAAAlHRkNAEDxRU7DajRBgTz69ttvFRoaqqysLHm9Xt1+++167rnndP/996tJkyY57l2yZs0abd26VWFhYTnmkZ6err/++ktJSUnat2+f2rRp4xvn5+enli1bcho/AAD5REYDAFB8kdMoLmiCAnnUsWNH/fvf/1ZAQIBiY2Pl5/fPP5+QkJAc06ampqpFixaaMmXKafMpV65codcKAEBpQkYDAFB8kdMoLmiCAnkUEhKiuLi4PE170UUXaerUqSpfvrzCw8NznaZSpUpavny52rVrJ0lyu936/fffddFFFxVYzQAAlAZkNAAAxRc5jeKCByMBhaBXr16KiYlR9+7dtXjxYm3btk2LFi3Sgw8+qN27d0uSHnroIb344ouaOXOmNm7cqPvuu0+JiYnWFg4AgM2R0QAAFF/kNAoTTVCgEAQHB+vnn39WtWrVdMMNN6hBgwa6++67lZ6e7jua9dhjj6lPnz668847dckllygsLEz/+te/LK4cAAB7I6MBACi+yGkUJofhzrEAAAAAAAAAbIwzQQEAAAAAAADYGk1QAAAAAAAAALZGExQAAAAAAACArdEEBQAAAAAAAGBrNEEBAAAAAAAA2BpNUAAAAAAAAAC2RhMUAAAAAAAAgK3RBAUAAAAAAABgazRBAQAAAAAAANgaTVAAAAAAAAAAtkYTFAAAAAAAAICt0QQFAAAAAAAAYGv/D8OlyGeR37CuAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# %% [code]\n",
        "# ====== Confusion matrices so sánh ======\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "titles_preds = [\n",
        "    (\"Equal Avg (1/3 each)\", np.argmax((logits_rgb_val + logits_ms_val + logits_hs_val)/3, axis=1)),\n",
        "    (f\"Manual (RGB={W_RGB}, MS={W_MS}, HS={W_HS})\", np.argmax(W_RGB*logits_rgb_val + W_MS*logits_ms_val + W_HS*logits_hs_val, axis=1)),\n",
        "    (f\"Grid Best (RGB={BEST_W_RGB}, MS={BEST_W_MS}, HS={BEST_W_HS})\", p_fus_best),\n",
        "]\n",
        "\n",
        "for ax, (title, preds) in zip(axes, titles_preds):\n",
        "    cm = confusion_matrix(y_true, preds)\n",
        "    f1m = f1_score(y_true, preds, average=\"macro\")\n",
        "    ax.imshow(cm, cmap=\"Blues\")\n",
        "    ax.set_title(f\"{title}\\nF1={f1m:.4f}\", fontsize=9)\n",
        "    ax.set_xticks(range(len(CLASSES)))\n",
        "    ax.set_xticklabels(CLASSES, rotation=30, fontsize=8)\n",
        "    ax.set_yticks(range(len(CLASSES)))\n",
        "    ax.set_yticklabels(CLASSES, fontsize=8)\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\", fontsize=11)\n",
        "    ax.set_xlabel(\"Pred\")\n",
        "    ax.set_ylabel(\"True\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "29f344ba",
      "metadata": {
        "id": "29f344ba",
        "outputId": "6cfa4264-51f2-4a12-c287-1b4c1a026b60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test files: RGB=300, MS=300, HS=300\n",
            "Test intersection keys (RGB∩MS∩HS): 300\n"
          ]
        }
      ],
      "source": [
        "# %% [code]\n",
        "# ====== KAGGLE SUBMISSION: Late Fusion (RGB + MS + HS) ======\n",
        "\n",
        "# --- List test files ---\n",
        "test_rgb_files = sorted([f for f in os.listdir(TEST_RGB_DIR) if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))])\n",
        "test_ms_files  = sorted([f for f in os.listdir(TEST_MS_DIR)  if f.lower().endswith((\".tif\", \".tiff\"))])\n",
        "test_hs_files  = sorted([f for f in os.listdir(TEST_HS_DIR)  if f.lower().endswith((\".tif\", \".tiff\"))])\n",
        "\n",
        "test_rgb_map = {key_from_filename(f): f for f in test_rgb_files}\n",
        "test_ms_map  = {key_from_filename(f): f for f in test_ms_files}\n",
        "test_hs_map  = {key_from_filename(f): f for f in test_hs_files}\n",
        "\n",
        "test_keys = sorted(set(test_rgb_map.keys()) & set(test_ms_map.keys()) & set(test_hs_map.keys()))\n",
        "print(f\"Test files: RGB={len(test_rgb_files)}, MS={len(test_ms_files)}, HS={len(test_hs_files)}\")\n",
        "print(f\"Test intersection keys (RGB∩MS∩HS): {len(test_keys)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "99309a29",
      "metadata": {
        "id": "99309a29",
        "outputId": "b3d9be36-14dc-4493-b2ff-c8356ebe24ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test dataset: 300 samples\n"
          ]
        }
      ],
      "source": [
        "# %% [code]\n",
        "# --- Test Dataset (không có label) ---\n",
        "class TestFusionDataset(Dataset):\n",
        "    def __init__(self, keys, rgb_dir, ms_dir, hs_dir, rgb_map, ms_map, hs_map,\n",
        "                 img_size=IMG_SIZE, hs_img_size=IMG_SIZE,\n",
        "                 ms_mean=None, ms_std=None,\n",
        "                 hs_global_mean=None, hs_global_std=None,\n",
        "                 hs_selected_bands=None):\n",
        "        self.keys = keys\n",
        "        self.rgb_dir = rgb_dir\n",
        "        self.ms_dir = ms_dir\n",
        "        self.hs_dir = hs_dir\n",
        "        self.rgb_map = rgb_map\n",
        "        self.ms_map = ms_map\n",
        "        self.hs_map = hs_map\n",
        "        self.img_size = img_size\n",
        "        self.hs_img_size = hs_img_size\n",
        "        self.ms_mean = ms_mean\n",
        "        self.ms_std = ms_std\n",
        "        self.hs_global_mean = hs_global_mean\n",
        "        self.hs_global_std = hs_global_std\n",
        "        self.hs_selected_bands = hs_selected_bands\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.keys)\n",
        "\n",
        "    def load_rgb(self, path):\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        img = img.resize((self.img_size, self.img_size), resample=Image.BILINEAR)\n",
        "        arr = np.array(img, dtype=np.float32) / 255.0\n",
        "        x = arr.transpose(2,0,1)\n",
        "        x = normalize_chw(x, RGB_MEAN, RGB_STD)\n",
        "        return x\n",
        "\n",
        "    def load_ms(self, path):\n",
        "        arr = tiff.imread(path)\n",
        "        if arr.ndim == 2:\n",
        "            arr = arr[None, :, :]\n",
        "        elif arr.ndim == 3:\n",
        "            if arr.shape[0] != 5 and arr.shape[-1] == 5:\n",
        "                arr = np.transpose(arr, (2,0,1))\n",
        "        else:\n",
        "            raise ValueError(f\"MS tif shape not supported: {arr.shape} | {path}\")\n",
        "        arr = arr.astype(np.float32) / 65535.0\n",
        "        arr = resize_np_chw(arr, self.img_size)\n",
        "        if self.ms_mean is not None and self.ms_std is not None:\n",
        "            arr = normalize_chw(arr, self.ms_mean, self.ms_std)\n",
        "        return arr\n",
        "\n",
        "    def load_hs(self, path):\n",
        "        \"\"\"Load HS theo pipeline TopK: 125 bands → resize → clip → Z-score → select 20 bands.\"\"\"\n",
        "        arr = tiff.imread(path).astype(np.float32)\n",
        "        arr = ensure_chw_hs(arr)\n",
        "        arr = fix_bands_125(arr)\n",
        "\n",
        "        arr = resize_np_chw(arr, self.hs_img_size)\n",
        "\n",
        "        x = torch.from_numpy(arr)\n",
        "        x = clip_per_band(x, ql=0.01, qh=0.99)\n",
        "        arr = x.numpy()\n",
        "\n",
        "        if self.hs_global_mean is not None and self.hs_global_std is not None:\n",
        "            arr = normalize_chw(arr, self.hs_global_mean, self.hs_global_std)\n",
        "\n",
        "        if self.hs_selected_bands is not None:\n",
        "            arr = arr[self.hs_selected_bands]  # (20, 64, 64)\n",
        "\n",
        "        return arr\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        k = self.keys[idx]\n",
        "        x_rgb = self.load_rgb(os.path.join(self.rgb_dir, self.rgb_map[k]))\n",
        "        x_ms  = self.load_ms(os.path.join(self.ms_dir,  self.ms_map[k]))\n",
        "        x_hs  = self.load_hs(os.path.join(self.hs_dir,  self.hs_map[k]))\n",
        "        return (\n",
        "            torch.from_numpy(x_rgb).float(),\n",
        "            torch.from_numpy(x_ms).float(),\n",
        "            torch.from_numpy(x_hs).float(),\n",
        "            k\n",
        "        )\n",
        "\n",
        "test_ds = TestFusionDataset(\n",
        "    keys=test_keys,\n",
        "    rgb_dir=TEST_RGB_DIR, ms_dir=TEST_MS_DIR, hs_dir=TEST_HS_DIR,\n",
        "    rgb_map=test_rgb_map, ms_map=test_ms_map, hs_map=test_hs_map,\n",
        "    img_size=IMG_SIZE,\n",
        "    hs_img_size=HS_IMG_SIZE,\n",
        "    ms_mean=MS_MEAN, ms_std=MS_STD,\n",
        "    hs_global_mean=HS_GLOBAL_MEAN,\n",
        "    hs_global_std=HS_GLOBAL_STD,\n",
        "    hs_selected_bands=HS_SELECTED_BANDS\n",
        ")\n",
        "\n",
        "def test_collate_fn(batch):\n",
        "    x_rgb_list, x_ms_list, x_hs_list, k_list = [], [], [], []\n",
        "    for rgb, ms, hs, k in batch:\n",
        "        x_rgb_list.append(rgb)\n",
        "        x_ms_list.append(ms)\n",
        "        x_hs_list.append(hs)\n",
        "        k_list.append(k)\n",
        "    return torch.stack(x_rgb_list), torch.stack(x_ms_list), torch.stack(x_hs_list), k_list\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True,\n",
        "    collate_fn=test_collate_fn\n",
        ")\n",
        "\n",
        "print(f\"Test dataset: {len(test_ds)} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "8162ab42",
      "metadata": {
        "id": "8162ab42",
        "outputId": "8c933b8a-329f-4d8a-fcf2-ea6b740a73b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using BEST weights: RGB=0.45, MS=0.55, HS=0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1033403914.py:22: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  img = Image.fromarray(x_chw[c].astype(np.float32), mode=\"F\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: 300 samples\n",
            "Distribution: {'Health': 126, 'Other': 87, 'Rust': 87}\n"
          ]
        }
      ],
      "source": [
        "# %% [code]\n",
        "# --- Inference trên test set với BEST WEIGHTS ---\n",
        "@torch.no_grad()\n",
        "def predict_fusion(loader, model_rgb, model_ms, model_hs, device,\n",
        "                   w_rgb=0.3, w_ms=0.5, w_hs=0.2):\n",
        "    all_keys = []\n",
        "    all_preds = []\n",
        "\n",
        "    model_rgb.eval()\n",
        "    model_ms.eval()\n",
        "    model_hs.eval()\n",
        "\n",
        "    for x_rgb, x_ms, x_hs, keys in loader:\n",
        "        x_rgb = x_rgb.to(device, non_blocking=True)\n",
        "        x_ms  = x_ms.to(device, non_blocking=True)\n",
        "        x_hs  = x_hs.to(device, non_blocking=True)\n",
        "\n",
        "        logits_rgb = model_rgb(x_rgb)\n",
        "        logits_ms  = model_ms(x_ms)\n",
        "        logits_hs  = model_hs(x_hs)\n",
        "\n",
        "        # Weighted late fusion\n",
        "        logits_fus = w_rgb * logits_rgb + w_ms * logits_ms + w_hs * logits_hs\n",
        "        preds = torch.argmax(logits_fus, dim=1).cpu().numpy()\n",
        "\n",
        "        all_keys.extend(keys)\n",
        "        all_preds.extend(preds)\n",
        "\n",
        "    return all_keys, np.array(all_preds)\n",
        "\n",
        "# Dùng trọng số tối ưu từ grid search\n",
        "print(f\"Using BEST weights: RGB={BEST_W_RGB}, MS={BEST_W_MS}, HS={BEST_W_HS}\")\n",
        "\n",
        "test_keys_out, test_preds = predict_fusion(\n",
        "    test_loader, model_rgb, model_ms, model_hs, DEVICE,\n",
        "    w_rgb=BEST_W_RGB, w_ms=BEST_W_MS, w_hs=BEST_W_HS\n",
        ")\n",
        "print(f\"Predictions: {len(test_preds)} samples\")\n",
        "print(f\"Distribution: { {c: int((test_preds==i).sum()) for c,i in CLASS_TO_IDX.items()} }\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "9107014c",
      "metadata": {
        "id": "9107014c",
        "outputId": "e2b6b8de-96fa-40be-e8c5-c73af94e279b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission saved to: /content/AI-for-Agriculture-2026/notebooks/LateFusion/submission_latefusion_best_rgb_resnet18_224_best_ms_resnet18_224_best_hs_topK20_resnet18_224.csv\n",
            "Total rows: 300\n",
            "\n",
            "Distribution:\n",
            "Category\n",
            "Health    126\n",
            "Other      87\n",
            "Rust       87\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Head:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Id Category\n",
              "0  val_000a83c1.tif   Health\n",
              "1  val_00a704b1.tif    Other\n",
              "2  val_01dde030.tif    Other\n",
              "3  val_024df365.tif   Health\n",
              "4  val_02afcb0e.tif     Rust\n",
              "5  val_03864ba6.tif   Health\n",
              "6  val_0537e324.tif     Rust\n",
              "7  val_059983e0.tif     Rust\n",
              "8  val_05cee914.tif    Other\n",
              "9  val_07af871a.tif     Rust"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81df941a-3abd-419a-8d9e-526f55b7bf0b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>val_000a83c1.tif</td>\n",
              "      <td>Health</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>val_00a704b1.tif</td>\n",
              "      <td>Other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>val_01dde030.tif</td>\n",
              "      <td>Other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>val_024df365.tif</td>\n",
              "      <td>Health</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>val_02afcb0e.tif</td>\n",
              "      <td>Rust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>val_03864ba6.tif</td>\n",
              "      <td>Health</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>val_0537e324.tif</td>\n",
              "      <td>Rust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>val_059983e0.tif</td>\n",
              "      <td>Rust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>val_05cee914.tif</td>\n",
              "      <td>Other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>val_07af871a.tif</td>\n",
              "      <td>Rust</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81df941a-3abd-419a-8d9e-526f55b7bf0b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-81df941a-3abd-419a-8d9e-526f55b7bf0b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-81df941a-3abd-419a-8d9e-526f55b7bf0b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "sub_df",
              "summary": "{\n  \"name\": \"sub_df\",\n  \"rows\": 300,\n  \"fields\": [\n    {\n      \"column\": \"Id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 300,\n        \"samples\": [\n          \"val_b826d518.tif\",\n          \"val_e9ce960f.tif\",\n          \"val_94d72cf9.tif\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Health\",\n          \"Other\",\n          \"Rust\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# %% [code]\n",
        "# --- Tạo file submission CSV ---\n",
        "# Format Kaggle: columns = [\"Id\", \"Category\"]\n",
        "# Id = filename .tif (ưu tiên HS/MS), Category = Health/Rust/Other\n",
        "\n",
        "submission_rows = []\n",
        "for k, pred_idx in zip(test_keys_out, test_preds):\n",
        "    # Lấy filename .tif từ HS hoặc MS (Kaggle dùng .tif)\n",
        "    if k in test_hs_map:\n",
        "        file_id = test_hs_map[k]\n",
        "    elif k in test_ms_map:\n",
        "        file_id = test_ms_map[k]\n",
        "    else:\n",
        "        file_id = test_rgb_map[k]\n",
        "\n",
        "    label = IDX_TO_CLASS[int(pred_idx)]\n",
        "    submission_rows.append({\"Id\": file_id, \"Category\": label})\n",
        "\n",
        "sub_df = pd.DataFrame(submission_rows)\n",
        "sub_df = sub_df.sort_values(\"Id\").reset_index(drop=True)\n",
        "sub_df.to_csv(OUT_SUB_PATH, index=False)\n",
        "\n",
        "print(f\"Submission saved to: {OUT_SUB_PATH}\")\n",
        "print(f\"Total rows: {len(sub_df)}\")\n",
        "print(f\"\\nDistribution:\")\n",
        "print(sub_df[\"Category\"].value_counts())\n",
        "print(f\"\\nHead:\")\n",
        "sub_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Push to GitHub"
      ],
      "metadata": {
        "id": "gGoSc-PL83Sk"
      },
      "id": "gGoSc-PL83Sk"
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --list"
      ],
      "metadata": {
        "id": "f3wmlTyY826F",
        "outputId": "4bca2566-630e-41ab-a4ec-5495941e9e0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "f3wmlTyY826F",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filter.lfs.clean=git-lfs clean -- %f\n",
            "filter.lfs.smudge=git-lfs smudge -- %f\n",
            "filter.lfs.process=git-lfs filter-process\n",
            "filter.lfs.required=true\n",
            "user.name=doduyquy\n",
            "user.email=doduyquy211@gmail.com\n",
            "core.repositoryformatversion=0\n",
            "core.filemode=true\n",
            "core.bare=false\n",
            "core.logallrefupdates=true\n",
            "remote.origin.url=https://github.com/doduyquy/AI-for-Agriculture-2026.git\n",
            "remote.origin.fetch=+refs/heads/*:refs/remotes/origin/*\n",
            "branch.HongPhuc.remote=origin\n",
            "branch.HongPhuc.merge=refs/heads/HongPhuc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "push_msg = f\"latefusion: {submission_fn}\"\n",
        "\n",
        "!git add /content/AI-for-Agriculture-2026/checkpoints/ /content/AI-for-Agriculture-2026/notebooks/LateFusion/submission_latefusion_best_rgb_resnet18_224_best_ms_resnet18_224_best_hs_topK20_resnet18_224.csv\n",
        "!git commit -m \"{push_msg}\"\n",
        "!git push https://doduyquy:${GITHUB_TOKEN}@github.com/doduyquy/AI-for-Agriculture-2026.git HongPhuc\n",
        "print(f\"Push to github successfully with message: {push_msg}\")\n"
      ],
      "metadata": {
        "id": "z7G8x7ox88RC",
        "outputId": "50ecb937-7e4f-4b72-fe7c-cf5ea02cbf64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "z7G8x7ox88RC",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HongPhuc d35acd2] latefusion: submission_latefusion_best_rgb_resnet18_224_best_ms_resnet18_224_best_hs_topK20_resnet18_224.csv\n",
            " 1 file changed, 301 insertions(+)\n",
            " create mode 100644 notebooks/LateFusion/submission_latefusion_best_rgb_resnet18_224_best_ms_resnet18_224_best_hs_topK20_resnet18_224.csv\n",
            "Enumerating objects: 8, done.\n",
            "Counting objects: 100% (8/8), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (5/5), done.\n",
            "Writing objects: 100% (5/5), 2.48 KiB | 2.48 MiB/s, done.\n",
            "Total 5 (delta 1), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
            "To https://github.com/doduyquy/AI-for-Agriculture-2026.git\n",
            "   feaf8da..d35acd2  HongPhuc -> HongPhuc\n",
            "Push to github successfully with message: latefusion: submission_latefusion_best_rgb_resnet18_224_best_ms_resnet18_224_best_hs_topK20_resnet18_224.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### The end"
      ],
      "metadata": {
        "id": "pVR3QNLm8Trp"
      },
      "id": "pVR3QNLm8Trp"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}