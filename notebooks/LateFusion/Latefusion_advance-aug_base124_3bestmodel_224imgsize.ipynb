{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Late fusion: RGB + MS + HS"
      ],
      "metadata": {
        "id": "ZHxNqJ75yAhf"
      },
      "id": "ZHxNqJ75yAhf"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cb1d117d",
      "metadata": {
        "id": "cb1d117d"
      },
      "outputs": [],
      "source": [
        "# %% [code]\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from PIL import Image\n",
        "import tifffile as tiff\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to GitHub"
      ],
      "metadata": {
        "id": "iH3hvMh61Nb5"
      },
      "id": "iH3hvMh61Nb5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Clone repo (branch: HongPhuc)"
      ],
      "metadata": {
        "id": "593L3ivg1h4Y"
      },
      "id": "593L3ivg1h4Y"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b HongPhuc https://github.com/doduyquy/AI-for-Agriculture-2026.git\n",
        "\n",
        "# move to AI-for-Agriculture-2026 directory\n",
        "%cd AI-for-Agriculture-2026\n",
        "\n",
        "!git branch # check current branch\n",
        "\n",
        "\n",
        "print(\"[OK] Clone repo successfully\")"
      ],
      "metadata": {
        "id": "aMxU5HwC1Tou",
        "outputId": "93fdfd52-2497-4fc8-c261-ab75538b7488",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "aMxU5HwC1Tou",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AI-for-Agriculture-2026'...\n",
            "remote: Enumerating objects: 3159, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 3159 (delta 13), reused 5 (delta 5), pack-reused 3136 (from 6)\u001b[K\n",
            "Receiving objects: 100% (3159/3159), 816.72 MiB | 30.56 MiB/s, done.\n",
            "Resolving deltas: 100% (115/115), done.\n",
            "Updating files: 100% (3053/3053), done.\n",
            "/content/AI-for-Agriculture-2026\n",
            "* \u001b[32mHongPhuc\u001b[m\n",
            "[OK] Clone repo successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Config git user"
      ],
      "metadata": {
        "id": "uxyge_qY1jfC"
      },
      "id": "uxyge_qY1jfC"
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name \"doduyquy\"\n",
        "!git config --global user.email \"doduyquy211@gmail.com\""
      ],
      "metadata": {
        "id": "bWI8JfbB1kxz"
      },
      "id": "bWI8JfbB1kxz",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***!!! WARNING !!!***"
      ],
      "metadata": {
        "id": "I-lqInUZ1jcP"
      },
      "id": "I-lqInUZ1jcP"
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GITHUB_TOKEN\"] = \"\""
      ],
      "metadata": {
        "id": "j6R-Dc9d1p7D"
      },
      "id": "j6R-Dc9d1p7D",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config"
      ],
      "metadata": {
        "id": "IjE9JvsB1u8n"
      },
      "id": "IjE9JvsB1u8n"
    },
    {
      "cell_type": "code",
      "source": [
        "# print working dir\n",
        "!pwd"
      ],
      "metadata": {
        "id": "rO7OyeSI15cm",
        "outputId": "9ce62071-0e25-4a50-c837-4c0ffbf0dcfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "rO7OyeSI15cm",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AI-for-Agriculture-2026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "current_challenge_dir= Path.cwd()\n",
        "notebooks_dir = current_challenge_dir.resolve() / \"notebooks\"\n",
        "checkpoint_dir = current_challenge_dir / 'checkpoints'\n",
        "\n",
        "ROOT_DATASET_TRAIN = current_challenge_dir.resolve() / 'data' / 'raw' / 'train'\n",
        "RGB_DIR = ROOT_DATASET_TRAIN / \"RGB\"\n",
        "MS_DIR  = ROOT_DATASET_TRAIN / \"MS\"\n",
        "HS_DIR  = ROOT_DATASET_TRAIN / \"HS\"\n",
        "\n",
        "\n",
        "SPLIT_DIR = notebooks_dir / 'split' / 'splits'\n",
        "VAL_IDX_PATH = SPLIT_DIR / 'val_idx.npy'\n",
        "TRAIN_IDX_FILE = SPLIT_DIR / \"train_idx.npy\"\n",
        "\n",
        "\n",
        "CKPT_069 = checkpoint_dir / '069_kaggle'\n",
        "# CKPT_RGB = CKPT_069 / 'best_rgb_resnet18_224.pth'\n",
        "# CKPT_RGB = checkpoint_dir / 'rgb_resnet18_aug-v5_full_combo_img224_batch8_epoch20_lr0.0001.pth'\n",
        "CKPT_RGB = checkpoint_dir / \"rgb_resnet18_aug-v5_base124_img224_batch8_epoch20_lr0.0001.pth\"\n",
        "CKPT_MS  = CKPT_069 / 'best_ms_resnet18_224.pth'\n",
        "CKPT_HS  = CKPT_069 / 'best_hs_topK20_resnet18_224.pth'\n",
        "\n",
        "ROOT_DATASET_VAL = current_challenge_dir.resolve() / 'data' / 'raw' / 'val'\n",
        "TEST_RGB_DIR = os.path.join(ROOT_DATASET_VAL, \"RGB\")\n",
        "TEST_MS_DIR  = os.path.join(ROOT_DATASET_VAL, \"MS\")\n",
        "TEST_HS_DIR  = os.path.join(ROOT_DATASET_VAL, \"HS\")\n",
        "\n",
        "OUT_SUB_DIR = notebooks_dir / 'LateFusion'\n",
        "\n",
        "\n",
        "# Check\n",
        "print(f\"Val idx: {VAL_IDX_PATH}\")\n",
        "print(f\"Checkpoint RGB: {CKPT_RGB}\")\n",
        "print(f\"Checkpoint MS: {CKPT_MS}\")\n",
        "print(f\"Checkpoint HS: {CKPT_HS}\")\n",
        "print(f\"Training data RGB: {RGB_DIR}\")\n",
        "print(f\"Testing data MS: {TEST_MS_DIR}\")\n",
        "print(f\"Train split idx file: {TRAIN_IDX_FILE}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "8j2zc9SkyI8h",
        "outputId": "ebb85d38-fe5e-4480-eb60-bcd11d659d2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8j2zc9SkyI8h",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val idx: /content/AI-for-Agriculture-2026/notebooks/split/splits/val_idx.npy\n",
            "Checkpoint RGB: /content/AI-for-Agriculture-2026/checkpoints/rgb_resnet18_aug-v5_base124_img224_batch8_epoch20_lr0.0001.pth\n",
            "Checkpoint MS: /content/AI-for-Agriculture-2026/checkpoints/069_kaggle/best_ms_resnet18_224.pth\n",
            "Checkpoint HS: /content/AI-for-Agriculture-2026/checkpoints/069_kaggle/best_hs_topK20_resnet18_224.pth\n",
            "Training data RGB: /content/AI-for-Agriculture-2026/data/raw/train/RGB\n",
            "Testing data MS: /content/AI-for-Agriculture-2026/data/raw/val/MS\n",
            "Train split idx file: /content/AI-for-Agriculture-2026/notebooks/split/splits/train_idx.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get checkpoint file name (without extension)\n",
        "ckpt_rgb_fn = Path(CKPT_RGB).stem\n",
        "ckpt_ms_fn = Path(CKPT_MS).stem\n",
        "ckpt_hs_fn = Path(CKPT_HS).stem\n",
        "\n",
        "submission_fn = f\"submission_latefusion_{ckpt_rgb_fn}_{ckpt_ms_fn}_{ckpt_hs_fn}.csv\"\n",
        "\n",
        "print(f\"Submission file name: {submission_fn}\")"
      ],
      "metadata": {
        "id": "lt7DfjPO7f3J",
        "outputId": "a050aa96-2f9a-46f4-cf48-cdd946b6efd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "lt7DfjPO7f3J",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file name: submission_latefusion_rgb_resnet18_aug-v5_base124_img224_batch8_epoch20_lr0.0001_best_ms_resnet18_224_best_hs_topK20_resnet18_224.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUT_SUB_PATH = OUT_SUB_DIR / submission_fn\n",
        "print(f\"Submission path: {OUT_SUB_PATH}\")"
      ],
      "metadata": {
        "id": "QlJHFB_X7YMP",
        "outputId": "dec0f903-95d3-43b0-bb9f-0ba7d0ffad36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "QlJHFB_X7YMP",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission path: /content/AI-for-Agriculture-2026/notebooks/LateFusion/submission_latefusion_rgb_resnet18_aug-v5_base124_img224_batch8_epoch20_lr0.0001_best_ms_resnet18_224_best_hs_topK20_resnet18_224.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cf7e5b55",
      "metadata": {
        "id": "cf7e5b55",
        "outputId": "dd00b41a-f624-4577-9e19-503e6e4669ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE: cuda\n"
          ]
        }
      ],
      "source": [
        "# %% [code]\n",
        "# ====== CONFIG ======\n",
        "\n",
        "IMG_SIZE = 224     # phải giống baseline bạn train (nếu baseline dùng 64)\n",
        "BATCH_SIZE = 8\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "CLASSES = [\"Health\", \"Other\", \"Rust\"]\n",
        "CLASS_TO_IDX = {c:i for i,c in enumerate(CLASSES)}\n",
        "IDX_TO_CLASS = {i:c for c,i in CLASS_TO_IDX.items()}\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def seed_everything(seed=1):\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(1)\n",
        "\n",
        "print(\"DEVICE:\", DEVICE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3861b923",
      "metadata": {
        "id": "3861b923"
      },
      "outputs": [],
      "source": [
        "# %% [code]\n",
        "def label_from_filename(fname: str) -> str:\n",
        "    # lấy prefix class theo list CLASSES\n",
        "    for c in CLASSES:\n",
        "        if fname.lower().startswith(c.lower()):\n",
        "            return c\n",
        "    raise ValueError(f\"Cannot parse label from filename: {fname}\")\n",
        "\n",
        "def key_from_filename(fname: str) -> str:\n",
        "    # bỏ extension + normalize\n",
        "    base = os.path.splitext(fname)[0]\n",
        "    return base.strip().lower()\n",
        "\n",
        "def resize_np_chw(x_chw: np.ndarray, out_hw: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    x_chw: (C,H,W) float32\n",
        "    Resize theo từng channel bằng PIL (bilinear) để đơn giản và ổn định.\n",
        "    \"\"\"\n",
        "    C, H, W = x_chw.shape\n",
        "    out = np.empty((C, out_hw, out_hw), dtype=np.float32)\n",
        "    for c in range(C):\n",
        "        img = Image.fromarray(x_chw[c].astype(np.float32), mode=\"F\")\n",
        "        img = img.resize((out_hw, out_hw), resample=Image.BILINEAR)\n",
        "        out[c] = np.array(img, dtype=np.float32)\n",
        "    return out\n",
        "\n",
        "def normalize_chw(x_chw: np.ndarray, mean: np.ndarray, std: np.ndarray) -> np.ndarray:\n",
        "    # mean,std: shape (C,)\n",
        "    return (x_chw - mean[:, None, None]) / (std[:, None, None] + 1e-6)\n",
        "\n",
        "def clip_per_band(x: torch.Tensor, ql=0.01, qh=0.99) -> torch.Tensor:\n",
        "    \"\"\"Clip mỗi band theo quantile q1/q99. Input/output: (C, H, W).\"\"\"\n",
        "    C = x.shape[0]\n",
        "    flat = x.view(C, -1)\n",
        "    lo = torch.quantile(flat, ql, dim=1).view(-1, 1, 1)\n",
        "    hi = torch.quantile(flat, qh, dim=1).view(-1, 1, 1)\n",
        "    return torch.clamp(x, lo, hi)\n",
        "\n",
        "def ensure_chw_hs(arr):\n",
        "    \"\"\"Đảm bảo HS array có shape (C, H, W) với C=125.\"\"\"\n",
        "    if arr.ndim == 2:\n",
        "        return arr[None, :, :]\n",
        "    if arr.ndim == 3:\n",
        "        if arr.shape[0] in (125, 126):\n",
        "            return arr\n",
        "        if arr.shape[-1] in (125, 126):\n",
        "            return np.transpose(arr, (2, 0, 1))\n",
        "        band_axis = np.argmax(arr.shape)\n",
        "        if band_axis == 2:\n",
        "            return np.transpose(arr, (2, 0, 1))\n",
        "    return arr\n",
        "\n",
        "def fix_bands_125(arr):\n",
        "    \"\"\"Đảm bảo đúng 125 bands.\"\"\"\n",
        "    if arr.shape[0] > 125:\n",
        "        arr = arr[:125]\n",
        "    elif arr.shape[0] < 125:\n",
        "        pad = 125 - arr.shape[0]\n",
        "        arr = np.pad(arr, ((0, pad), (0, 0), (0, 0)), mode=\"edge\")\n",
        "    return arr\n",
        "\n",
        "# ====== NORMALIZATION STATS ======\n",
        "RGB_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
        "RGB_STD  = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
        "\n",
        "# MS: global mean/std computed on TRAIN split after dividing by 65535\n",
        "MS_MEAN = np.array([0.00651217, 0.01202489, 0.01260268, 0.03442739, 0.04236133], dtype=np.float32)\n",
        "MS_STD  = np.array([0.00558527, 0.00672570, 0.00985042, 0.01149776, 0.01547735], dtype=np.float32)\n",
        "\n",
        "# ====== HS TopK-20 config ======\n",
        "# Bands từ Hard-Concrete L0 Gate (sorted)\n",
        "HS_SELECTED_BANDS = [7, 32, 43, 48, 50, 58, 72, 84, 92, 97, 98, 99,\n",
        "                     101, 105, 110, 111, 112, 114, 117, 122]\n",
        "HS_IMG_SIZE = 224   # TopK model dùng 64x64\n",
        "\n",
        "# HS global mean/std sẽ được tính ở cell tiếp theo\n",
        "HS_GLOBAL_MEAN = None  # shape (125,) - tính từ train data\n",
        "HS_GLOBAL_STD  = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "114e9e20",
      "metadata": {
        "id": "114e9e20",
        "outputId": "e67f3627-efd2-4abe-d9f1-998007616617",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RGB files: 600 | MS: 600 | HS: 600\n",
            "Intersection keys (RGB∩MS∩HS): 600\n",
            "Val keys: 116\n",
            "rust_hyper_131 -> Rust\n",
            "other_hyper_85 -> Other\n",
            "health_hyper_62 -> Health\n",
            "other_hyper_137 -> Other\n",
            "rust_hyper_74 -> Rust\n"
          ]
        }
      ],
      "source": [
        "# %% [code]\n",
        "def list_files(dir_path, exts):\n",
        "    return sorted([f for f in os.listdir(dir_path) if f.lower().endswith(exts)])\n",
        "\n",
        "rgb_files = list_files(RGB_DIR, (\".png\", \".jpg\", \".jpeg\"))\n",
        "ms_files  = list_files(MS_DIR,  (\".tif\", \".tiff\"))\n",
        "hs_files  = list_files(HS_DIR,  (\".tif\", \".tiff\"))\n",
        "\n",
        "rgb_map = {key_from_filename(f): f for f in rgb_files}\n",
        "ms_map  = {key_from_filename(f): f for f in ms_files}\n",
        "hs_map  = {key_from_filename(f): f for f in hs_files}\n",
        "\n",
        "# lấy intersection keys có đủ 3 modality\n",
        "all_keys = sorted(set(rgb_map.keys()) & set(ms_map.keys()) & set(hs_map.keys()))\n",
        "print(\"RGB files:\", len(rgb_files), \"| MS:\", len(ms_files), \"| HS:\", len(hs_files))\n",
        "print(\"Intersection keys (RGB∩MS∩HS):\", len(all_keys))\n",
        "\n",
        "# ---- Load val_idx.npy ----\n",
        "val_idx = np.load(VAL_IDX_PATH)\n",
        "val_idx = np.array(val_idx, dtype=int)\n",
        "\n",
        "# CỰC QUAN TRỌNG:\n",
        "# val_idx này phải được tạo dựa trên một list \"chuẩn\" tương thích với all_keys.\n",
        "# Ở đây mình assume val_idx được tạo từ list HS đã sorted theo filename và sau đó key cũng theo sorted.\n",
        "# Nếu split của bạn trước đây dựa trên HS sorted list -> cách này sẽ match tốt khi all_keys cũng được sorted theo key giống HS.\n",
        "#\n",
        "# Nếu bạn muốn chắc chắn tuyệt đối: hãy dùng HS sorted list làm chuẩn split và map sang all_keys theo key.\n",
        "# Ở đây, để chạy ngay, ta sẽ áp val_idx trực tiếp lên all_keys (phổ biến khi bạn đã làm split chung).\n",
        "val_keys = [all_keys[i] for i in val_idx if 0 <= i < len(all_keys)]\n",
        "print(\"Val keys:\", len(val_keys))\n",
        "\n",
        "# sanity check xem label parse ổn\n",
        "for k in val_keys[:5]:\n",
        "    print(k, \"->\", label_from_filename(rgb_map[k]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "19e9bf1c",
      "metadata": {
        "id": "19e9bf1c",
        "outputId": "6ae6998e-484f-4e9f-bbd1-a62393332b68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing HS global stats on 461 train samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rHS stats:   0%|          | 0/461 [00:00<?, ?it/s]/tmp/ipython-input-738311097.py:22: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  img = Image.fromarray(x_chw[c].astype(np.float32), mode=\"F\")\n",
            "HS stats: 100%|██████████| 461/461 [07:34<00:00,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HS Global Mean[0:5]: [274.33752 332.61566 360.572   378.06027 391.32166]\n",
            "HS Global Std [0:5]: [339.42944 356.93826 363.0298  366.1827  372.26035]\n",
            "HS Global Mean shape: (125,)\n",
            "\n",
            "TopK-20 Mean: [ 418.34137  801.85815  822.22     824.4204   820.9778   864.821\n",
            " 2158.5183  2650.928   2661.856   2651.864   2650.8083  2649.1948\n",
            " 2646.4912  2629.0188  2583.5854  2569.6738  2554.2322  2513.4272\n",
            " 2420.075   2168.3157 ]\n",
            "TopK-20 Std:  [ 382.85593  559.02795  637.8201   665.75323  675.6458   703.6001\n",
            "  837.1711  1098.469   1101.9298  1099.0345  1098.3705  1098.0251\n",
            " 1097.5237  1090.5641  1075.7609  1070.9634  1065.3912  1051.4756\n",
            " 1017.5553   917.4244 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ====== Tính HS global mean/std trên TRAIN split (giống baseline TopK) ======\n",
        "# Pipeline: load → CHW → fix 125 bands → resize 64×64 → clip per-band (q1%-q99%) → accumulate stats\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "\n",
        "# Lấy train files (tất cả trừ val)\n",
        "train_idx = np.load(TRAIN_IDX_FILE)\n",
        "train_idx = np.array(train_idx, dtype=int)\n",
        "train_keys = [all_keys[i] for i in train_idx if 0 <= i < len(all_keys)]\n",
        "\n",
        "print(f\"Computing HS global stats on {len(train_keys)} train samples...\")\n",
        "\n",
        "n_bands = 125\n",
        "pixel_count = 0\n",
        "band_sum = np.zeros(n_bands, dtype=np.float64)\n",
        "band_sum_sq = np.zeros(n_bands, dtype=np.float64)\n",
        "\n",
        "for k in tqdm(train_keys, desc=\"HS stats\"):\n",
        "    path = os.path.join(HS_DIR, hs_map[k])\n",
        "    arr = tiff.imread(path).astype(np.float32)\n",
        "    arr = ensure_chw_hs(arr)\n",
        "    arr = fix_bands_125(arr)\n",
        "    arr = resize_np_chw(arr, HS_IMG_SIZE)  # (125, 64, 64)\n",
        "\n",
        "    # clip per-band (quantile 1%-99%) giống baseline\n",
        "    x = torch.from_numpy(arr)\n",
        "    x = clip_per_band(x, ql=0.01, qh=0.99)\n",
        "    arr = x.numpy()\n",
        "\n",
        "    # accumulate per-band stats\n",
        "    for b in range(n_bands):\n",
        "        band_pixels = arr[b].ravel()\n",
        "        band_sum[b] += band_pixels.sum()\n",
        "        band_sum_sq[b] += (band_pixels ** 2).sum()\n",
        "    pixel_count += arr.shape[1] * arr.shape[2]\n",
        "\n",
        "HS_GLOBAL_MEAN = (band_sum / pixel_count).astype(np.float32)\n",
        "HS_GLOBAL_STD  = np.sqrt(band_sum_sq / pixel_count - (band_sum / pixel_count) ** 2).astype(np.float32)\n",
        "\n",
        "print(f\"HS Global Mean[0:5]: {HS_GLOBAL_MEAN[:5]}\")\n",
        "print(f\"HS Global Std [0:5]: {HS_GLOBAL_STD[:5]}\")\n",
        "print(f\"HS Global Mean shape: {HS_GLOBAL_MEAN.shape}\")\n",
        "\n",
        "# Subset cho 20 selected bands\n",
        "HS_TOPK_MEAN = HS_GLOBAL_MEAN[HS_SELECTED_BANDS]\n",
        "HS_TOPK_STD  = HS_GLOBAL_STD[HS_SELECTED_BANDS]\n",
        "print(f\"\\nTopK-20 Mean: {HS_TOPK_MEAN}\")\n",
        "print(f\"TopK-20 Std:  {HS_TOPK_STD}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ce85fad2",
      "metadata": {
        "id": "ce85fad2",
        "outputId": "584c8f35-61fa-4f2e-a1b0-d6e39f73c6d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val dataset: 116\n"
          ]
        }
      ],
      "source": [
        "# %% [code]\n",
        "class FusionDataset(Dataset):\n",
        "    def __init__(self, keys, rgb_dir, ms_dir, hs_dir, rgb_map, ms_map, hs_map,\n",
        "                 img_size=IMG_SIZE, hs_img_size=IMG_SIZE,\n",
        "                 ms_mean=None, ms_std=None,\n",
        "                 hs_global_mean=None, hs_global_std=None,\n",
        "                 hs_selected_bands=None):\n",
        "        self.keys = keys\n",
        "        self.rgb_dir = rgb_dir\n",
        "        self.ms_dir = ms_dir\n",
        "        self.hs_dir = hs_dir\n",
        "        self.rgb_map = rgb_map\n",
        "        self.ms_map = ms_map\n",
        "        self.hs_map = hs_map\n",
        "        self.img_size = img_size\n",
        "        self.hs_img_size = hs_img_size\n",
        "\n",
        "        self.ms_mean = ms_mean\n",
        "        self.ms_std = ms_std\n",
        "        self.hs_global_mean = hs_global_mean  # shape (125,)\n",
        "        self.hs_global_std = hs_global_std    # shape (125,)\n",
        "        self.hs_selected_bands = hs_selected_bands  # list of 20 indices\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.keys)\n",
        "\n",
        "    def load_rgb(self, path):\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        img = img.resize((self.img_size, self.img_size), resample=Image.BILINEAR)\n",
        "        arr = np.array(img, dtype=np.float32) / 255.0  # HWC 0..1\n",
        "        x = arr.transpose(2,0,1)  # CHW\n",
        "        x = normalize_chw(x, RGB_MEAN, RGB_STD)\n",
        "        return x\n",
        "\n",
        "    def load_ms(self, path):\n",
        "        arr = tiff.imread(path)\n",
        "        if arr.ndim == 2:\n",
        "            arr = arr[None, :, :]\n",
        "        elif arr.ndim == 3:\n",
        "            if arr.shape[0] != 5 and arr.shape[-1] == 5:\n",
        "                arr = np.transpose(arr, (2,0,1))\n",
        "        else:\n",
        "            raise ValueError(f\"MS tif shape not supported: {arr.shape} | {path}\")\n",
        "        arr = arr.astype(np.float32)\n",
        "        arr = arr / 65535.0\n",
        "        arr = resize_np_chw(arr, self.img_size)\n",
        "        if self.ms_mean is not None and self.ms_std is not None:\n",
        "            arr = normalize_chw(arr, self.ms_mean, self.ms_std)\n",
        "        return arr\n",
        "\n",
        "    def load_hs(self, path):\n",
        "        \"\"\"Load HS theo pipeline TopK: 125 bands → resize → clip → Z-score → select 20 bands.\"\"\"\n",
        "        arr = tiff.imread(path).astype(np.float32)\n",
        "        arr = ensure_chw_hs(arr)\n",
        "        arr = fix_bands_125(arr)\n",
        "\n",
        "        # Resize → 64x64\n",
        "        arr = resize_np_chw(arr, self.hs_img_size)\n",
        "\n",
        "        # Clip per-band (quantile 1%-99%)\n",
        "        x = torch.from_numpy(arr)\n",
        "        x = clip_per_band(x, ql=0.01, qh=0.99)\n",
        "        arr = x.numpy()\n",
        "\n",
        "        # Global Z-score normalize (125 bands)\n",
        "        if self.hs_global_mean is not None and self.hs_global_std is not None:\n",
        "            arr = normalize_chw(arr, self.hs_global_mean, self.hs_global_std)\n",
        "\n",
        "        # Select 20 TopK bands\n",
        "        if self.hs_selected_bands is not None:\n",
        "            arr = arr[self.hs_selected_bands]  # (20, 64, 64)\n",
        "\n",
        "        return arr\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        k = self.keys[idx]\n",
        "\n",
        "        rgb_path = os.path.join(self.rgb_dir, self.rgb_map[k])\n",
        "        ms_path  = os.path.join(self.ms_dir,  self.ms_map[k])\n",
        "        hs_path  = os.path.join(self.hs_dir,  self.hs_map[k])\n",
        "\n",
        "        x_rgb = self.load_rgb(rgb_path)\n",
        "        x_ms  = self.load_ms(ms_path)\n",
        "        x_hs  = self.load_hs(hs_path)\n",
        "\n",
        "        y = CLASS_TO_IDX[label_from_filename(self.rgb_map[k])]\n",
        "\n",
        "        return (\n",
        "            torch.from_numpy(x_rgb).float(),\n",
        "            torch.from_numpy(x_ms).float(),\n",
        "            torch.from_numpy(x_hs).float(),\n",
        "            torch.tensor(y, dtype=torch.long),\n",
        "            k\n",
        "        )\n",
        "\n",
        "val_ds = FusionDataset(\n",
        "    keys=val_keys,\n",
        "    rgb_dir=RGB_DIR, ms_dir=MS_DIR, hs_dir=HS_DIR,\n",
        "    rgb_map=rgb_map, ms_map=ms_map, hs_map=hs_map,\n",
        "    img_size=IMG_SIZE,\n",
        "    hs_img_size=HS_IMG_SIZE,\n",
        "    ms_mean=MS_MEAN, ms_std=MS_STD,\n",
        "    hs_global_mean=HS_GLOBAL_MEAN,\n",
        "    hs_global_std=HS_GLOBAL_STD,\n",
        "    hs_selected_bands=HS_SELECTED_BANDS\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(\"Val dataset:\", len(val_ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c941fa56",
      "metadata": {
        "id": "c941fa56",
        "outputId": "0ae51b35-44c9-40de-ed1a-ef127ea33974",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RGB ckpt loaded | missing: [] | unexpected: []\n",
            "MS ckpt loaded | missing: [] | unexpected: []\n",
            "HS ckpt loaded | missing: [] | unexpected: []\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(20, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# %% [code]\n",
        "import torchvision\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "def build_resnet18(num_classes=3, in_channels=3, pretrained=False):\n",
        "    \"\"\"\n",
        "    pretrained=False vì checkpoint của bạn là từ baseline đã train rồi.\n",
        "    Nếu bạn muốn init conv1 từ imagenet khi in_channels != 3 thì phải làm thêm logic riêng.\n",
        "    \"\"\"\n",
        "    if pretrained and in_channels == 3:\n",
        "        model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "    else:\n",
        "        model = resnet18(weights=None)\n",
        "\n",
        "    # sửa conv1 nếu in_channels khác 3\n",
        "    if in_channels != 3:\n",
        "        old = model.conv1\n",
        "        model.conv1 = nn.Conv2d(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=old.out_channels,\n",
        "            kernel_size=old.kernel_size,\n",
        "            stride=old.stride,\n",
        "            padding=old.padding,\n",
        "            bias=(old.bias is not None)\n",
        "        )\n",
        "\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "def load_ckpt(model, ckpt_path, device):\n",
        "    ckpt = torch.load(ckpt_path, map_location=device)\n",
        "    # nhiều notebook lưu kiểu {\"model_state\": ...} hoặc lưu thẳng state_dict\n",
        "    if isinstance(ckpt, dict) and \"state_dict\" in ckpt:\n",
        "        state = ckpt[\"state_dict\"]\n",
        "    elif isinstance(ckpt, dict) and \"model_state_dict\" in ckpt:\n",
        "        state = ckpt[\"model_state_dict\"]\n",
        "    elif isinstance(ckpt, dict) and \"model\" in ckpt and isinstance(ckpt[\"model\"], dict):\n",
        "        state = ckpt[\"model\"]\n",
        "    else:\n",
        "        state = ckpt\n",
        "\n",
        "    missing, unexpected = model.load_state_dict(state, strict=True)\n",
        "    return missing, unexpected\n",
        "\n",
        "# build models\n",
        "model_rgb = build_resnet18(num_classes=3, in_channels=3,   pretrained=False).to(DEVICE)\n",
        "model_ms  = build_resnet18(num_classes=3, in_channels=5,   pretrained=False).to(DEVICE)\n",
        "model_hs  = build_resnet18(num_classes=3, in_channels=20,  pretrained=False).to(DEVICE)\n",
        "\n",
        "# load checkpoints\n",
        "miss, unexp = load_ckpt(model_rgb, CKPT_RGB, DEVICE)\n",
        "print(\"RGB ckpt loaded | missing:\", miss, \"| unexpected:\", unexp)\n",
        "\n",
        "miss, unexp = load_ckpt(model_ms, CKPT_MS, DEVICE)\n",
        "print(\"MS ckpt loaded | missing:\", miss, \"| unexpected:\", unexp)\n",
        "\n",
        "miss, unexp = load_ckpt(model_hs, CKPT_HS, DEVICE)\n",
        "print(\"HS ckpt loaded | missing:\", miss, \"| unexpected:\", unexp)\n",
        "\n",
        "model_rgb.eval()\n",
        "model_ms.eval()\n",
        "model_hs.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "147ed663",
      "metadata": {
        "id": "147ed663",
        "outputId": "e83ff9dc-ef9b-4ab9-b612-7845536030d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-738311097.py:22: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  img = Image.fromarray(x_chw[c].astype(np.float32), mode=\"F\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== RGB-only =====\n",
            "Acc     : 0.6810\n",
            "F1-macro: 0.6799\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Health     0.6047    0.6341    0.6190        41\n",
            "       Other     0.8421    0.8000    0.8205        40\n",
            "        Rust     0.6000    0.6000    0.6000        35\n",
            "\n",
            "    accuracy                         0.6810       116\n",
            "   macro avg     0.6823    0.6780    0.6799       116\n",
            "weighted avg     0.6851    0.6810    0.6828       116\n",
            "\n",
            "Confusion matrix:\n",
            " [[26  4 11]\n",
            " [ 5 32  3]\n",
            " [12  2 21]]\n",
            "\n",
            "===== MS-only =====\n",
            "Acc     : 0.8534\n",
            "F1-macro: 0.8541\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Health     0.7778    0.8537    0.8140        41\n",
            "       Other     0.9000    0.9000    0.9000        40\n",
            "        Rust     0.9032    0.8000    0.8485        35\n",
            "\n",
            "    accuracy                         0.8534       116\n",
            "   macro avg     0.8603    0.8512    0.8541       116\n",
            "weighted avg     0.8578    0.8534    0.8540       116\n",
            "\n",
            "Confusion matrix:\n",
            " [[35  4  2]\n",
            " [ 3 36  1]\n",
            " [ 7  0 28]]\n",
            "\n",
            "===== HS-only =====\n",
            "Acc     : 0.6983\n",
            "F1-macro: 0.6903\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Health     0.6786    0.4634    0.5507        41\n",
            "       Other     0.8333    0.8750    0.8537        40\n",
            "        Rust     0.5870    0.7714    0.6667        35\n",
            "\n",
            "    accuracy                         0.6983       116\n",
            "   macro avg     0.6996    0.7033    0.6903       116\n",
            "weighted avg     0.7043    0.6983    0.6902       116\n",
            "\n",
            "Confusion matrix:\n",
            " [[19  5 17]\n",
            " [ 3 35  2]\n",
            " [ 6  2 27]]\n",
            "\n",
            "===== Fusion (Equal Avg 1/3) =====\n",
            "Acc     : 0.8534\n",
            "F1-macro: 0.8537\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Health     0.7955    0.8537    0.8235        41\n",
            "       Other     0.9459    0.8750    0.9091        40\n",
            "        Rust     0.8286    0.8286    0.8286        35\n",
            "\n",
            "    accuracy                         0.8534       116\n",
            "   macro avg     0.8567    0.8524    0.8537       116\n",
            "weighted avg     0.8573    0.8534    0.8546       116\n",
            "\n",
            "Confusion matrix:\n",
            " [[35  2  4]\n",
            " [ 3 35  2]\n",
            " [ 6  0 29]]\n",
            "\n",
            "===== Fusion Weighted (RGB=0.3, MS=0.5, HS=0.2) =====\n",
            "Acc     : 0.8707\n",
            "F1-macro: 0.8711\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Health     0.8000    0.8780    0.8372        41\n",
            "       Other     0.9474    0.9000    0.9231        40\n",
            "        Rust     0.8788    0.8286    0.8529        35\n",
            "\n",
            "    accuracy                         0.8707       116\n",
            "   macro avg     0.8754    0.8689    0.8711       116\n",
            "weighted avg     0.8746    0.8707    0.8716       116\n",
            "\n",
            "Confusion matrix:\n",
            " [[36  2  3]\n",
            " [ 3 36  1]\n",
            " [ 6  0 29]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8706896551724138, 0.8710758006243643)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# %% [code]\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Custom collate fn\n",
        "def fusion_collate_fn(batch):\n",
        "    x_rgb_list, x_ms_list, x_hs_list, y_list, k_list = [], [], [], [], []\n",
        "    for rgb, ms, hs, y, k in batch:\n",
        "        x_rgb_list.append(rgb)\n",
        "        x_ms_list.append(ms)\n",
        "        x_hs_list.append(hs)\n",
        "        y_list.append(y)\n",
        "        k_list.append(k)\n",
        "    return (\n",
        "        torch.stack(x_rgb_list),\n",
        "        torch.stack(x_ms_list),\n",
        "        torch.stack(x_hs_list),\n",
        "        torch.stack(y_list),\n",
        "        k_list\n",
        "    )\n",
        "\n",
        "# Rebuild DataLoader with custom collate\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True,\n",
        "    collate_fn=fusion_collate_fn\n",
        ")\n",
        "\n",
        "# ====== Thu thập logits thô để dùng cho tối ưu trọng số ======\n",
        "@torch.no_grad()\n",
        "def collect_logits(loader, model_rgb, model_ms, model_hs, device):\n",
        "    \"\"\"Thu thập raw logits từ 3 model + ground truth label.\"\"\"\n",
        "    y_true_all = []\n",
        "    logits_rgb_all = []\n",
        "    logits_ms_all  = []\n",
        "    logits_hs_all  = []\n",
        "\n",
        "    model_rgb.eval(); model_ms.eval(); model_hs.eval()\n",
        "\n",
        "    for x_rgb, x_ms, x_hs, y, keys in loader:\n",
        "        x_rgb = x_rgb.to(device, non_blocking=True)\n",
        "        x_ms  = x_ms.to(device, non_blocking=True)\n",
        "        x_hs  = x_hs.to(device, non_blocking=True)\n",
        "\n",
        "        logits_rgb_all.append(model_rgb(x_rgb).cpu())\n",
        "        logits_ms_all.append(model_ms(x_ms).cpu())\n",
        "        logits_hs_all.append(model_hs(x_hs).cpu())\n",
        "        y_true_all.append(y)\n",
        "\n",
        "    return (\n",
        "        torch.cat(y_true_all).numpy(),\n",
        "        torch.cat(logits_rgb_all).numpy(),\n",
        "        torch.cat(logits_ms_all).numpy(),\n",
        "        torch.cat(logits_hs_all).numpy(),\n",
        "    )\n",
        "\n",
        "y_true, logits_rgb_val, logits_ms_val, logits_hs_val = collect_logits(\n",
        "    val_loader, model_rgb, model_ms, model_hs, DEVICE\n",
        ")\n",
        "\n",
        "# ====== Eval từng model đơn lẻ ======\n",
        "def summarize(name, y_true, y_pred):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1m = f1_score(y_true, y_pred, average=\"macro\")\n",
        "    print(f\"\\n===== {name} =====\")\n",
        "    print(f\"Acc     : {acc:.4f}\")\n",
        "    print(f\"F1-macro: {f1m:.4f}\")\n",
        "    print(classification_report(y_true, y_pred, target_names=CLASSES, digits=4))\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(\"Confusion matrix:\\n\", cm)\n",
        "    return acc, f1m\n",
        "\n",
        "p_rgb = np.argmax(logits_rgb_val, axis=1)\n",
        "p_ms  = np.argmax(logits_ms_val,  axis=1)\n",
        "p_hs  = np.argmax(logits_hs_val,  axis=1)\n",
        "\n",
        "summarize(\"RGB-only\", y_true, p_rgb)\n",
        "summarize(\"MS-only\",  y_true, p_ms)\n",
        "summarize(\"HS-only\",  y_true, p_hs)\n",
        "\n",
        "# ====== Fusion equal average (baseline) ======\n",
        "p_fus_avg = np.argmax((logits_rgb_val + logits_ms_val + logits_hs_val) / 3.0, axis=1)\n",
        "summarize(\"Fusion (Equal Avg 1/3)\", y_true, p_fus_avg)\n",
        "\n",
        "# ====== Weighted fusion: w_MS=0.5, w_RGB=0.3, w_HS=0.2 ======\n",
        "W_RGB, W_MS, W_HS = 0.3, 0.5, 0.2\n",
        "logits_weighted = W_RGB * logits_rgb_val + W_MS * logits_ms_val + W_HS * logits_hs_val\n",
        "p_fus_w = np.argmax(logits_weighted, axis=1)\n",
        "summarize(f\"Fusion Weighted (RGB={W_RGB}, MS={W_MS}, HS={W_HS})\", y_true, p_fus_w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "e3a57f32",
      "metadata": {
        "id": "e3a57f32",
        "outputId": "29edd7ae-6118-43f1-acef-c50634f2286c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid search done! 231 combinations tested.\n",
            "\n",
            "==================================================\n",
            "BEST WEIGHTS: RGB=0.0, MS=0.55, HS=0.45\n",
            "Best F1-macro: 0.8714 | Best Acc: 0.8707\n",
            "==================================================\n",
            "\n",
            "Top 10 weight combinations (by F1-macro):\n",
            "   RGB     MS     HS      Acc   F1-macro\n",
            "  0.00   0.55   0.45   0.8707     0.8714 <-- BEST\n",
            "  0.05   0.50   0.45   0.8707     0.8714\n",
            "  0.10   0.50   0.40   0.8707     0.8714\n",
            "  0.00   0.50   0.50   0.8707     0.8713\n",
            "  0.20   0.45   0.35   0.8707     0.8711\n",
            "  0.20   0.50   0.30   0.8707     0.8711\n",
            "  0.25   0.45   0.30   0.8707     0.8711\n",
            "  0.25   0.50   0.25   0.8707     0.8711\n",
            "  0.30   0.50   0.20   0.8707     0.8711\n",
            "  0.35   0.50   0.15   0.8707     0.8711\n",
            "\n",
            "===== Fusion BEST (RGB=0.0, MS=0.55, HS=0.45) =====\n",
            "Acc     : 0.8707\n",
            "F1-macro: 0.8714\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Health     0.8140    0.8537    0.8333        41\n",
            "       Other     0.9231    0.9000    0.9114        40\n",
            "        Rust     0.8824    0.8571    0.8696        35\n",
            "\n",
            "    accuracy                         0.8707       116\n",
            "   macro avg     0.8731    0.8703    0.8714       116\n",
            "weighted avg     0.8722    0.8707    0.8712       116\n",
            "\n",
            "Confusion matrix:\n",
            " [[35  3  3]\n",
            " [ 3 36  1]\n",
            " [ 5  0 30]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8706896551724138, 0.8714303185959763)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# %% [code]\n",
        "# ====== GRID SEARCH tìm trọng số tối ưu trên val set ======\n",
        "from itertools import product\n",
        "\n",
        "best_f1 = -1\n",
        "best_acc = -1\n",
        "best_weights = (0.3, 0.5, 0.2)\n",
        "results = []\n",
        "\n",
        "# Grid search với step = 0.05, tổng = 1.0\n",
        "step = 0.05\n",
        "for w_rgb_i in range(0, 21):          # 0.0 -> 1.0\n",
        "    for w_ms_i in range(0, 21 - w_rgb_i):\n",
        "        w_rgb = round(w_rgb_i * step, 2)\n",
        "        w_ms  = round(w_ms_i * step, 2)\n",
        "        w_hs  = round(1.0 - w_rgb - w_ms, 2)\n",
        "        if w_hs < 0:\n",
        "            continue\n",
        "\n",
        "        logits_fus = w_rgb * logits_rgb_val + w_ms * logits_ms_val + w_hs * logits_hs_val\n",
        "        preds = np.argmax(logits_fus, axis=1)\n",
        "        acc = accuracy_score(y_true, preds)\n",
        "        f1m = f1_score(y_true, preds, average=\"macro\")\n",
        "        results.append((w_rgb, w_ms, w_hs, acc, f1m))\n",
        "\n",
        "        if f1m > best_f1 or (f1m == best_f1 and acc > best_acc):\n",
        "            best_f1 = f1m\n",
        "            best_acc = acc\n",
        "            best_weights = (w_rgb, w_ms, w_hs)\n",
        "\n",
        "print(f\"Grid search done! {len(results)} combinations tested.\")\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"BEST WEIGHTS: RGB={best_weights[0]}, MS={best_weights[1]}, HS={best_weights[2]}\")\n",
        "print(f\"Best F1-macro: {best_f1:.4f} | Best Acc: {best_acc:.4f}\")\n",
        "print(f\"{'='*50}\")\n",
        "\n",
        "# Show top 10\n",
        "results_sorted = sorted(results, key=lambda x: (-x[4], -x[3]))\n",
        "print(\"\\nTop 10 weight combinations (by F1-macro):\")\n",
        "print(f\"{'RGB':>6} {'MS':>6} {'HS':>6} {'Acc':>8} {'F1-macro':>10}\")\n",
        "for w_rgb, w_ms, w_hs, acc, f1m in results_sorted[:10]:\n",
        "    marker = \" <-- BEST\" if (w_rgb, w_ms, w_hs) == best_weights else \"\"\n",
        "    print(f\"{w_rgb:>6.2f} {w_ms:>6.2f} {w_hs:>6.2f} {acc:>8.4f} {f1m:>10.4f}{marker}\")\n",
        "\n",
        "# Eval best weights\n",
        "BEST_W_RGB, BEST_W_MS, BEST_W_HS = best_weights\n",
        "logits_best = BEST_W_RGB * logits_rgb_val + BEST_W_MS * logits_ms_val + BEST_W_HS * logits_hs_val\n",
        "p_fus_best = np.argmax(logits_best, axis=1)\n",
        "summarize(f\"Fusion BEST (RGB={BEST_W_RGB}, MS={BEST_W_MS}, HS={BEST_W_HS})\", y_true, p_fus_best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a8d15314",
      "metadata": {
        "id": "a8d15314",
        "outputId": "f28cdf1e-8d03-4d4c-8d33-29694961cdcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x400 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# %% [code]\n",
        "# ====== Confusion matrices so sánh ======\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "titles_preds = [\n",
        "    (\"Equal Avg (1/3 each)\", np.argmax((logits_rgb_val + logits_ms_val + logits_hs_val)/3, axis=1)),\n",
        "    (f\"Manual (RGB={W_RGB}, MS={W_MS}, HS={W_HS})\", np.argmax(W_RGB*logits_rgb_val + W_MS*logits_ms_val + W_HS*logits_hs_val, axis=1)),\n",
        "    (f\"Grid Best (RGB={BEST_W_RGB}, MS={BEST_W_MS}, HS={BEST_W_HS})\", p_fus_best),\n",
        "]\n",
        "\n",
        "for ax, (title, preds) in zip(axes, titles_preds):\n",
        "    cm = confusion_matrix(y_true, preds)\n",
        "    f1m = f1_score(y_true, preds, average=\"macro\")\n",
        "    ax.imshow(cm, cmap=\"Blues\")\n",
        "    ax.set_title(f\"{title}\\nF1={f1m:.4f}\", fontsize=9)\n",
        "    ax.set_xticks(range(len(CLASSES)))\n",
        "    ax.set_xticklabels(CLASSES, rotation=30, fontsize=8)\n",
        "    ax.set_yticks(range(len(CLASSES)))\n",
        "    ax.set_yticklabels(CLASSES, fontsize=8)\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\", fontsize=11)\n",
        "    ax.set_xlabel(\"Pred\")\n",
        "    ax.set_ylabel(\"True\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "29f344ba",
      "metadata": {
        "id": "29f344ba",
        "outputId": "88cfa94f-fcfc-48c0-d5e7-8021ce356c85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test files: RGB=300, MS=300, HS=300\n",
            "Test intersection keys (RGB∩MS∩HS): 300\n"
          ]
        }
      ],
      "source": [
        "# %% [code]\n",
        "# ====== KAGGLE SUBMISSION: Late Fusion (RGB + MS + HS) ======\n",
        "\n",
        "# --- List test files ---\n",
        "test_rgb_files = sorted([f for f in os.listdir(TEST_RGB_DIR) if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))])\n",
        "test_ms_files  = sorted([f for f in os.listdir(TEST_MS_DIR)  if f.lower().endswith((\".tif\", \".tiff\"))])\n",
        "test_hs_files  = sorted([f for f in os.listdir(TEST_HS_DIR)  if f.lower().endswith((\".tif\", \".tiff\"))])\n",
        "\n",
        "test_rgb_map = {key_from_filename(f): f for f in test_rgb_files}\n",
        "test_ms_map  = {key_from_filename(f): f for f in test_ms_files}\n",
        "test_hs_map  = {key_from_filename(f): f for f in test_hs_files}\n",
        "\n",
        "test_keys = sorted(set(test_rgb_map.keys()) & set(test_ms_map.keys()) & set(test_hs_map.keys()))\n",
        "print(f\"Test files: RGB={len(test_rgb_files)}, MS={len(test_ms_files)}, HS={len(test_hs_files)}\")\n",
        "print(f\"Test intersection keys (RGB∩MS∩HS): {len(test_keys)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "99309a29",
      "metadata": {
        "id": "99309a29",
        "outputId": "eea0a314-a5d4-4b4e-ddd9-e89c5de3977c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test dataset: 300 samples\n"
          ]
        }
      ],
      "source": [
        "# %% [code]\n",
        "# --- Test Dataset (không có label) ---\n",
        "class TestFusionDataset(Dataset):\n",
        "    def __init__(self, keys, rgb_dir, ms_dir, hs_dir, rgb_map, ms_map, hs_map,\n",
        "                 img_size=IMG_SIZE, hs_img_size=IMG_SIZE,\n",
        "                 ms_mean=None, ms_std=None,\n",
        "                 hs_global_mean=None, hs_global_std=None,\n",
        "                 hs_selected_bands=None):\n",
        "        self.keys = keys\n",
        "        self.rgb_dir = rgb_dir\n",
        "        self.ms_dir = ms_dir\n",
        "        self.hs_dir = hs_dir\n",
        "        self.rgb_map = rgb_map\n",
        "        self.ms_map = ms_map\n",
        "        self.hs_map = hs_map\n",
        "        self.img_size = img_size\n",
        "        self.hs_img_size = hs_img_size\n",
        "        self.ms_mean = ms_mean\n",
        "        self.ms_std = ms_std\n",
        "        self.hs_global_mean = hs_global_mean\n",
        "        self.hs_global_std = hs_global_std\n",
        "        self.hs_selected_bands = hs_selected_bands\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.keys)\n",
        "\n",
        "    def load_rgb(self, path):\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        img = img.resize((self.img_size, self.img_size), resample=Image.BILINEAR)\n",
        "        arr = np.array(img, dtype=np.float32) / 255.0\n",
        "        x = arr.transpose(2,0,1)\n",
        "        x = normalize_chw(x, RGB_MEAN, RGB_STD)\n",
        "        return x\n",
        "\n",
        "    def load_ms(self, path):\n",
        "        arr = tiff.imread(path)\n",
        "        if arr.ndim == 2:\n",
        "            arr = arr[None, :, :]\n",
        "        elif arr.ndim == 3:\n",
        "            if arr.shape[0] != 5 and arr.shape[-1] == 5:\n",
        "                arr = np.transpose(arr, (2,0,1))\n",
        "        else:\n",
        "            raise ValueError(f\"MS tif shape not supported: {arr.shape} | {path}\")\n",
        "        arr = arr.astype(np.float32) / 65535.0\n",
        "        arr = resize_np_chw(arr, self.img_size)\n",
        "        if self.ms_mean is not None and self.ms_std is not None:\n",
        "            arr = normalize_chw(arr, self.ms_mean, self.ms_std)\n",
        "        return arr\n",
        "\n",
        "    def load_hs(self, path):\n",
        "        \"\"\"Load HS theo pipeline TopK: 125 bands → resize → clip → Z-score → select 20 bands.\"\"\"\n",
        "        arr = tiff.imread(path).astype(np.float32)\n",
        "        arr = ensure_chw_hs(arr)\n",
        "        arr = fix_bands_125(arr)\n",
        "\n",
        "        arr = resize_np_chw(arr, self.hs_img_size)\n",
        "\n",
        "        x = torch.from_numpy(arr)\n",
        "        x = clip_per_band(x, ql=0.01, qh=0.99)\n",
        "        arr = x.numpy()\n",
        "\n",
        "        if self.hs_global_mean is not None and self.hs_global_std is not None:\n",
        "            arr = normalize_chw(arr, self.hs_global_mean, self.hs_global_std)\n",
        "\n",
        "        if self.hs_selected_bands is not None:\n",
        "            arr = arr[self.hs_selected_bands]  # (20, 64, 64)\n",
        "\n",
        "        return arr\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        k = self.keys[idx]\n",
        "        x_rgb = self.load_rgb(os.path.join(self.rgb_dir, self.rgb_map[k]))\n",
        "        x_ms  = self.load_ms(os.path.join(self.ms_dir,  self.ms_map[k]))\n",
        "        x_hs  = self.load_hs(os.path.join(self.hs_dir,  self.hs_map[k]))\n",
        "        return (\n",
        "            torch.from_numpy(x_rgb).float(),\n",
        "            torch.from_numpy(x_ms).float(),\n",
        "            torch.from_numpy(x_hs).float(),\n",
        "            k\n",
        "        )\n",
        "\n",
        "test_ds = TestFusionDataset(\n",
        "    keys=test_keys,\n",
        "    rgb_dir=TEST_RGB_DIR, ms_dir=TEST_MS_DIR, hs_dir=TEST_HS_DIR,\n",
        "    rgb_map=test_rgb_map, ms_map=test_ms_map, hs_map=test_hs_map,\n",
        "    img_size=IMG_SIZE,\n",
        "    hs_img_size=HS_IMG_SIZE,\n",
        "    ms_mean=MS_MEAN, ms_std=MS_STD,\n",
        "    hs_global_mean=HS_GLOBAL_MEAN,\n",
        "    hs_global_std=HS_GLOBAL_STD,\n",
        "    hs_selected_bands=HS_SELECTED_BANDS\n",
        ")\n",
        "\n",
        "def test_collate_fn(batch):\n",
        "    x_rgb_list, x_ms_list, x_hs_list, k_list = [], [], [], []\n",
        "    for rgb, ms, hs, k in batch:\n",
        "        x_rgb_list.append(rgb)\n",
        "        x_ms_list.append(ms)\n",
        "        x_hs_list.append(hs)\n",
        "        k_list.append(k)\n",
        "    return torch.stack(x_rgb_list), torch.stack(x_ms_list), torch.stack(x_hs_list), k_list\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True,\n",
        "    collate_fn=test_collate_fn\n",
        ")\n",
        "\n",
        "print(f\"Test dataset: {len(test_ds)} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "8162ab42",
      "metadata": {
        "id": "8162ab42",
        "outputId": "b15e2a4b-e551-4a67-ff35-97035f3632d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using BEST weights: RGB=0.0, MS=0.55, HS=0.45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-738311097.py:22: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  img = Image.fromarray(x_chw[c].astype(np.float32), mode=\"F\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: 300 samples\n",
            "Distribution: {'Health': 101, 'Other': 101, 'Rust': 98}\n"
          ]
        }
      ],
      "source": [
        "# %% [code]\n",
        "# --- Inference trên test set với BEST WEIGHTS ---\n",
        "@torch.no_grad()\n",
        "def predict_fusion(loader, model_rgb, model_ms, model_hs, device,\n",
        "                   w_rgb=0.3, w_ms=0.5, w_hs=0.2):\n",
        "    all_keys = []\n",
        "    all_preds = []\n",
        "\n",
        "    model_rgb.eval()\n",
        "    model_ms.eval()\n",
        "    model_hs.eval()\n",
        "\n",
        "    for x_rgb, x_ms, x_hs, keys in loader:\n",
        "        x_rgb = x_rgb.to(device, non_blocking=True)\n",
        "        x_ms  = x_ms.to(device, non_blocking=True)\n",
        "        x_hs  = x_hs.to(device, non_blocking=True)\n",
        "\n",
        "        logits_rgb = model_rgb(x_rgb)\n",
        "        logits_ms  = model_ms(x_ms)\n",
        "        logits_hs  = model_hs(x_hs)\n",
        "\n",
        "        # Weighted late fusion\n",
        "        logits_fus = w_rgb * logits_rgb + w_ms * logits_ms + w_hs * logits_hs\n",
        "        preds = torch.argmax(logits_fus, dim=1).cpu().numpy()\n",
        "\n",
        "        all_keys.extend(keys)\n",
        "        all_preds.extend(preds)\n",
        "\n",
        "    return all_keys, np.array(all_preds)\n",
        "\n",
        "# Dùng trọng số tối ưu từ grid search\n",
        "print(f\"Using BEST weights: RGB={BEST_W_RGB}, MS={BEST_W_MS}, HS={BEST_W_HS}\")\n",
        "\n",
        "test_keys_out, test_preds = predict_fusion(\n",
        "    test_loader, model_rgb, model_ms, model_hs, DEVICE,\n",
        "    w_rgb=BEST_W_RGB, w_ms=BEST_W_MS, w_hs=BEST_W_HS\n",
        ")\n",
        "print(f\"Predictions: {len(test_preds)} samples\")\n",
        "print(f\"Distribution: { {c: int((test_preds==i).sum()) for c,i in CLASS_TO_IDX.items()} }\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "9107014c",
      "metadata": {
        "id": "9107014c",
        "outputId": "b76b0bfe-6029-42dd-f13a-66d4564ba062",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission saved to: /content/AI-for-Agriculture-2026/notebooks/LateFusion/submission_latefusion_rgb_resnet18_aug-v5_base124_img224_batch8_epoch20_lr0.0001_best_ms_resnet18_224_best_hs_topK20_resnet18_224.csv\n",
            "Total rows: 300\n",
            "\n",
            "Distribution:\n",
            "Category\n",
            "Health    101\n",
            "Other     101\n",
            "Rust       98\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Head:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Id Category\n",
              "0  val_000a83c1.tif   Health\n",
              "1  val_00a704b1.tif    Other\n",
              "2  val_01dde030.tif    Other\n",
              "3  val_024df365.tif   Health\n",
              "4  val_02afcb0e.tif     Rust\n",
              "5  val_03864ba6.tif   Health\n",
              "6  val_0537e324.tif   Health\n",
              "7  val_059983e0.tif     Rust\n",
              "8  val_05cee914.tif    Other\n",
              "9  val_07af871a.tif     Rust"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d81f5d43-8dcc-42bf-92d9-00743bc27c07\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>val_000a83c1.tif</td>\n",
              "      <td>Health</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>val_00a704b1.tif</td>\n",
              "      <td>Other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>val_01dde030.tif</td>\n",
              "      <td>Other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>val_024df365.tif</td>\n",
              "      <td>Health</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>val_02afcb0e.tif</td>\n",
              "      <td>Rust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>val_03864ba6.tif</td>\n",
              "      <td>Health</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>val_0537e324.tif</td>\n",
              "      <td>Health</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>val_059983e0.tif</td>\n",
              "      <td>Rust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>val_05cee914.tif</td>\n",
              "      <td>Other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>val_07af871a.tif</td>\n",
              "      <td>Rust</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d81f5d43-8dcc-42bf-92d9-00743bc27c07')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d81f5d43-8dcc-42bf-92d9-00743bc27c07 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d81f5d43-8dcc-42bf-92d9-00743bc27c07');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "sub_df",
              "summary": "{\n  \"name\": \"sub_df\",\n  \"rows\": 300,\n  \"fields\": [\n    {\n      \"column\": \"Id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 300,\n        \"samples\": [\n          \"val_b826d518.tif\",\n          \"val_e9ce960f.tif\",\n          \"val_94d72cf9.tif\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Health\",\n          \"Other\",\n          \"Rust\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# %% [code]\n",
        "# --- Tạo file submission CSV ---\n",
        "# Format Kaggle: columns = [\"Id\", \"Category\"]\n",
        "# Id = filename .tif (ưu tiên HS/MS), Category = Health/Rust/Other\n",
        "\n",
        "submission_rows = []\n",
        "for k, pred_idx in zip(test_keys_out, test_preds):\n",
        "    # Lấy filename .tif từ HS hoặc MS (Kaggle dùng .tif)\n",
        "    if k in test_hs_map:\n",
        "        file_id = test_hs_map[k]\n",
        "    elif k in test_ms_map:\n",
        "        file_id = test_ms_map[k]\n",
        "    else:\n",
        "        file_id = test_rgb_map[k]\n",
        "\n",
        "    label = IDX_TO_CLASS[int(pred_idx)]\n",
        "    submission_rows.append({\"Id\": file_id, \"Category\": label})\n",
        "\n",
        "sub_df = pd.DataFrame(submission_rows)\n",
        "sub_df = sub_df.sort_values(\"Id\").reset_index(drop=True)\n",
        "sub_df.to_csv(OUT_SUB_PATH, index=False)\n",
        "\n",
        "print(f\"Submission saved to: {OUT_SUB_PATH}\")\n",
        "print(f\"Total rows: {len(sub_df)}\")\n",
        "print(f\"\\nDistribution:\")\n",
        "print(sub_df[\"Category\"].value_counts())\n",
        "print(f\"\\nHead:\")\n",
        "sub_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Push to GitHub"
      ],
      "metadata": {
        "id": "gGoSc-PL83Sk"
      },
      "id": "gGoSc-PL83Sk"
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --list"
      ],
      "metadata": {
        "id": "f3wmlTyY826F",
        "outputId": "73ea3cef-7774-44ca-a80a-945b0ce0021f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "f3wmlTyY826F",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filter.lfs.clean=git-lfs clean -- %f\n",
            "filter.lfs.smudge=git-lfs smudge -- %f\n",
            "filter.lfs.process=git-lfs filter-process\n",
            "filter.lfs.required=true\n",
            "user.name=doduyquy\n",
            "user.email=doduyquy211@gmail.com\n",
            "core.repositoryformatversion=0\n",
            "core.filemode=true\n",
            "core.bare=false\n",
            "core.logallrefupdates=true\n",
            "remote.origin.url=https://github.com/doduyquy/AI-for-Agriculture-2026.git\n",
            "remote.origin.fetch=+refs/heads/*:refs/remotes/origin/*\n",
            "branch.HongPhuc.remote=origin\n",
            "branch.HongPhuc.merge=refs/heads/HongPhuc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "push_msg = f\"latefusion: {submission_fn}\"\n",
        "\n",
        "!git add /content/AI-for-Agriculture-2026/notebooks/LateFusion/submission_latefusion_rgb_resnet18_aug-v5_base124_img224_batch8_epoch20_lr0.0001_best_ms_resnet18_224_best_hs_topK20_resnet18_224.csv\n",
        "!git commit -m \"{push_msg}\"\n",
        "!git push https://doduyquy:${GITHUB_TOKEN}@github.com/doduyquy/AI-for-Agriculture-2026.git HongPhuc\n",
        "print(f\"Push to github successfully with message: {push_msg}\")"
      ],
      "metadata": {
        "id": "DcFTaKac_edx",
        "outputId": "d4b673e4-f0e3-4145-fd23-079965d4ab8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "DcFTaKac_edx",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HongPhuc a8918a3] latefusion: submission_latefusion_rgb_resnet18_aug-v5_base124_img224_batch8_epoch20_lr0.0001_best_ms_resnet18_224_best_hs_topK20_resnet18_224.csv\n",
            " 1 file changed, 301 insertions(+)\n",
            " create mode 100644 notebooks/LateFusion/submission_latefusion_rgb_resnet18_aug-v5_base124_img224_batch8_epoch20_lr0.0001_best_ms_resnet18_224_best_hs_topK20_resnet18_224.csv\n",
            "Enumerating objects: 8, done.\n",
            "Counting objects: 100% (8/8), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (5/5), done.\n",
            "Writing objects: 100% (5/5), 2.37 KiB | 2.38 MiB/s, done.\n",
            "Total 5 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/doduyquy/AI-for-Agriculture-2026.git\n",
            "   b76cc8f..a8918a3  HongPhuc -> HongPhuc\n",
            "Push to github successfully with message: latefusion: submission_latefusion_rgb_resnet18_aug-v5_base124_img224_batch8_epoch20_lr0.0001_best_ms_resnet18_224_best_hs_topK20_resnet18_224.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### The end"
      ],
      "metadata": {
        "id": "pVR3QNLm8Trp"
      },
      "id": "pVR3QNLm8Trp"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "djvadbil9wUh"
      },
      "id": "djvadbil9wUh",
      "execution_count": 23,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}