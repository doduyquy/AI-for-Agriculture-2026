{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Late fusion: RGB + MS + HS"
      ],
      "metadata": {
        "id": "ZHxNqJ75yAhf"
      },
      "id": "ZHxNqJ75yAhf"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cb1d117d",
      "metadata": {
        "id": "cb1d117d"
      },
      "outputs": [],
      "source": [
        "# %% [code]\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from PIL import Image\n",
        "import tifffile as tiff\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to GitHub"
      ],
      "metadata": {
        "id": "iH3hvMh61Nb5"
      },
      "id": "iH3hvMh61Nb5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Clone repo (branch: HongPhuc)"
      ],
      "metadata": {
        "id": "593L3ivg1h4Y"
      },
      "id": "593L3ivg1h4Y"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -b HongPhuc https://github.com/doduyquy/AI-for-Agriculture-2026.git\n",
        "\n",
        "# move to AI-for-Agriculture-2026 directory\n",
        "%cd AI-for-Agriculture-2026\n",
        "\n",
        "!git branch # check current branch\n",
        "\n",
        "\n",
        "print(\"[OK] Clone repo successfully\")"
      ],
      "metadata": {
        "id": "aMxU5HwC1Tou",
        "outputId": "8abcd6e2-b40a-4821-ba9a-62ac5f461e52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "aMxU5HwC1Tou",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AI-for-Agriculture-2026'...\n",
            "remote: Enumerating objects: 3125, done.\u001b[K\n",
            "remote: Total 3125 (delta 0), reused 0 (delta 0), pack-reused 3125 (from 2)\u001b[K\n",
            "Receiving objects: 100% (3125/3125), 768.40 MiB | 16.81 MiB/s, done.\n",
            "Resolving deltas: 100% (114/114), done.\n",
            "Updating files: 100% (3007/3007), done.\n",
            "/content/AI-for-Agriculture-2026\n",
            "* \u001b[32mHongPhuc\u001b[m\n",
            "[OK] Clone repo successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Config git user"
      ],
      "metadata": {
        "id": "uxyge_qY1jfC"
      },
      "id": "uxyge_qY1jfC"
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name \"doduyquy\"\n",
        "!git config --global user.email \"doduyquy211@gmail.com\""
      ],
      "metadata": {
        "id": "bWI8JfbB1kxz"
      },
      "id": "bWI8JfbB1kxz",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***!!! WARNING !!!***"
      ],
      "metadata": {
        "id": "I-lqInUZ1jcP"
      },
      "id": "I-lqInUZ1jcP"
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GITHUB_TOKEN\"] = \"\""
      ],
      "metadata": {
        "id": "j6R-Dc9d1p7D"
      },
      "id": "j6R-Dc9d1p7D",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config"
      ],
      "metadata": {
        "id": "IjE9JvsB1u8n"
      },
      "id": "IjE9JvsB1u8n"
    },
    {
      "cell_type": "code",
      "source": [
        "# print working dir\n",
        "!pwd"
      ],
      "metadata": {
        "id": "rO7OyeSI15cm",
        "outputId": "8cc9564c-ad0f-4373-bc5d-72a83a432577",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "rO7OyeSI15cm",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AI-for-Agriculture-2026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "current_challenge_dir= Path.cwd()\n",
        "notebooks_dir = current_challenge_dir.resolve() / \"notebooks\"\n",
        "checkpoint_dir = current_challenge_dir / 'checkpoints'\n",
        "\n",
        "ROOT_DATASET_TRAIN = current_challenge_dir.resolve() / 'data' / 'raw' / 'train'\n",
        "RGB_DIR = ROOT_DATASET_TRAIN / \"RGB\"\n",
        "MS_DIR  = ROOT_DATASET_TRAIN / \"MS\"\n",
        "HS_DIR  = ROOT_DATASET_TRAIN / \"HS\"\n",
        "\n",
        "\n",
        "SPLIT_DIR = notebooks_dir / 'split' / 'splits'\n",
        "VAL_IDX_PATH = SPLIT_DIR / 'val_idx.npy'\n",
        "TRAIN_IDX_FILE = SPLIT_DIR / \"train_idx.npy\"\n",
        "\n",
        "\n",
        "CKPT_069 = checkpoint_dir / '069_kaggle'\n",
        "# CKPT_RGB = CKPT_069 / 'best_rgb_resnet18_224.pth'\n",
        "CKPT_RGB = checkpoint_dir / 'rgb_resnet18_aug-v5_full_combo_img224_batch8_epoch20_lr0.0001.pth'\n",
        "CKPT_MS  = CKPT_069 / 'best_ms_resnet18_224.pth'\n",
        "CKPT_HS  = CKPT_069 / 'best_hs_topK20_resnet18_224.pth'\n",
        "\n",
        "ROOT_DATASET_VAL = current_challenge_dir.resolve() / 'data' / 'raw' / 'val'\n",
        "TEST_RGB_DIR = os.path.join(ROOT_DATASET_VAL, \"RGB\")\n",
        "TEST_MS_DIR  = os.path.join(ROOT_DATASET_VAL, \"MS\")\n",
        "TEST_HS_DIR  = os.path.join(ROOT_DATASET_VAL, \"HS\")\n",
        "\n",
        "OUT_SUB_DIR = notebooks_dir / 'LateFusion'\n",
        "\n",
        "\n",
        "# Check\n",
        "print(f\"Val idx: {VAL_IDX_PATH}\")\n",
        "print(f\"Checkpoint RGB: {CKPT_RGB}\")\n",
        "print(f\"Checkpoint MS: {CKPT_MS}\")\n",
        "print(f\"Checkpoint HS: {CKPT_HS}\")\n",
        "print(f\"Training data RGB: {RGB_DIR}\")\n",
        "print(f\"Testing data MS: {TEST_MS_DIR}\")\n",
        "print(f\"Train split idx file: {TRAIN_IDX_FILE}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "8j2zc9SkyI8h",
        "outputId": "c4baf9e2-0cc8-49f3-ef1f-2b683292705a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8j2zc9SkyI8h",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val idx: /content/AI-for-Agriculture-2026/notebooks/split/splits/val_idx.npy\n",
            "Checkpoint RGB: /content/AI-for-Agriculture-2026/checkpoints/rgb_resnet18_aug-v5_full_combo_img224_batch8_epoch20_lr0.0001.pth\n",
            "Checkpoint MS: /content/AI-for-Agriculture-2026/checkpoints/069_kaggle/best_ms_resnet18_224.pth\n",
            "Checkpoint HS: /content/AI-for-Agriculture-2026/checkpoints/069_kaggle/best_hs_topK20_resnet18_224.pth\n",
            "Training data RGB: /content/AI-for-Agriculture-2026/data/raw/train/RGB\n",
            "Testing data MS: /content/AI-for-Agriculture-2026/data/raw/val/MS\n",
            "Train split idx file: /content/AI-for-Agriculture-2026/notebooks/split/splits/train_idx.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get checkpoint file name (without extension)\n",
        "ckpt_rgb_fn = Path(CKPT_RGB).stem\n",
        "ckpt_ms_fn = Path(CKPT_MS).stem\n",
        "ckpt_hs_fn = Path(CKPT_HS).stem\n",
        "\n",
        "submission_fn = f\"submission_latefusion_{ckpt_rgb_fn}_{ckpt_ms_fn}_{ckpt_hs_fn}.csv\"\n",
        "\n",
        "print(f\"Submission file name: {submission_fn}\")"
      ],
      "metadata": {
        "id": "lt7DfjPO7f3J",
        "outputId": "dd2872a7-788d-4f26-a726-036551c24db1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "lt7DfjPO7f3J",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file name: submission_latefusion_rgb_resnet18_aug-v5_full_combo_img224_batch8_epoch20_lr0.0001_best_ms_resnet18_224_best_hs_topK20_resnet18_224.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUT_SUB_PATH = OUT_SUB_DIR / submission_fn\n",
        "print(f\"Submission path: {OUT_SUB_PATH}\")"
      ],
      "metadata": {
        "id": "QlJHFB_X7YMP",
        "outputId": "7d08982f-7795-4751-c240-a6e96827a3dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "QlJHFB_X7YMP",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission path: /content/AI-for-Agriculture-2026/notebooks/LateFusion/submission_latefusion_rgb_resnet18_aug-v5_full_combo_img224_batch8_epoch20_lr0.0001_best_ms_resnet18_224_best_hs_topK20_resnet18_224.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cf7e5b55",
      "metadata": {
        "id": "cf7e5b55",
        "outputId": "478e9109-7730-4e6a-d9c4-a985dc4e4c52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE: cpu\n"
          ]
        }
      ],
      "source": [
        "# %% [code]\n",
        "# ====== CONFIG ======\n",
        "\n",
        "IMG_SIZE = 224     # phải giống baseline bạn train (nếu baseline dùng 64)\n",
        "BATCH_SIZE = 8\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "CLASSES = [\"Health\", \"Other\", \"Rust\"]\n",
        "CLASS_TO_IDX = {c:i for i,c in enumerate(CLASSES)}\n",
        "IDX_TO_CLASS = {i:c for c,i in CLASS_TO_IDX.items()}\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def seed_everything(seed=1):\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(1)\n",
        "\n",
        "print(\"DEVICE:\", DEVICE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3861b923",
      "metadata": {
        "id": "3861b923"
      },
      "outputs": [],
      "source": [
        "# %% [code]\n",
        "def label_from_filename(fname: str) -> str:\n",
        "    # lấy prefix class theo list CLASSES\n",
        "    for c in CLASSES:\n",
        "        if fname.lower().startswith(c.lower()):\n",
        "            return c\n",
        "    raise ValueError(f\"Cannot parse label from filename: {fname}\")\n",
        "\n",
        "def key_from_filename(fname: str) -> str:\n",
        "    # bỏ extension + normalize\n",
        "    base = os.path.splitext(fname)[0]\n",
        "    return base.strip().lower()\n",
        "\n",
        "def resize_np_chw(x_chw: np.ndarray, out_hw: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    x_chw: (C,H,W) float32\n",
        "    Resize theo từng channel bằng PIL (bilinear) để đơn giản và ổn định.\n",
        "    \"\"\"\n",
        "    C, H, W = x_chw.shape\n",
        "    out = np.empty((C, out_hw, out_hw), dtype=np.float32)\n",
        "    for c in range(C):\n",
        "        img = Image.fromarray(x_chw[c].astype(np.float32), mode=\"F\")\n",
        "        img = img.resize((out_hw, out_hw), resample=Image.BILINEAR)\n",
        "        out[c] = np.array(img, dtype=np.float32)\n",
        "    return out\n",
        "\n",
        "def normalize_chw(x_chw: np.ndarray, mean: np.ndarray, std: np.ndarray) -> np.ndarray:\n",
        "    # mean,std: shape (C,)\n",
        "    return (x_chw - mean[:, None, None]) / (std[:, None, None] + 1e-6)\n",
        "\n",
        "def clip_per_band(x: torch.Tensor, ql=0.01, qh=0.99) -> torch.Tensor:\n",
        "    \"\"\"Clip mỗi band theo quantile q1/q99. Input/output: (C, H, W).\"\"\"\n",
        "    C = x.shape[0]\n",
        "    flat = x.view(C, -1)\n",
        "    lo = torch.quantile(flat, ql, dim=1).view(-1, 1, 1)\n",
        "    hi = torch.quantile(flat, qh, dim=1).view(-1, 1, 1)\n",
        "    return torch.clamp(x, lo, hi)\n",
        "\n",
        "def ensure_chw_hs(arr):\n",
        "    \"\"\"Đảm bảo HS array có shape (C, H, W) với C=125.\"\"\"\n",
        "    if arr.ndim == 2:\n",
        "        return arr[None, :, :]\n",
        "    if arr.ndim == 3:\n",
        "        if arr.shape[0] in (125, 126):\n",
        "            return arr\n",
        "        if arr.shape[-1] in (125, 126):\n",
        "            return np.transpose(arr, (2, 0, 1))\n",
        "        band_axis = np.argmax(arr.shape)\n",
        "        if band_axis == 2:\n",
        "            return np.transpose(arr, (2, 0, 1))\n",
        "    return arr\n",
        "\n",
        "def fix_bands_125(arr):\n",
        "    \"\"\"Đảm bảo đúng 125 bands.\"\"\"\n",
        "    if arr.shape[0] > 125:\n",
        "        arr = arr[:125]\n",
        "    elif arr.shape[0] < 125:\n",
        "        pad = 125 - arr.shape[0]\n",
        "        arr = np.pad(arr, ((0, pad), (0, 0), (0, 0)), mode=\"edge\")\n",
        "    return arr\n",
        "\n",
        "# ====== NORMALIZATION STATS ======\n",
        "RGB_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
        "RGB_STD  = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
        "\n",
        "# MS: global mean/std computed on TRAIN split after dividing by 65535\n",
        "MS_MEAN = np.array([0.00651217, 0.01202489, 0.01260268, 0.03442739, 0.04236133], dtype=np.float32)\n",
        "MS_STD  = np.array([0.00558527, 0.00672570, 0.00985042, 0.01149776, 0.01547735], dtype=np.float32)\n",
        "\n",
        "# ====== HS TopK-20 config ======\n",
        "# Bands từ Hard-Concrete L0 Gate (sorted)\n",
        "HS_SELECTED_BANDS = [7, 32, 43, 48, 50, 58, 72, 84, 92, 97, 98, 99,\n",
        "                     101, 105, 110, 111, 112, 114, 117, 122]\n",
        "HS_IMG_SIZE = 224   # TopK model dùng 64x64\n",
        "\n",
        "# HS global mean/std sẽ được tính ở cell tiếp theo\n",
        "HS_GLOBAL_MEAN = None  # shape (125,) - tính từ train data\n",
        "HS_GLOBAL_STD  = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "114e9e20",
      "metadata": {
        "id": "114e9e20",
        "outputId": "956fd8ed-9454-4931-a696-66621911478a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RGB files: 600 | MS: 600 | HS: 600\n",
            "Intersection keys (RGB∩MS∩HS): 600\n",
            "Val keys: 116\n",
            "rust_hyper_131 -> Rust\n",
            "other_hyper_85 -> Other\n",
            "health_hyper_62 -> Health\n",
            "other_hyper_137 -> Other\n",
            "rust_hyper_74 -> Rust\n"
          ]
        }
      ],
      "source": [
        "# %% [code]\n",
        "def list_files(dir_path, exts):\n",
        "    return sorted([f for f in os.listdir(dir_path) if f.lower().endswith(exts)])\n",
        "\n",
        "rgb_files = list_files(RGB_DIR, (\".png\", \".jpg\", \".jpeg\"))\n",
        "ms_files  = list_files(MS_DIR,  (\".tif\", \".tiff\"))\n",
        "hs_files  = list_files(HS_DIR,  (\".tif\", \".tiff\"))\n",
        "\n",
        "rgb_map = {key_from_filename(f): f for f in rgb_files}\n",
        "ms_map  = {key_from_filename(f): f for f in ms_files}\n",
        "hs_map  = {key_from_filename(f): f for f in hs_files}\n",
        "\n",
        "# lấy intersection keys có đủ 3 modality\n",
        "all_keys = sorted(set(rgb_map.keys()) & set(ms_map.keys()) & set(hs_map.keys()))\n",
        "print(\"RGB files:\", len(rgb_files), \"| MS:\", len(ms_files), \"| HS:\", len(hs_files))\n",
        "print(\"Intersection keys (RGB∩MS∩HS):\", len(all_keys))\n",
        "\n",
        "# ---- Load val_idx.npy ----\n",
        "val_idx = np.load(VAL_IDX_PATH)\n",
        "val_idx = np.array(val_idx, dtype=int)\n",
        "\n",
        "# CỰC QUAN TRỌNG:\n",
        "# val_idx này phải được tạo dựa trên một list \"chuẩn\" tương thích với all_keys.\n",
        "# Ở đây mình assume val_idx được tạo từ list HS đã sorted theo filename và sau đó key cũng theo sorted.\n",
        "# Nếu split của bạn trước đây dựa trên HS sorted list -> cách này sẽ match tốt khi all_keys cũng được sorted theo key giống HS.\n",
        "#\n",
        "# Nếu bạn muốn chắc chắn tuyệt đối: hãy dùng HS sorted list làm chuẩn split và map sang all_keys theo key.\n",
        "# Ở đây, để chạy ngay, ta sẽ áp val_idx trực tiếp lên all_keys (phổ biến khi bạn đã làm split chung).\n",
        "val_keys = [all_keys[i] for i in val_idx if 0 <= i < len(all_keys)]\n",
        "print(\"Val keys:\", len(val_keys))\n",
        "\n",
        "# sanity check xem label parse ổn\n",
        "for k in val_keys[:5]:\n",
        "    print(k, \"->\", label_from_filename(rgb_map[k]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "19e9bf1c",
      "metadata": {
        "id": "19e9bf1c",
        "outputId": "20900266-d45c-472a-f608-c2b4c5d38d53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing HS global stats on 461 train samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rHS stats:   0%|          | 0/461 [00:00<?, ?it/s]/tmp/ipython-input-738311097.py:22: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  img = Image.fromarray(x_chw[c].astype(np.float32), mode=\"F\")\n",
            "HS stats: 100%|██████████| 461/461 [09:21<00:00,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HS Global Mean[0:5]: [274.33752 332.61566 360.572   378.06027 391.32166]\n",
            "HS Global Std [0:5]: [339.42944 356.93826 363.0298  366.1827  372.26035]\n",
            "HS Global Mean shape: (125,)\n",
            "\n",
            "TopK-20 Mean: [ 418.34137  801.85815  822.22     824.4204   820.9778   864.821\n",
            " 2158.5183  2650.928   2661.856   2651.864   2650.8083  2649.1948\n",
            " 2646.4912  2629.0188  2583.5854  2569.6738  2554.2322  2513.4272\n",
            " 2420.075   2168.3157 ]\n",
            "TopK-20 Std:  [ 382.85593  559.02795  637.8201   665.75323  675.6458   703.6001\n",
            "  837.1711  1098.469   1101.9298  1099.0345  1098.3705  1098.0251\n",
            " 1097.5237  1090.5641  1075.7609  1070.9634  1065.3912  1051.4756\n",
            " 1017.5553   917.4244 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ====== Tính HS global mean/std trên TRAIN split (giống baseline TopK) ======\n",
        "# Pipeline: load → CHW → fix 125 bands → resize 64×64 → clip per-band (q1%-q99%) → accumulate stats\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "\n",
        "# Lấy train files (tất cả trừ val)\n",
        "train_idx = np.load(TRAIN_IDX_FILE)\n",
        "train_idx = np.array(train_idx, dtype=int)\n",
        "train_keys = [all_keys[i] for i in train_idx if 0 <= i < len(all_keys)]\n",
        "\n",
        "print(f\"Computing HS global stats on {len(train_keys)} train samples...\")\n",
        "\n",
        "n_bands = 125\n",
        "pixel_count = 0\n",
        "band_sum = np.zeros(n_bands, dtype=np.float64)\n",
        "band_sum_sq = np.zeros(n_bands, dtype=np.float64)\n",
        "\n",
        "for k in tqdm(train_keys, desc=\"HS stats\"):\n",
        "    path = os.path.join(HS_DIR, hs_map[k])\n",
        "    arr = tiff.imread(path).astype(np.float32)\n",
        "    arr = ensure_chw_hs(arr)\n",
        "    arr = fix_bands_125(arr)\n",
        "    arr = resize_np_chw(arr, HS_IMG_SIZE)  # (125, 64, 64)\n",
        "\n",
        "    # clip per-band (quantile 1%-99%) giống baseline\n",
        "    x = torch.from_numpy(arr)\n",
        "    x = clip_per_band(x, ql=0.01, qh=0.99)\n",
        "    arr = x.numpy()\n",
        "\n",
        "    # accumulate per-band stats\n",
        "    for b in range(n_bands):\n",
        "        band_pixels = arr[b].ravel()\n",
        "        band_sum[b] += band_pixels.sum()\n",
        "        band_sum_sq[b] += (band_pixels ** 2).sum()\n",
        "    pixel_count += arr.shape[1] * arr.shape[2]\n",
        "\n",
        "HS_GLOBAL_MEAN = (band_sum / pixel_count).astype(np.float32)\n",
        "HS_GLOBAL_STD  = np.sqrt(band_sum_sq / pixel_count - (band_sum / pixel_count) ** 2).astype(np.float32)\n",
        "\n",
        "print(f\"HS Global Mean[0:5]: {HS_GLOBAL_MEAN[:5]}\")\n",
        "print(f\"HS Global Std [0:5]: {HS_GLOBAL_STD[:5]}\")\n",
        "print(f\"HS Global Mean shape: {HS_GLOBAL_MEAN.shape}\")\n",
        "\n",
        "# Subset cho 20 selected bands\n",
        "HS_TOPK_MEAN = HS_GLOBAL_MEAN[HS_SELECTED_BANDS]\n",
        "HS_TOPK_STD  = HS_GLOBAL_STD[HS_SELECTED_BANDS]\n",
        "print(f\"\\nTopK-20 Mean: {HS_TOPK_MEAN}\")\n",
        "print(f\"TopK-20 Std:  {HS_TOPK_STD}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ce85fad2",
      "metadata": {
        "id": "ce85fad2",
        "outputId": "6b44505d-4cbe-4da8-ba52-17511fb2308a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val dataset: 116\n"
          ]
        }
      ],
      "source": [
        "# %% [code]\n",
        "class FusionDataset(Dataset):\n",
        "    def __init__(self, keys, rgb_dir, ms_dir, hs_dir, rgb_map, ms_map, hs_map,\n",
        "                 img_size=IMG_SIZE, hs_img_size=IMG_SIZE,\n",
        "                 ms_mean=None, ms_std=None,\n",
        "                 hs_global_mean=None, hs_global_std=None,\n",
        "                 hs_selected_bands=None):\n",
        "        self.keys = keys\n",
        "        self.rgb_dir = rgb_dir\n",
        "        self.ms_dir = ms_dir\n",
        "        self.hs_dir = hs_dir\n",
        "        self.rgb_map = rgb_map\n",
        "        self.ms_map = ms_map\n",
        "        self.hs_map = hs_map\n",
        "        self.img_size = img_size\n",
        "        self.hs_img_size = hs_img_size\n",
        "\n",
        "        self.ms_mean = ms_mean\n",
        "        self.ms_std = ms_std\n",
        "        self.hs_global_mean = hs_global_mean  # shape (125,)\n",
        "        self.hs_global_std = hs_global_std    # shape (125,)\n",
        "        self.hs_selected_bands = hs_selected_bands  # list of 20 indices\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.keys)\n",
        "\n",
        "    def load_rgb(self, path):\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        img = img.resize((self.img_size, self.img_size), resample=Image.BILINEAR)\n",
        "        arr = np.array(img, dtype=np.float32) / 255.0  # HWC 0..1\n",
        "        x = arr.transpose(2,0,1)  # CHW\n",
        "        x = normalize_chw(x, RGB_MEAN, RGB_STD)\n",
        "        return x\n",
        "\n",
        "    def load_ms(self, path):\n",
        "        arr = tiff.imread(path)\n",
        "        if arr.ndim == 2:\n",
        "            arr = arr[None, :, :]\n",
        "        elif arr.ndim == 3:\n",
        "            if arr.shape[0] != 5 and arr.shape[-1] == 5:\n",
        "                arr = np.transpose(arr, (2,0,1))\n",
        "        else:\n",
        "            raise ValueError(f\"MS tif shape not supported: {arr.shape} | {path}\")\n",
        "        arr = arr.astype(np.float32)\n",
        "        arr = arr / 65535.0\n",
        "        arr = resize_np_chw(arr, self.img_size)\n",
        "        if self.ms_mean is not None and self.ms_std is not None:\n",
        "            arr = normalize_chw(arr, self.ms_mean, self.ms_std)\n",
        "        return arr\n",
        "\n",
        "    def load_hs(self, path):\n",
        "        \"\"\"Load HS theo pipeline TopK: 125 bands → resize → clip → Z-score → select 20 bands.\"\"\"\n",
        "        arr = tiff.imread(path).astype(np.float32)\n",
        "        arr = ensure_chw_hs(arr)\n",
        "        arr = fix_bands_125(arr)\n",
        "\n",
        "        # Resize → 64x64\n",
        "        arr = resize_np_chw(arr, self.hs_img_size)\n",
        "\n",
        "        # Clip per-band (quantile 1%-99%)\n",
        "        x = torch.from_numpy(arr)\n",
        "        x = clip_per_band(x, ql=0.01, qh=0.99)\n",
        "        arr = x.numpy()\n",
        "\n",
        "        # Global Z-score normalize (125 bands)\n",
        "        if self.hs_global_mean is not None and self.hs_global_std is not None:\n",
        "            arr = normalize_chw(arr, self.hs_global_mean, self.hs_global_std)\n",
        "\n",
        "        # Select 20 TopK bands\n",
        "        if self.hs_selected_bands is not None:\n",
        "            arr = arr[self.hs_selected_bands]  # (20, 64, 64)\n",
        "\n",
        "        return arr\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        k = self.keys[idx]\n",
        "\n",
        "        rgb_path = os.path.join(self.rgb_dir, self.rgb_map[k])\n",
        "        ms_path  = os.path.join(self.ms_dir,  self.ms_map[k])\n",
        "        hs_path  = os.path.join(self.hs_dir,  self.hs_map[k])\n",
        "\n",
        "        x_rgb = self.load_rgb(rgb_path)\n",
        "        x_ms  = self.load_ms(ms_path)\n",
        "        x_hs  = self.load_hs(hs_path)\n",
        "\n",
        "        y = CLASS_TO_IDX[label_from_filename(self.rgb_map[k])]\n",
        "\n",
        "        return (\n",
        "            torch.from_numpy(x_rgb).float(),\n",
        "            torch.from_numpy(x_ms).float(),\n",
        "            torch.from_numpy(x_hs).float(),\n",
        "            torch.tensor(y, dtype=torch.long),\n",
        "            k\n",
        "        )\n",
        "\n",
        "val_ds = FusionDataset(\n",
        "    keys=val_keys,\n",
        "    rgb_dir=RGB_DIR, ms_dir=MS_DIR, hs_dir=HS_DIR,\n",
        "    rgb_map=rgb_map, ms_map=ms_map, hs_map=hs_map,\n",
        "    img_size=IMG_SIZE,\n",
        "    hs_img_size=HS_IMG_SIZE,\n",
        "    ms_mean=MS_MEAN, ms_std=MS_STD,\n",
        "    hs_global_mean=HS_GLOBAL_MEAN,\n",
        "    hs_global_std=HS_GLOBAL_STD,\n",
        "    hs_selected_bands=HS_SELECTED_BANDS\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(\"Val dataset:\", len(val_ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "c941fa56",
      "metadata": {
        "id": "c941fa56",
        "outputId": "49352c33-32ff-4f13-8089-78887f1754c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RGB ckpt loaded | missing: [] | unexpected: []\n",
            "MS ckpt loaded | missing: [] | unexpected: []\n",
            "HS ckpt loaded | missing: [] | unexpected: []\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(20, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# %% [code]\n",
        "import torchvision\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "def build_resnet18(num_classes=3, in_channels=3, pretrained=False):\n",
        "    \"\"\"\n",
        "    pretrained=False vì checkpoint của bạn là từ baseline đã train rồi.\n",
        "    Nếu bạn muốn init conv1 từ imagenet khi in_channels != 3 thì phải làm thêm logic riêng.\n",
        "    \"\"\"\n",
        "    if pretrained and in_channels == 3:\n",
        "        model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "    else:\n",
        "        model = resnet18(weights=None)\n",
        "\n",
        "    # sửa conv1 nếu in_channels khác 3\n",
        "    if in_channels != 3:\n",
        "        old = model.conv1\n",
        "        model.conv1 = nn.Conv2d(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=old.out_channels,\n",
        "            kernel_size=old.kernel_size,\n",
        "            stride=old.stride,\n",
        "            padding=old.padding,\n",
        "            bias=(old.bias is not None)\n",
        "        )\n",
        "\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "def load_ckpt(model, ckpt_path, device):\n",
        "    ckpt = torch.load(ckpt_path, map_location=device)\n",
        "    # nhiều notebook lưu kiểu {\"model_state\": ...} hoặc lưu thẳng state_dict\n",
        "    if isinstance(ckpt, dict) and \"state_dict\" in ckpt:\n",
        "        state = ckpt[\"state_dict\"]\n",
        "    elif isinstance(ckpt, dict) and \"model_state_dict\" in ckpt:\n",
        "        state = ckpt[\"model_state_dict\"]\n",
        "    elif isinstance(ckpt, dict) and \"model\" in ckpt and isinstance(ckpt[\"model\"], dict):\n",
        "        state = ckpt[\"model\"]\n",
        "    else:\n",
        "        state = ckpt\n",
        "\n",
        "    missing, unexpected = model.load_state_dict(state, strict=True)\n",
        "    return missing, unexpected\n",
        "\n",
        "# build models\n",
        "model_rgb = build_resnet18(num_classes=3, in_channels=3,   pretrained=False).to(DEVICE)\n",
        "model_ms  = build_resnet18(num_classes=3, in_channels=5,   pretrained=False).to(DEVICE)\n",
        "model_hs  = build_resnet18(num_classes=3, in_channels=20,  pretrained=False).to(DEVICE)\n",
        "\n",
        "# load checkpoints\n",
        "miss, unexp = load_ckpt(model_rgb, CKPT_RGB, DEVICE)\n",
        "print(\"RGB ckpt loaded | missing:\", miss, \"| unexpected:\", unexp)\n",
        "\n",
        "miss, unexp = load_ckpt(model_ms, CKPT_MS, DEVICE)\n",
        "print(\"MS ckpt loaded | missing:\", miss, \"| unexpected:\", unexp)\n",
        "\n",
        "miss, unexp = load_ckpt(model_hs, CKPT_HS, DEVICE)\n",
        "print(\"HS ckpt loaded | missing:\", miss, \"| unexpected:\", unexp)\n",
        "\n",
        "model_rgb.eval()\n",
        "model_ms.eval()\n",
        "model_hs.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "147ed663",
      "metadata": {
        "id": "147ed663",
        "outputId": "ee3b6d93-e4a4-43c4-9372-e0bee06c22ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/tmp/ipython-input-738311097.py:22: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  img = Image.fromarray(x_chw[c].astype(np.float32), mode=\"F\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== RGB-only =====\n",
            "Acc     : 0.7931\n",
            "F1-macro: 0.7924\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Health     0.7714    0.6585    0.7105        41\n",
            "       Other     0.9211    0.8750    0.8974        40\n",
            "        Rust     0.6977    0.8571    0.7692        35\n",
            "\n",
            "    accuracy                         0.7931       116\n",
            "   macro avg     0.7967    0.7969    0.7924       116\n",
            "weighted avg     0.8008    0.7931    0.7927       116\n",
            "\n",
            "Confusion matrix:\n",
            " [[27  3 11]\n",
            " [ 3 35  2]\n",
            " [ 5  0 30]]\n",
            "\n",
            "===== MS-only =====\n",
            "Acc     : 0.8534\n",
            "F1-macro: 0.8541\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Health     0.7778    0.8537    0.8140        41\n",
            "       Other     0.9000    0.9000    0.9000        40\n",
            "        Rust     0.9032    0.8000    0.8485        35\n",
            "\n",
            "    accuracy                         0.8534       116\n",
            "   macro avg     0.8603    0.8512    0.8541       116\n",
            "weighted avg     0.8578    0.8534    0.8540       116\n",
            "\n",
            "Confusion matrix:\n",
            " [[35  4  2]\n",
            " [ 3 36  1]\n",
            " [ 7  0 28]]\n",
            "\n",
            "===== HS-only =====\n",
            "Acc     : 0.6983\n",
            "F1-macro: 0.6903\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Health     0.6786    0.4634    0.5507        41\n",
            "       Other     0.8333    0.8750    0.8537        40\n",
            "        Rust     0.5870    0.7714    0.6667        35\n",
            "\n",
            "    accuracy                         0.6983       116\n",
            "   macro avg     0.6996    0.7033    0.6903       116\n",
            "weighted avg     0.7043    0.6983    0.6902       116\n",
            "\n",
            "Confusion matrix:\n",
            " [[19  5 17]\n",
            " [ 3 35  2]\n",
            " [ 6  2 27]]\n",
            "\n",
            "===== Fusion (Equal Avg 1/3) =====\n",
            "Acc     : 0.8534\n",
            "F1-macro: 0.8538\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Health     0.8049    0.8049    0.8049        41\n",
            "       Other     0.9474    0.9000    0.9231        40\n",
            "        Rust     0.8108    0.8571    0.8333        35\n",
            "\n",
            "    accuracy                         0.8534       116\n",
            "   macro avg     0.8544    0.8540    0.8538       116\n",
            "weighted avg     0.8558    0.8534    0.8542       116\n",
            "\n",
            "Confusion matrix:\n",
            " [[33  2  6]\n",
            " [ 3 36  1]\n",
            " [ 5  0 30]]\n",
            "\n",
            "===== Fusion Weighted (RGB=0.3, MS=0.5, HS=0.2) =====\n",
            "Acc     : 0.8448\n",
            "F1-macro: 0.8449\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Health     0.7727    0.8293    0.8000        41\n",
            "       Other     0.9474    0.9000    0.9231        40\n",
            "        Rust     0.8235    0.8000    0.8116        35\n",
            "\n",
            "    accuracy                         0.8448       116\n",
            "   macro avg     0.8479    0.8431    0.8449       116\n",
            "weighted avg     0.8483    0.8448    0.8459       116\n",
            "\n",
            "Confusion matrix:\n",
            " [[34  2  5]\n",
            " [ 3 36  1]\n",
            " [ 7  0 28]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8448275862068966, 0.844890375325158)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# %% [code]\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Custom collate fn\n",
        "def fusion_collate_fn(batch):\n",
        "    x_rgb_list, x_ms_list, x_hs_list, y_list, k_list = [], [], [], [], []\n",
        "    for rgb, ms, hs, y, k in batch:\n",
        "        x_rgb_list.append(rgb)\n",
        "        x_ms_list.append(ms)\n",
        "        x_hs_list.append(hs)\n",
        "        y_list.append(y)\n",
        "        k_list.append(k)\n",
        "    return (\n",
        "        torch.stack(x_rgb_list),\n",
        "        torch.stack(x_ms_list),\n",
        "        torch.stack(x_hs_list),\n",
        "        torch.stack(y_list),\n",
        "        k_list\n",
        "    )\n",
        "\n",
        "# Rebuild DataLoader with custom collate\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True,\n",
        "    collate_fn=fusion_collate_fn\n",
        ")\n",
        "\n",
        "# ====== Thu thập logits thô để dùng cho tối ưu trọng số ======\n",
        "@torch.no_grad()\n",
        "def collect_logits(loader, model_rgb, model_ms, model_hs, device):\n",
        "    \"\"\"Thu thập raw logits từ 3 model + ground truth label.\"\"\"\n",
        "    y_true_all = []\n",
        "    logits_rgb_all = []\n",
        "    logits_ms_all  = []\n",
        "    logits_hs_all  = []\n",
        "\n",
        "    model_rgb.eval(); model_ms.eval(); model_hs.eval()\n",
        "\n",
        "    for x_rgb, x_ms, x_hs, y, keys in loader:\n",
        "        x_rgb = x_rgb.to(device, non_blocking=True)\n",
        "        x_ms  = x_ms.to(device, non_blocking=True)\n",
        "        x_hs  = x_hs.to(device, non_blocking=True)\n",
        "\n",
        "        logits_rgb_all.append(model_rgb(x_rgb).cpu())\n",
        "        logits_ms_all.append(model_ms(x_ms).cpu())\n",
        "        logits_hs_all.append(model_hs(x_hs).cpu())\n",
        "        y_true_all.append(y)\n",
        "\n",
        "    return (\n",
        "        torch.cat(y_true_all).numpy(),\n",
        "        torch.cat(logits_rgb_all).numpy(),\n",
        "        torch.cat(logits_ms_all).numpy(),\n",
        "        torch.cat(logits_hs_all).numpy(),\n",
        "    )\n",
        "\n",
        "y_true, logits_rgb_val, logits_ms_val, logits_hs_val = collect_logits(\n",
        "    val_loader, model_rgb, model_ms, model_hs, DEVICE\n",
        ")\n",
        "\n",
        "# ====== Eval từng model đơn lẻ ======\n",
        "def summarize(name, y_true, y_pred):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1m = f1_score(y_true, y_pred, average=\"macro\")\n",
        "    print(f\"\\n===== {name} =====\")\n",
        "    print(f\"Acc     : {acc:.4f}\")\n",
        "    print(f\"F1-macro: {f1m:.4f}\")\n",
        "    print(classification_report(y_true, y_pred, target_names=CLASSES, digits=4))\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(\"Confusion matrix:\\n\", cm)\n",
        "    return acc, f1m\n",
        "\n",
        "p_rgb = np.argmax(logits_rgb_val, axis=1)\n",
        "p_ms  = np.argmax(logits_ms_val,  axis=1)\n",
        "p_hs  = np.argmax(logits_hs_val,  axis=1)\n",
        "\n",
        "summarize(\"RGB-only\", y_true, p_rgb)\n",
        "summarize(\"MS-only\",  y_true, p_ms)\n",
        "summarize(\"HS-only\",  y_true, p_hs)\n",
        "\n",
        "# ====== Fusion equal average (baseline) ======\n",
        "p_fus_avg = np.argmax((logits_rgb_val + logits_ms_val + logits_hs_val) / 3.0, axis=1)\n",
        "summarize(\"Fusion (Equal Avg 1/3)\", y_true, p_fus_avg)\n",
        "\n",
        "# ====== Weighted fusion: w_MS=0.5, w_RGB=0.3, w_HS=0.2 ======\n",
        "W_RGB, W_MS, W_HS = 0.3, 0.5, 0.2\n",
        "logits_weighted = W_RGB * logits_rgb_val + W_MS * logits_ms_val + W_HS * logits_hs_val\n",
        "p_fus_w = np.argmax(logits_weighted, axis=1)\n",
        "summarize(f\"Fusion Weighted (RGB={W_RGB}, MS={W_MS}, HS={W_HS})\", y_true, p_fus_w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "e3a57f32",
      "metadata": {
        "id": "e3a57f32",
        "outputId": "4376d765-6dcd-438c-fa1a-5021d5122627",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid search done! 231 combinations tested.\n",
            "\n",
            "==================================================\n",
            "BEST WEIGHTS: RGB=0.5, MS=0.5, HS=0.0\n",
            "Best F1-macro: 0.8730 | Best Acc: 0.8707\n",
            "==================================================\n",
            "\n",
            "Top 10 weight combinations (by F1-macro):\n",
            "   RGB     MS     HS      Acc   F1-macro\n",
            "  0.50   0.50   0.00   0.8707     0.8730 <-- BEST\n",
            "  0.55   0.45  -0.00   0.8707     0.8730\n",
            "  0.45   0.45   0.10   0.8707     0.8721\n",
            "  0.00   0.55   0.45   0.8707     0.8714\n",
            "  0.05   0.55   0.40   0.8707     0.8714\n",
            "  0.10   0.60   0.30   0.8707     0.8714\n",
            "  0.00   0.50   0.50   0.8707     0.8713\n",
            "  0.10   0.45   0.45   0.8707     0.8712\n",
            "  0.15   0.60   0.25   0.8707     0.8712\n",
            "  0.40   0.45   0.15   0.8707     0.8712\n",
            "\n",
            "===== Fusion BEST (RGB=0.5, MS=0.5, HS=0.0) =====\n",
            "Acc     : 0.8707\n",
            "F1-macro: 0.8730\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Health     0.7826    0.8780    0.8276        41\n",
            "       Other     0.9459    0.8750    0.9091        40\n",
            "        Rust     0.9091    0.8571    0.8824        35\n",
            "\n",
            "    accuracy                         0.8707       116\n",
            "   macro avg     0.8792    0.8701    0.8730       116\n",
            "weighted avg     0.8771    0.8707    0.8722       116\n",
            "\n",
            "Confusion matrix:\n",
            " [[36  2  3]\n",
            " [ 5 35  0]\n",
            " [ 5  0 30]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8706896551724138, 0.8730100190546438)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# %% [code]\n",
        "# ====== GRID SEARCH tìm trọng số tối ưu trên val set ======\n",
        "from itertools import product\n",
        "\n",
        "best_f1 = -1\n",
        "best_acc = -1\n",
        "best_weights = (0.3, 0.5, 0.2)\n",
        "results = []\n",
        "\n",
        "# Grid search với step = 0.05, tổng = 1.0\n",
        "step = 0.05\n",
        "for w_rgb_i in range(0, 21):          # 0.0 -> 1.0\n",
        "    for w_ms_i in range(0, 21 - w_rgb_i):\n",
        "        w_rgb = round(w_rgb_i * step, 2)\n",
        "        w_ms  = round(w_ms_i * step, 2)\n",
        "        w_hs  = round(1.0 - w_rgb - w_ms, 2)\n",
        "        if w_hs < 0:\n",
        "            continue\n",
        "\n",
        "        logits_fus = w_rgb * logits_rgb_val + w_ms * logits_ms_val + w_hs * logits_hs_val\n",
        "        preds = np.argmax(logits_fus, axis=1)\n",
        "        acc = accuracy_score(y_true, preds)\n",
        "        f1m = f1_score(y_true, preds, average=\"macro\")\n",
        "        results.append((w_rgb, w_ms, w_hs, acc, f1m))\n",
        "\n",
        "        if f1m > best_f1 or (f1m == best_f1 and acc > best_acc):\n",
        "            best_f1 = f1m\n",
        "            best_acc = acc\n",
        "            best_weights = (w_rgb, w_ms, w_hs)\n",
        "\n",
        "print(f\"Grid search done! {len(results)} combinations tested.\")\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"BEST WEIGHTS: RGB={best_weights[0]}, MS={best_weights[1]}, HS={best_weights[2]}\")\n",
        "print(f\"Best F1-macro: {best_f1:.4f} | Best Acc: {best_acc:.4f}\")\n",
        "print(f\"{'='*50}\")\n",
        "\n",
        "# Show top 10\n",
        "results_sorted = sorted(results, key=lambda x: (-x[4], -x[3]))\n",
        "print(\"\\nTop 10 weight combinations (by F1-macro):\")\n",
        "print(f\"{'RGB':>6} {'MS':>6} {'HS':>6} {'Acc':>8} {'F1-macro':>10}\")\n",
        "for w_rgb, w_ms, w_hs, acc, f1m in results_sorted[:10]:\n",
        "    marker = \" <-- BEST\" if (w_rgb, w_ms, w_hs) == best_weights else \"\"\n",
        "    print(f\"{w_rgb:>6.2f} {w_ms:>6.2f} {w_hs:>6.2f} {acc:>8.4f} {f1m:>10.4f}{marker}\")\n",
        "\n",
        "# Eval best weights\n",
        "BEST_W_RGB, BEST_W_MS, BEST_W_HS = best_weights\n",
        "logits_best = BEST_W_RGB * logits_rgb_val + BEST_W_MS * logits_ms_val + BEST_W_HS * logits_hs_val\n",
        "p_fus_best = np.argmax(logits_best, axis=1)\n",
        "summarize(f\"Fusion BEST (RGB={BEST_W_RGB}, MS={BEST_W_MS}, HS={BEST_W_HS})\", y_true, p_fus_best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "a8d15314",
      "metadata": {
        "id": "a8d15314",
        "outputId": "af5f6cc0-956a-49b8-8a18-f87dece99a95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x400 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# %% [code]\n",
        "# ====== Confusion matrices so sánh ======\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "titles_preds = [\n",
        "    (\"Equal Avg (1/3 each)\", np.argmax((logits_rgb_val + logits_ms_val + logits_hs_val)/3, axis=1)),\n",
        "    (f\"Manual (RGB={W_RGB}, MS={W_MS}, HS={W_HS})\", np.argmax(W_RGB*logits_rgb_val + W_MS*logits_ms_val + W_HS*logits_hs_val, axis=1)),\n",
        "    (f\"Grid Best (RGB={BEST_W_RGB}, MS={BEST_W_MS}, HS={BEST_W_HS})\", p_fus_best),\n",
        "]\n",
        "\n",
        "for ax, (title, preds) in zip(axes, titles_preds):\n",
        "    cm = confusion_matrix(y_true, preds)\n",
        "    f1m = f1_score(y_true, preds, average=\"macro\")\n",
        "    ax.imshow(cm, cmap=\"Blues\")\n",
        "    ax.set_title(f\"{title}\\nF1={f1m:.4f}\", fontsize=9)\n",
        "    ax.set_xticks(range(len(CLASSES)))\n",
        "    ax.set_xticklabels(CLASSES, rotation=30, fontsize=8)\n",
        "    ax.set_yticks(range(len(CLASSES)))\n",
        "    ax.set_yticklabels(CLASSES, fontsize=8)\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\", fontsize=11)\n",
        "    ax.set_xlabel(\"Pred\")\n",
        "    ax.set_ylabel(\"True\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "29f344ba",
      "metadata": {
        "id": "29f344ba",
        "outputId": "b41ec06d-33eb-4386-93ed-a647ccfd39fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test files: RGB=300, MS=300, HS=300\n",
            "Test intersection keys (RGB∩MS∩HS): 300\n"
          ]
        }
      ],
      "source": [
        "# %% [code]\n",
        "# ====== KAGGLE SUBMISSION: Late Fusion (RGB + MS + HS) ======\n",
        "\n",
        "# --- List test files ---\n",
        "test_rgb_files = sorted([f for f in os.listdir(TEST_RGB_DIR) if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))])\n",
        "test_ms_files  = sorted([f for f in os.listdir(TEST_MS_DIR)  if f.lower().endswith((\".tif\", \".tiff\"))])\n",
        "test_hs_files  = sorted([f for f in os.listdir(TEST_HS_DIR)  if f.lower().endswith((\".tif\", \".tiff\"))])\n",
        "\n",
        "test_rgb_map = {key_from_filename(f): f for f in test_rgb_files}\n",
        "test_ms_map  = {key_from_filename(f): f for f in test_ms_files}\n",
        "test_hs_map  = {key_from_filename(f): f for f in test_hs_files}\n",
        "\n",
        "test_keys = sorted(set(test_rgb_map.keys()) & set(test_ms_map.keys()) & set(test_hs_map.keys()))\n",
        "print(f\"Test files: RGB={len(test_rgb_files)}, MS={len(test_ms_files)}, HS={len(test_hs_files)}\")\n",
        "print(f\"Test intersection keys (RGB∩MS∩HS): {len(test_keys)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "99309a29",
      "metadata": {
        "id": "99309a29",
        "outputId": "6e9c4c07-9c11-457e-efc5-e00a8a6c9844",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test dataset: 300 samples\n"
          ]
        }
      ],
      "source": [
        "# %% [code]\n",
        "# --- Test Dataset (không có label) ---\n",
        "class TestFusionDataset(Dataset):\n",
        "    def __init__(self, keys, rgb_dir, ms_dir, hs_dir, rgb_map, ms_map, hs_map,\n",
        "                 img_size=IMG_SIZE, hs_img_size=IMG_SIZE,\n",
        "                 ms_mean=None, ms_std=None,\n",
        "                 hs_global_mean=None, hs_global_std=None,\n",
        "                 hs_selected_bands=None):\n",
        "        self.keys = keys\n",
        "        self.rgb_dir = rgb_dir\n",
        "        self.ms_dir = ms_dir\n",
        "        self.hs_dir = hs_dir\n",
        "        self.rgb_map = rgb_map\n",
        "        self.ms_map = ms_map\n",
        "        self.hs_map = hs_map\n",
        "        self.img_size = img_size\n",
        "        self.hs_img_size = hs_img_size\n",
        "        self.ms_mean = ms_mean\n",
        "        self.ms_std = ms_std\n",
        "        self.hs_global_mean = hs_global_mean\n",
        "        self.hs_global_std = hs_global_std\n",
        "        self.hs_selected_bands = hs_selected_bands\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.keys)\n",
        "\n",
        "    def load_rgb(self, path):\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        img = img.resize((self.img_size, self.img_size), resample=Image.BILINEAR)\n",
        "        arr = np.array(img, dtype=np.float32) / 255.0\n",
        "        x = arr.transpose(2,0,1)\n",
        "        x = normalize_chw(x, RGB_MEAN, RGB_STD)\n",
        "        return x\n",
        "\n",
        "    def load_ms(self, path):\n",
        "        arr = tiff.imread(path)\n",
        "        if arr.ndim == 2:\n",
        "            arr = arr[None, :, :]\n",
        "        elif arr.ndim == 3:\n",
        "            if arr.shape[0] != 5 and arr.shape[-1] == 5:\n",
        "                arr = np.transpose(arr, (2,0,1))\n",
        "        else:\n",
        "            raise ValueError(f\"MS tif shape not supported: {arr.shape} | {path}\")\n",
        "        arr = arr.astype(np.float32) / 65535.0\n",
        "        arr = resize_np_chw(arr, self.img_size)\n",
        "        if self.ms_mean is not None and self.ms_std is not None:\n",
        "            arr = normalize_chw(arr, self.ms_mean, self.ms_std)\n",
        "        return arr\n",
        "\n",
        "    def load_hs(self, path):\n",
        "        \"\"\"Load HS theo pipeline TopK: 125 bands → resize → clip → Z-score → select 20 bands.\"\"\"\n",
        "        arr = tiff.imread(path).astype(np.float32)\n",
        "        arr = ensure_chw_hs(arr)\n",
        "        arr = fix_bands_125(arr)\n",
        "\n",
        "        arr = resize_np_chw(arr, self.hs_img_size)\n",
        "\n",
        "        x = torch.from_numpy(arr)\n",
        "        x = clip_per_band(x, ql=0.01, qh=0.99)\n",
        "        arr = x.numpy()\n",
        "\n",
        "        if self.hs_global_mean is not None and self.hs_global_std is not None:\n",
        "            arr = normalize_chw(arr, self.hs_global_mean, self.hs_global_std)\n",
        "\n",
        "        if self.hs_selected_bands is not None:\n",
        "            arr = arr[self.hs_selected_bands]  # (20, 64, 64)\n",
        "\n",
        "        return arr\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        k = self.keys[idx]\n",
        "        x_rgb = self.load_rgb(os.path.join(self.rgb_dir, self.rgb_map[k]))\n",
        "        x_ms  = self.load_ms(os.path.join(self.ms_dir,  self.ms_map[k]))\n",
        "        x_hs  = self.load_hs(os.path.join(self.hs_dir,  self.hs_map[k]))\n",
        "        return (\n",
        "            torch.from_numpy(x_rgb).float(),\n",
        "            torch.from_numpy(x_ms).float(),\n",
        "            torch.from_numpy(x_hs).float(),\n",
        "            k\n",
        "        )\n",
        "\n",
        "test_ds = TestFusionDataset(\n",
        "    keys=test_keys,\n",
        "    rgb_dir=TEST_RGB_DIR, ms_dir=TEST_MS_DIR, hs_dir=TEST_HS_DIR,\n",
        "    rgb_map=test_rgb_map, ms_map=test_ms_map, hs_map=test_hs_map,\n",
        "    img_size=IMG_SIZE,\n",
        "    hs_img_size=HS_IMG_SIZE,\n",
        "    ms_mean=MS_MEAN, ms_std=MS_STD,\n",
        "    hs_global_mean=HS_GLOBAL_MEAN,\n",
        "    hs_global_std=HS_GLOBAL_STD,\n",
        "    hs_selected_bands=HS_SELECTED_BANDS\n",
        ")\n",
        "\n",
        "def test_collate_fn(batch):\n",
        "    x_rgb_list, x_ms_list, x_hs_list, k_list = [], [], [], []\n",
        "    for rgb, ms, hs, k in batch:\n",
        "        x_rgb_list.append(rgb)\n",
        "        x_ms_list.append(ms)\n",
        "        x_hs_list.append(hs)\n",
        "        k_list.append(k)\n",
        "    return torch.stack(x_rgb_list), torch.stack(x_ms_list), torch.stack(x_hs_list), k_list\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True,\n",
        "    collate_fn=test_collate_fn\n",
        ")\n",
        "\n",
        "print(f\"Test dataset: {len(test_ds)} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "8162ab42",
      "metadata": {
        "id": "8162ab42",
        "outputId": "0572deff-e6f6-47ee-d1fa-a7a5f82e8ac8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using BEST weights: RGB=0.5, MS=0.5, HS=0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/tmp/ipython-input-738311097.py:22: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  img = Image.fromarray(x_chw[c].astype(np.float32), mode=\"F\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: 300 samples\n",
            "Distribution: {'Health': 108, 'Other': 93, 'Rust': 99}\n"
          ]
        }
      ],
      "source": [
        "# %% [code]\n",
        "# --- Inference trên test set với BEST WEIGHTS ---\n",
        "@torch.no_grad()\n",
        "def predict_fusion(loader, model_rgb, model_ms, model_hs, device,\n",
        "                   w_rgb=0.3, w_ms=0.5, w_hs=0.2):\n",
        "    all_keys = []\n",
        "    all_preds = []\n",
        "\n",
        "    model_rgb.eval()\n",
        "    model_ms.eval()\n",
        "    model_hs.eval()\n",
        "\n",
        "    for x_rgb, x_ms, x_hs, keys in loader:\n",
        "        x_rgb = x_rgb.to(device, non_blocking=True)\n",
        "        x_ms  = x_ms.to(device, non_blocking=True)\n",
        "        x_hs  = x_hs.to(device, non_blocking=True)\n",
        "\n",
        "        logits_rgb = model_rgb(x_rgb)\n",
        "        logits_ms  = model_ms(x_ms)\n",
        "        logits_hs  = model_hs(x_hs)\n",
        "\n",
        "        # Weighted late fusion\n",
        "        logits_fus = w_rgb * logits_rgb + w_ms * logits_ms + w_hs * logits_hs\n",
        "        preds = torch.argmax(logits_fus, dim=1).cpu().numpy()\n",
        "\n",
        "        all_keys.extend(keys)\n",
        "        all_preds.extend(preds)\n",
        "\n",
        "    return all_keys, np.array(all_preds)\n",
        "\n",
        "# Dùng trọng số tối ưu từ grid search\n",
        "print(f\"Using BEST weights: RGB={BEST_W_RGB}, MS={BEST_W_MS}, HS={BEST_W_HS}\")\n",
        "\n",
        "test_keys_out, test_preds = predict_fusion(\n",
        "    test_loader, model_rgb, model_ms, model_hs, DEVICE,\n",
        "    w_rgb=BEST_W_RGB, w_ms=BEST_W_MS, w_hs=BEST_W_HS\n",
        ")\n",
        "print(f\"Predictions: {len(test_preds)} samples\")\n",
        "print(f\"Distribution: { {c: int((test_preds==i).sum()) for c,i in CLASS_TO_IDX.items()} }\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "9107014c",
      "metadata": {
        "id": "9107014c",
        "outputId": "eb54797d-fe6a-4ee8-8489-b377c33323fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission saved to: /content/AI-for-Agriculture-2026/notebooks/LateFusion/submission_latefusion_rgb_resnet18_aug-v5_full_combo_img224_batch8_epoch20_lr0.0001_best_ms_resnet18_224_best_hs_topK20_resnet18_224.csv\n",
            "Total rows: 300\n",
            "\n",
            "Distribution:\n",
            "Category\n",
            "Health    108\n",
            "Rust       99\n",
            "Other      93\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Head:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Id Category\n",
              "0  val_000a83c1.tif   Health\n",
              "1  val_00a704b1.tif    Other\n",
              "2  val_01dde030.tif   Health\n",
              "3  val_024df365.tif   Health\n",
              "4  val_02afcb0e.tif     Rust\n",
              "5  val_03864ba6.tif   Health\n",
              "6  val_0537e324.tif   Health\n",
              "7  val_059983e0.tif   Health\n",
              "8  val_05cee914.tif    Other\n",
              "9  val_07af871a.tif     Rust"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6ba6eb1-29ce-4ca5-9684-887e1a264976\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>val_000a83c1.tif</td>\n",
              "      <td>Health</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>val_00a704b1.tif</td>\n",
              "      <td>Other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>val_01dde030.tif</td>\n",
              "      <td>Health</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>val_024df365.tif</td>\n",
              "      <td>Health</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>val_02afcb0e.tif</td>\n",
              "      <td>Rust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>val_03864ba6.tif</td>\n",
              "      <td>Health</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>val_0537e324.tif</td>\n",
              "      <td>Health</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>val_059983e0.tif</td>\n",
              "      <td>Health</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>val_05cee914.tif</td>\n",
              "      <td>Other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>val_07af871a.tif</td>\n",
              "      <td>Rust</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6ba6eb1-29ce-4ca5-9684-887e1a264976')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a6ba6eb1-29ce-4ca5-9684-887e1a264976 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a6ba6eb1-29ce-4ca5-9684-887e1a264976');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "sub_df",
              "summary": "{\n  \"name\": \"sub_df\",\n  \"rows\": 300,\n  \"fields\": [\n    {\n      \"column\": \"Id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 300,\n        \"samples\": [\n          \"val_b826d518.tif\",\n          \"val_e9ce960f.tif\",\n          \"val_94d72cf9.tif\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Health\",\n          \"Other\",\n          \"Rust\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# %% [code]\n",
        "# --- Tạo file submission CSV ---\n",
        "# Format Kaggle: columns = [\"Id\", \"Category\"]\n",
        "# Id = filename .tif (ưu tiên HS/MS), Category = Health/Rust/Other\n",
        "\n",
        "submission_rows = []\n",
        "for k, pred_idx in zip(test_keys_out, test_preds):\n",
        "    # Lấy filename .tif từ HS hoặc MS (Kaggle dùng .tif)\n",
        "    if k in test_hs_map:\n",
        "        file_id = test_hs_map[k]\n",
        "    elif k in test_ms_map:\n",
        "        file_id = test_ms_map[k]\n",
        "    else:\n",
        "        file_id = test_rgb_map[k]\n",
        "\n",
        "    label = IDX_TO_CLASS[int(pred_idx)]\n",
        "    submission_rows.append({\"Id\": file_id, \"Category\": label})\n",
        "\n",
        "sub_df = pd.DataFrame(submission_rows)\n",
        "sub_df = sub_df.sort_values(\"Id\").reset_index(drop=True)\n",
        "sub_df.to_csv(OUT_SUB_PATH, index=False)\n",
        "\n",
        "print(f\"Submission saved to: {OUT_SUB_PATH}\")\n",
        "print(f\"Total rows: {len(sub_df)}\")\n",
        "print(f\"\\nDistribution:\")\n",
        "print(sub_df[\"Category\"].value_counts())\n",
        "print(f\"\\nHead:\")\n",
        "sub_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Push to GitHub"
      ],
      "metadata": {
        "id": "gGoSc-PL83Sk"
      },
      "id": "gGoSc-PL83Sk"
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --list"
      ],
      "metadata": {
        "id": "f3wmlTyY826F"
      },
      "id": "f3wmlTyY826F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "push_msg = f\"latefusion: {submission_fn}\"\n",
        "\n",
        "!git add /content/AI-for-Agriculture-2026/checkpoints/ /content/AI-for-Agriculture-2026/notebooks/LateFusion/submission_latefusion_rgb_resnet18_aug-v5_full_combo_img224_batch8_epoch20_lr0.0001_best_ms_resnet18_224_best_hs_topK20_resnet18_224.csv\n",
        "!git commit -m \"{push_msg}\"\n",
        "!git push https://doduyquy:${GITHUB_TOKEN}@github.com/doduyquy/AI-for-Agriculture-2026.git HongPhuc\n",
        "print(f\"Push to github successfully with message: {push_msg}\")"
      ],
      "metadata": {
        "id": "DcFTaKac_edx",
        "outputId": "1dd8e278-b968-43cd-f564-3694c4f41776",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "DcFTaKac_edx",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HongPhuc 291e452] latefusion: submission_latefusion_rgb_resnet18_aug-v5_full_combo_img224_batch8_epoch20_lr0.0001_best_ms_resnet18_224_best_hs_topK20_resnet18_224.csv\n",
            " 1 file changed, 301 insertions(+)\n",
            " create mode 100644 notebooks/LateFusion/submission_latefusion_rgb_resnet18_aug-v5_full_combo_img224_batch8_epoch20_lr0.0001_best_ms_resnet18_224_best_hs_topK20_resnet18_224.csv\n",
            "Enumerating objects: 8, done.\n",
            "Counting objects: 100% (8/8), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (5/5), done.\n",
            "Writing objects: 100% (5/5), 2.43 KiB | 2.43 MiB/s, done.\n",
            "Total 5 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/doduyquy/AI-for-Agriculture-2026.git\n",
            "   1c25ba3..291e452  HongPhuc -> HongPhuc\n",
            "Push to github successfully with message: latefusion: submission_latefusion_rgb_resnet18_aug-v5_full_combo_img224_batch8_epoch20_lr0.0001_best_ms_resnet18_224_best_hs_topK20_resnet18_224.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### The end"
      ],
      "metadata": {
        "id": "pVR3QNLm8Trp"
      },
      "id": "pVR3QNLm8Trp"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "djvadbil9wUh"
      },
      "id": "djvadbil9wUh",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}