{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb1d117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "import tifffile as tiff\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf7e5b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "# ====== CONFIG ======\n",
    "ROOT = r\"D:\\GitHub\\AI-for-Agriculture-2026\\dataset\\train\"  # chỉnh đúng\n",
    "RGB_DIR = os.path.join(ROOT, \"RGB\")\n",
    "MS_DIR  = os.path.join(ROOT, \"MS\")\n",
    "HS_DIR  = os.path.join(ROOT, \"HS\")\n",
    "\n",
    "VAL_IDX_PATH = r\"D:\\HocTap\\NCKH_ThayDoNhuTai\\Challenges\\Notebooks\\split\\splits\\val_idx.npy\"  # chỉnh đúng\n",
    "\n",
    "CKPT_RGB = r\"D:\\HocTap\\NCKH_ThayDoNhuTai\\Challenges\\checkpoints\\best_rgb_resnet18.pth\"\n",
    "CKPT_MS  = r\"D:\\HocTap\\NCKH_ThayDoNhuTai\\Challenges\\checkpoints\\best_ms_resnet18.pth\"\n",
    "CKPT_HS  = r\"D:\\HocTap\\NCKH_ThayDoNhuTai\\Challenges\\checkpoints\\best_hs_topK20_resnet18.pth\"\n",
    "\n",
    "IMG_SIZE = 64     # phải giống baseline bạn train (nếu baseline dùng 64)\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "CLASSES = [\"Health\", \"Other\", \"Rust\"]\n",
    "CLASS_TO_IDX = {c:i for i,c in enumerate(CLASSES)}\n",
    "IDX_TO_CLASS = {i:c for c,i in CLASS_TO_IDX.items()}\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def seed_everything(seed=1):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(1)\n",
    "\n",
    "print(\"DEVICE:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3861b923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "import json\n",
    "\n",
    "def label_from_filename(fname: str) -> str:\n",
    "    for c in CLASSES:\n",
    "        if fname.lower().startswith(c.lower()):\n",
    "            return c\n",
    "    raise ValueError(f\"Cannot parse label from filename: {fname}\")\n",
    "\n",
    "def key_from_filename(fname: str) -> str:\n",
    "    base = os.path.splitext(fname)[0]\n",
    "    return base.strip().lower()\n",
    "\n",
    "def resize_np_chw(x_chw: np.ndarray, out_hw: int) -> np.ndarray:\n",
    "    C, H, W = x_chw.shape\n",
    "    out = np.empty((C, out_hw, out_hw), dtype=np.float32)\n",
    "    for c in range(C):\n",
    "        img = Image.fromarray(x_chw[c].astype(np.float32), mode=\"F\")\n",
    "        img = img.resize((out_hw, out_hw), resample=Image.BILINEAR)\n",
    "        out[c] = np.array(img, dtype=np.float32)\n",
    "    return out\n",
    "\n",
    "def normalize_chw(x_chw: np.ndarray, mean: np.ndarray, std: np.ndarray) -> np.ndarray:\n",
    "    return (x_chw - mean[:, None, None]) / (std[:, None, None] + 1e-6)\n",
    "\n",
    "def clip_per_band(x: torch.Tensor, ql=0.01, qh=0.99) -> torch.Tensor:\n",
    "    \"\"\"Clip mỗi band theo quantile q1/q99. Input/output: (C, H, W).\"\"\"\n",
    "    C = x.shape[0]\n",
    "    flat = x.view(C, -1)\n",
    "    lo = torch.quantile(flat, ql, dim=1).view(-1, 1, 1)\n",
    "    hi = torch.quantile(flat, qh, dim=1).view(-1, 1, 1)\n",
    "    return torch.clamp(x, lo, hi)\n",
    "\n",
    "# ====== NORMALIZATION STATS ======\n",
    "RGB_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "RGB_STD  = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "\n",
    "# MS: global mean/std computed on TRAIN split after dividing by 65535\n",
    "MS_MEAN = np.array([0.00651217, 0.01202489, 0.01260268, 0.03442739, 0.04236133], dtype=np.float32)\n",
    "MS_STD  = np.array([0.00558527, 0.00672570, 0.00985042, 0.01149776, 0.01547735], dtype=np.float32)\n",
    "\n",
    "# ====== HS TopK-20 config ======\n",
    "# Bands từ Hard-Concrete L0 Gate (sorted)\n",
    "HS_SELECTED_BANDS = [7, 32, 43, 48, 50, 58, 72, 84, 92, 97, 98, 99,\n",
    "                     101, 105, 110, 111, 112, 114, 117, 122]\n",
    "HS_IMG_SIZE = 64   # TopK model dùng 64x64 (khác full HS dùng 32x32)\n",
    "\n",
    "# HS global mean/std sẽ được tính ở cell tiếp theo\n",
    "HS_GLOBAL_MEAN = None  # shape (125,) - tính từ train data\n",
    "HS_GLOBAL_STD  = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "114e9e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB files: 577 | MS: 577 | HS: 577\n",
      "Intersection keys (RGB∩MS∩HS): 577\n",
      "Val keys: 116\n",
      "rust_hyper_152 -> Rust\n",
      "rust_hyper_105 -> Rust\n",
      "health_hyper_7 -> Health\n",
      "other_hyper_15 -> Other\n",
      "rust_hyper_95 -> Rust\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "def list_files(dir_path, exts):\n",
    "    return sorted([f for f in os.listdir(dir_path) if f.lower().endswith(exts)])\n",
    "\n",
    "rgb_files = list_files(RGB_DIR, (\".png\", \".jpg\", \".jpeg\"))\n",
    "ms_files  = list_files(MS_DIR,  (\".tif\", \".tiff\"))\n",
    "hs_files  = list_files(HS_DIR,  (\".tif\", \".tiff\"))\n",
    "\n",
    "rgb_map = {key_from_filename(f): f for f in rgb_files}\n",
    "ms_map  = {key_from_filename(f): f for f in ms_files}\n",
    "hs_map  = {key_from_filename(f): f for f in hs_files}\n",
    "\n",
    "# lấy intersection keys có đủ 3 modality\n",
    "all_keys = sorted(set(rgb_map.keys()) & set(ms_map.keys()) & set(hs_map.keys()))\n",
    "print(\"RGB files:\", len(rgb_files), \"| MS:\", len(ms_files), \"| HS:\", len(hs_files))\n",
    "print(\"Intersection keys (RGB∩MS∩HS):\", len(all_keys))\n",
    "\n",
    "# ---- Load val_idx.npy ----\n",
    "val_idx = np.load(VAL_IDX_PATH)\n",
    "val_idx = np.array(val_idx, dtype=int)\n",
    "\n",
    "# CỰC QUAN TRỌNG:\n",
    "# val_idx này phải được tạo dựa trên một list \"chuẩn\" tương thích với all_keys.\n",
    "# Ở đây mình assume val_idx được tạo từ list HS đã sorted theo filename và sau đó key cũng theo sorted.\n",
    "# Nếu split của bạn trước đây dựa trên HS sorted list -> cách này sẽ match tốt khi all_keys cũng được sorted theo key giống HS.\n",
    "#\n",
    "# Nếu bạn muốn chắc chắn tuyệt đối: hãy dùng HS sorted list làm chuẩn split và map sang all_keys theo key.\n",
    "# Ở đây, để chạy ngay, ta sẽ áp val_idx trực tiếp lên all_keys (phổ biến khi bạn đã làm split chung).\n",
    "val_keys = [all_keys[i] for i in val_idx if 0 <= i < len(all_keys)]\n",
    "print(\"Val keys:\", len(val_keys))\n",
    "\n",
    "# sanity check xem label parse ổn\n",
    "for k in val_keys[:5]:\n",
    "    print(k, \"->\", label_from_filename(rgb_map[k]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c13b352f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing HS global stats on 461 train samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HS stats: 100%|██████████| 461/461 [00:13<00:00, 34.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HS Global Mean[0:5]: [273.14627 330.85364 361.67108 378.8944  390.42963]\n",
      "HS Global Std [0:5]: [320.62762 337.5937  344.18594 345.93216 348.84344]\n",
      "HS Global Mean shape: (125,)\n",
      "\n",
      "TopK-20 Mean: [ 419.11826  812.9561   829.61334  829.69415  825.6685   870.10394\n",
      " 2255.6812  2775.3604  2785.1318  2774.2727  2773.3323  2771.702\n",
      " 2768.2466  2749.2087  2699.9448  2685.2603  2668.8267  2624.4062\n",
      " 2524.873   2258.3933 ]\n",
      "TopK-20 Std:  [358.47552 518.0874  599.7242  628.6103  639.36975 666.3828  727.7671\n",
      " 984.47974 986.8003  984.55835 984.10736 983.90924 984.09735 977.6791\n",
      " 964.6898  960.8005  956.25214 943.71234 912.6187  821.5273 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "# ====== Tính HS global mean/std trên TRAIN split (giống baseline TopK) ======\n",
    "# Pipeline: load → CHW → fix 125 bands → resize 64×64 → clip per-band (q1%-q99%) → accumulate stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "def ensure_chw_hs(arr):\n",
    "    \"\"\"Đảm bảo HS array có shape (C, H, W) với C=125.\"\"\"\n",
    "    if arr.ndim == 2:\n",
    "        return arr[None, :, :]\n",
    "    if arr.ndim == 3:\n",
    "        if arr.shape[0] in (125, 126):\n",
    "            return arr\n",
    "        if arr.shape[-1] in (125, 126):\n",
    "            return np.transpose(arr, (2, 0, 1))\n",
    "        # fallback\n",
    "        band_axis = np.argmax(arr.shape)\n",
    "        if band_axis == 2:\n",
    "            return np.transpose(arr, (2, 0, 1))\n",
    "    return arr\n",
    "\n",
    "def fix_bands_125(arr):\n",
    "    \"\"\"Đảm bảo đúng 125 bands.\"\"\"\n",
    "    if arr.shape[0] > 125:\n",
    "        arr = arr[:125]\n",
    "    elif arr.shape[0] < 125:\n",
    "        pad = 125 - arr.shape[0]\n",
    "        # pad bằng mean spatial của band cuối\n",
    "        arr = np.pad(arr, ((0, pad), (0, 0), (0, 0)), mode=\"edge\")\n",
    "    return arr\n",
    "\n",
    "# Lấy train files (tất cả trừ val)\n",
    "train_idx = np.load(r\"D:\\HocTap\\NCKH_ThayDoNhuTai\\Challenges\\Notebooks\\split\\splits\\train_idx.npy\")\n",
    "train_idx = np.array(train_idx, dtype=int)\n",
    "train_keys = [all_keys[i] for i in train_idx if 0 <= i < len(all_keys)]\n",
    "\n",
    "print(f\"Computing HS global stats on {len(train_keys)} train samples...\")\n",
    "\n",
    "n_bands = 125\n",
    "pixel_count = 0\n",
    "band_sum = np.zeros(n_bands, dtype=np.float64)\n",
    "band_sum_sq = np.zeros(n_bands, dtype=np.float64)\n",
    "\n",
    "for k in tqdm(train_keys, desc=\"HS stats\"):\n",
    "    path = os.path.join(HS_DIR, hs_map[k])\n",
    "    arr = tiff.imread(path).astype(np.float32)\n",
    "    arr = ensure_chw_hs(arr)\n",
    "    arr = fix_bands_125(arr)\n",
    "    arr = resize_np_chw(arr, HS_IMG_SIZE)  # (125, 64, 64)\n",
    "\n",
    "    # clip per-band (quantile 1%-99%) giống baseline\n",
    "    x = torch.from_numpy(arr)\n",
    "    x = clip_per_band(x, ql=0.01, qh=0.99)\n",
    "    arr = x.numpy()\n",
    "\n",
    "    # accumulate per-band stats\n",
    "    for b in range(n_bands):\n",
    "        band_pixels = arr[b].ravel()\n",
    "        band_sum[b] += band_pixels.sum()\n",
    "        band_sum_sq[b] += (band_pixels ** 2).sum()\n",
    "    pixel_count += arr.shape[1] * arr.shape[2]\n",
    "\n",
    "HS_GLOBAL_MEAN = (band_sum / pixel_count).astype(np.float32)\n",
    "HS_GLOBAL_STD  = np.sqrt(band_sum_sq / pixel_count - (band_sum / pixel_count) ** 2).astype(np.float32)\n",
    "\n",
    "print(f\"HS Global Mean[0:5]: {HS_GLOBAL_MEAN[:5]}\")\n",
    "print(f\"HS Global Std [0:5]: {HS_GLOBAL_STD[:5]}\")\n",
    "print(f\"HS Global Mean shape: {HS_GLOBAL_MEAN.shape}\")\n",
    "\n",
    "# Subset cho 20 selected bands\n",
    "HS_TOPK_MEAN = HS_GLOBAL_MEAN[HS_SELECTED_BANDS]\n",
    "HS_TOPK_STD  = HS_GLOBAL_STD[HS_SELECTED_BANDS]\n",
    "print(f\"\\nTopK-20 Mean: {HS_TOPK_MEAN}\")\n",
    "print(f\"TopK-20 Std:  {HS_TOPK_STD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce85fad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val dataset: 116\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "class FusionDataset(Dataset):\n",
    "    def __init__(self, keys, rgb_dir, ms_dir, hs_dir, rgb_map, ms_map, hs_map,\n",
    "                 img_size=64, hs_img_size=64,\n",
    "                 ms_mean=None, ms_std=None,\n",
    "                 hs_global_mean=None, hs_global_std=None,\n",
    "                 hs_selected_bands=None):\n",
    "        self.keys = keys\n",
    "        self.rgb_dir = rgb_dir\n",
    "        self.ms_dir = ms_dir\n",
    "        self.hs_dir = hs_dir\n",
    "        self.rgb_map = rgb_map\n",
    "        self.ms_map = ms_map\n",
    "        self.hs_map = hs_map\n",
    "        self.img_size = img_size\n",
    "        self.hs_img_size = hs_img_size\n",
    "\n",
    "        self.ms_mean = ms_mean\n",
    "        self.ms_std = ms_std\n",
    "        self.hs_global_mean = hs_global_mean  # shape (125,)\n",
    "        self.hs_global_std = hs_global_std    # shape (125,)\n",
    "        self.hs_selected_bands = hs_selected_bands  # list of 20 indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "\n",
    "    def load_rgb(self, path):\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        img = img.resize((self.img_size, self.img_size), resample=Image.BILINEAR)\n",
    "        arr = np.array(img, dtype=np.float32) / 255.0\n",
    "        x = arr.transpose(2,0,1)\n",
    "        x = normalize_chw(x, RGB_MEAN, RGB_STD)\n",
    "        return x\n",
    "\n",
    "    def load_ms(self, path):\n",
    "        arr = tiff.imread(path)\n",
    "        if arr.ndim == 2:\n",
    "            arr = arr[None, :, :]\n",
    "        elif arr.ndim == 3:\n",
    "            if arr.shape[0] != 5 and arr.shape[-1] == 5:\n",
    "                arr = np.transpose(arr, (2,0,1))\n",
    "        else:\n",
    "            raise ValueError(f\"MS tif shape not supported: {arr.shape} | {path}\")\n",
    "        arr = arr.astype(np.float32)\n",
    "        arr = arr / 65535.0\n",
    "        arr = resize_np_chw(arr, self.img_size)\n",
    "        if self.ms_mean is not None and self.ms_std is not None:\n",
    "            arr = normalize_chw(arr, self.ms_mean, self.ms_std)\n",
    "        return arr\n",
    "\n",
    "    def load_hs(self, path):\n",
    "        \"\"\"Load HS theo pipeline TopK: 125 bands → resize → clip → Z-score → select 20 bands.\"\"\"\n",
    "        arr = tiff.imread(path).astype(np.float32)\n",
    "        arr = ensure_chw_hs(arr)\n",
    "        arr = fix_bands_125(arr)\n",
    "\n",
    "        # Resize → 64x64\n",
    "        arr = resize_np_chw(arr, self.hs_img_size)\n",
    "\n",
    "        # Clip per-band (quantile 1%-99%)\n",
    "        x = torch.from_numpy(arr)\n",
    "        x = clip_per_band(x, ql=0.01, qh=0.99)\n",
    "        arr = x.numpy()\n",
    "\n",
    "        # Global Z-score normalize (125 bands)\n",
    "        if self.hs_global_mean is not None and self.hs_global_std is not None:\n",
    "            arr = normalize_chw(arr, self.hs_global_mean, self.hs_global_std)\n",
    "\n",
    "        # Select 20 TopK bands\n",
    "        if self.hs_selected_bands is not None:\n",
    "            arr = arr[self.hs_selected_bands]  # (20, 64, 64)\n",
    "\n",
    "        return arr\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        k = self.keys[idx]\n",
    "        rgb_path = os.path.join(self.rgb_dir, self.rgb_map[k])\n",
    "        ms_path  = os.path.join(self.ms_dir,  self.ms_map[k])\n",
    "        hs_path  = os.path.join(self.hs_dir,  self.hs_map[k])\n",
    "\n",
    "        x_rgb = self.load_rgb(rgb_path)\n",
    "        x_ms  = self.load_ms(ms_path)\n",
    "        x_hs  = self.load_hs(hs_path)\n",
    "\n",
    "        y = CLASS_TO_IDX[label_from_filename(self.rgb_map[k])]\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(x_rgb).float(),\n",
    "            torch.from_numpy(x_ms).float(),\n",
    "            torch.from_numpy(x_hs).float(),\n",
    "            torch.tensor(y, dtype=torch.long),\n",
    "            k\n",
    "        )\n",
    "\n",
    "val_ds = FusionDataset(\n",
    "    keys=val_keys,\n",
    "    rgb_dir=RGB_DIR, ms_dir=MS_DIR, hs_dir=HS_DIR,\n",
    "    rgb_map=rgb_map, ms_map=ms_map, hs_map=hs_map,\n",
    "    img_size=IMG_SIZE,\n",
    "    hs_img_size=HS_IMG_SIZE,\n",
    "    ms_mean=MS_MEAN, ms_std=MS_STD,\n",
    "    hs_global_mean=HS_GLOBAL_MEAN,\n",
    "    hs_global_std=HS_GLOBAL_STD,\n",
    "    hs_selected_bands=HS_SELECTED_BANDS\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"Val dataset:\", len(val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c941fa56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB ckpt loaded | missing: [] | unexpected: []\n",
      "MS ckpt loaded | missing: [] | unexpected: []\n",
      "HS ckpt loaded | missing: [] | unexpected: []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(20, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% [code]\n",
    "import torchvision\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "def build_resnet18(num_classes=3, in_channels=3, pretrained=False):\n",
    "    \"\"\"\n",
    "    pretrained=False vì checkpoint của bạn là từ baseline đã train rồi.\n",
    "    Nếu bạn muốn init conv1 từ imagenet khi in_channels != 3 thì phải làm thêm logic riêng.\n",
    "    \"\"\"\n",
    "    if pretrained and in_channels == 3:\n",
    "        model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "    else:\n",
    "        model = resnet18(weights=None)\n",
    "\n",
    "    # sửa conv1 nếu in_channels khác 3\n",
    "    if in_channels != 3:\n",
    "        old = model.conv1\n",
    "        model.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=old.out_channels,\n",
    "            kernel_size=old.kernel_size,\n",
    "            stride=old.stride,\n",
    "            padding=old.padding,\n",
    "            bias=(old.bias is not None)\n",
    "        )\n",
    "\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def load_ckpt(model, ckpt_path, device):\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    # nhiều notebook lưu kiểu {\"model_state\": ...} hoặc lưu thẳng state_dict\n",
    "    if isinstance(ckpt, dict) and \"state_dict\" in ckpt:\n",
    "        state = ckpt[\"state_dict\"]\n",
    "    elif isinstance(ckpt, dict) and \"model_state_dict\" in ckpt:\n",
    "        state = ckpt[\"model_state_dict\"]\n",
    "    elif isinstance(ckpt, dict) and \"model\" in ckpt and isinstance(ckpt[\"model\"], dict):\n",
    "        state = ckpt[\"model\"]\n",
    "    else:\n",
    "        state = ckpt\n",
    "\n",
    "    missing, unexpected = model.load_state_dict(state, strict=True)\n",
    "    return missing, unexpected\n",
    "\n",
    "# build models\n",
    "model_rgb = build_resnet18(num_classes=3, in_channels=3,   pretrained=False).to(DEVICE)\n",
    "model_ms  = build_resnet18(num_classes=3, in_channels=5,   pretrained=False).to(DEVICE)\n",
    "model_hs  = build_resnet18(num_classes=3, in_channels=20, pretrained=False).to(DEVICE)\n",
    "\n",
    "# load checkpoints\n",
    "miss, unexp = load_ckpt(model_rgb, CKPT_RGB, DEVICE)\n",
    "print(\"RGB ckpt loaded | missing:\", miss, \"| unexpected:\", unexp)\n",
    "\n",
    "miss, unexp = load_ckpt(model_ms, CKPT_MS, DEVICE)\n",
    "print(\"MS ckpt loaded | missing:\", miss, \"| unexpected:\", unexp)\n",
    "\n",
    "miss, unexp = load_ckpt(model_hs, CKPT_HS, DEVICE)\n",
    "print(\"HS ckpt loaded | missing:\", miss, \"| unexpected:\", unexp)\n",
    "\n",
    "model_rgb.eval()\n",
    "model_ms.eval()\n",
    "model_hs.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "147ed663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== RGB-only =====\n",
      "Acc     : 0.5862\n",
      "F1-macro: 0.5941\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Health     0.4474    0.4359    0.4416        39\n",
      "       Other     0.8529    0.7838    0.8169        37\n",
      "        Rust     0.5000    0.5500    0.5238        40\n",
      "\n",
      "    accuracy                         0.5862       116\n",
      "   macro avg     0.6001    0.5899    0.5941       116\n",
      "weighted avg     0.5949    0.5862    0.5896       116\n",
      "\n",
      "Confusion matrix:\n",
      " [[17  3 19]\n",
      " [ 5 29  3]\n",
      " [16  2 22]]\n",
      "\n",
      "===== MS-only =====\n",
      "Acc     : 0.6379\n",
      "F1-macro: 0.6429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Health     0.5455    0.6154    0.5783        39\n",
      "       Other     0.7941    0.7297    0.7606        37\n",
      "        Rust     0.6053    0.5750    0.5897        40\n",
      "\n",
      "    accuracy                         0.6379       116\n",
      "   macro avg     0.6483    0.6400    0.6429       116\n",
      "weighted avg     0.6454    0.6379    0.6404       116\n",
      "\n",
      "Confusion matrix:\n",
      " [[24  2 13]\n",
      " [ 8 27  2]\n",
      " [12  5 23]]\n",
      "\n",
      "===== HS-only =====\n",
      "Acc     : 0.5776\n",
      "F1-macro: 0.5561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Health     0.6875    0.2821    0.4000        39\n",
      "       Other     0.6200    0.8378    0.7126        37\n",
      "        Rust     0.5000    0.6250    0.5556        40\n",
      "\n",
      "    accuracy                         0.5776       116\n",
      "   macro avg     0.6025    0.5816    0.5561       116\n",
      "weighted avg     0.6013    0.5776    0.5534       116\n",
      "\n",
      "Confusion matrix:\n",
      " [[11  8 20]\n",
      " [ 1 31  5]\n",
      " [ 4 11 25]]\n",
      "\n",
      "===== Fusion (Equal Avg 1/3) =====\n",
      "Acc     : 0.6121\n",
      "F1-macro: 0.6187\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Health     0.4571    0.4103    0.4324        39\n",
      "       Other     0.9032    0.7568    0.8235        37\n",
      "        Rust     0.5400    0.6750    0.6000        40\n",
      "\n",
      "    accuracy                         0.6121       116\n",
      "   macro avg     0.6335    0.6140    0.6187       116\n",
      "weighted avg     0.6280    0.6121    0.6150       116\n",
      "\n",
      "Confusion matrix:\n",
      " [[16  3 20]\n",
      " [ 6 28  3]\n",
      " [13  0 27]]\n",
      "\n",
      "===== Fusion Weighted (RGB=0.3, MS=0.5, HS=0.2) =====\n",
      "Acc     : 0.6379\n",
      "F1-macro: 0.6454\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Health     0.5263    0.5128    0.5195        39\n",
      "       Other     0.8788    0.7838    0.8286        37\n",
      "        Rust     0.5556    0.6250    0.5882        40\n",
      "\n",
      "    accuracy                         0.6379       116\n",
      "   macro avg     0.6536    0.6405    0.6454       116\n",
      "weighted avg     0.6488    0.6379    0.6418       116\n",
      "\n",
      "Confusion matrix:\n",
      " [[20  2 17]\n",
      " [ 5 29  3]\n",
      " [13  2 25]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6379310344827587, 0.6454290807231984)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% [code]\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Custom collate fn\n",
    "def fusion_collate_fn(batch):\n",
    "    x_rgb_list, x_ms_list, x_hs_list, y_list, k_list = [], [], [], [], []\n",
    "    for rgb, ms, hs, y, k in batch:\n",
    "        x_rgb_list.append(rgb)\n",
    "        x_ms_list.append(ms)\n",
    "        x_hs_list.append(hs)\n",
    "        y_list.append(y)\n",
    "        k_list.append(k)\n",
    "    return (\n",
    "        torch.stack(x_rgb_list),\n",
    "        torch.stack(x_ms_list),\n",
    "        torch.stack(x_hs_list),\n",
    "        torch.stack(y_list),\n",
    "        k_list\n",
    "    )\n",
    "\n",
    "# Rebuild DataLoader with custom collate\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    collate_fn=fusion_collate_fn\n",
    ")\n",
    "\n",
    "# ====== Thu thập logits thô để dùng cho tối ưu trọng số ======\n",
    "@torch.no_grad()\n",
    "def collect_logits(loader, model_rgb, model_ms, model_hs, device):\n",
    "    \"\"\"Thu thập raw logits từ 3 model + ground truth label.\"\"\"\n",
    "    y_true_all = []\n",
    "    logits_rgb_all = []\n",
    "    logits_ms_all  = []\n",
    "    logits_hs_all  = []\n",
    "\n",
    "    model_rgb.eval(); model_ms.eval(); model_hs.eval()\n",
    "\n",
    "    for x_rgb, x_ms, x_hs, y, keys in loader:\n",
    "        x_rgb = x_rgb.to(device, non_blocking=True)\n",
    "        x_ms  = x_ms.to(device, non_blocking=True)\n",
    "        x_hs  = x_hs.to(device, non_blocking=True)\n",
    "\n",
    "        logits_rgb_all.append(model_rgb(x_rgb).cpu())\n",
    "        logits_ms_all.append(model_ms(x_ms).cpu())\n",
    "        logits_hs_all.append(model_hs(x_hs).cpu())\n",
    "        y_true_all.append(y)\n",
    "\n",
    "    return (\n",
    "        torch.cat(y_true_all).numpy(),\n",
    "        torch.cat(logits_rgb_all).numpy(),\n",
    "        torch.cat(logits_ms_all).numpy(),\n",
    "        torch.cat(logits_hs_all).numpy(),\n",
    "    )\n",
    "\n",
    "y_true, logits_rgb_val, logits_ms_val, logits_hs_val = collect_logits(\n",
    "    val_loader, model_rgb, model_ms, model_hs, DEVICE\n",
    ")\n",
    "\n",
    "# ====== Eval từng model đơn lẻ ======\n",
    "def summarize(name, y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1m = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    print(f\"\\n===== {name} =====\")\n",
    "    print(f\"Acc     : {acc:.4f}\")\n",
    "    print(f\"F1-macro: {f1m:.4f}\")\n",
    "    print(classification_report(y_true, y_pred, target_names=CLASSES, digits=4))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"Confusion matrix:\\n\", cm)\n",
    "    return acc, f1m\n",
    "\n",
    "p_rgb = np.argmax(logits_rgb_val, axis=1)\n",
    "p_ms  = np.argmax(logits_ms_val,  axis=1)\n",
    "p_hs  = np.argmax(logits_hs_val,  axis=1)\n",
    "\n",
    "summarize(\"RGB-only\", y_true, p_rgb)\n",
    "summarize(\"MS-only\",  y_true, p_ms)\n",
    "summarize(\"HS-only\",  y_true, p_hs)\n",
    "\n",
    "# ====== Fusion equal average (baseline) ======\n",
    "p_fus_avg = np.argmax((logits_rgb_val + logits_ms_val + logits_hs_val) / 3.0, axis=1)\n",
    "summarize(\"Fusion (Equal Avg 1/3)\", y_true, p_fus_avg)\n",
    "\n",
    "# ====== Weighted fusion: w_MS=0.5, w_RGB=0.3, w_HS=0.2 ======\n",
    "W_RGB, W_MS, W_HS = 0.3, 0.5, 0.2\n",
    "logits_weighted = W_RGB * logits_rgb_val + W_MS * logits_ms_val + W_HS * logits_hs_val\n",
    "p_fus_w = np.argmax(logits_weighted, axis=1)\n",
    "summarize(f\"Fusion Weighted (RGB={W_RGB}, MS={W_MS}, HS={W_HS})\", y_true, p_fus_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3a57f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search done! 231 combinations tested.\n",
      "\n",
      "==================================================\n",
      "BEST WEIGHTS: RGB=0.15, MS=0.75, HS=0.1\n",
      "Best F1-macro: 0.6784 | Best Acc: 0.6724\n",
      "==================================================\n",
      "\n",
      "Top 10 weight combinations (by F1-macro):\n",
      "   RGB     MS     HS      Acc   F1-macro\n",
      "  0.15   0.75   0.10   0.6724     0.6784 <-- BEST\n",
      "  0.00   0.70   0.30   0.6724     0.6763\n",
      "  0.05   0.70   0.25   0.6724     0.6763\n",
      "  0.00   0.75   0.25   0.6724     0.6758\n",
      "  0.05   0.75   0.20   0.6724     0.6758\n",
      "  0.05   0.80   0.15   0.6724     0.6758\n",
      "  0.20   0.80   0.00   0.6638     0.6702\n",
      "  0.20   0.70   0.10   0.6638     0.6699\n",
      "  0.20   0.75   0.05   0.6638     0.6699\n",
      "  0.25   0.70   0.05   0.6638     0.6699\n",
      "\n",
      "===== Fusion BEST (RGB=0.15, MS=0.75, HS=0.1) =====\n",
      "Acc     : 0.6724\n",
      "F1-macro: 0.6784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Health     0.5581    0.6154    0.5854        39\n",
      "       Other     0.8529    0.7838    0.8169        37\n",
      "        Rust     0.6410    0.6250    0.6329        40\n",
      "\n",
      "    accuracy                         0.6724       116\n",
      "   macro avg     0.6840    0.6747    0.6784       116\n",
      "weighted avg     0.6808    0.6724    0.6756       116\n",
      "\n",
      "Confusion matrix:\n",
      " [[24  2 13]\n",
      " [ 7 29  1]\n",
      " [12  3 25]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6724137931034483, 0.6783928848381015)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% [code]\n",
    "# ====== GRID SEARCH tìm trọng số tối ưu trên val set ======\n",
    "from itertools import product\n",
    "\n",
    "best_f1 = -1\n",
    "best_acc = -1\n",
    "best_weights = (0.3, 0.5, 0.2)\n",
    "results = []\n",
    "\n",
    "# Grid search với step = 0.05, tổng = 1.0\n",
    "step = 0.05\n",
    "for w_rgb_i in range(0, 21):          # 0.0 -> 1.0\n",
    "    for w_ms_i in range(0, 21 - w_rgb_i):\n",
    "        w_rgb = round(w_rgb_i * step, 2)\n",
    "        w_ms  = round(w_ms_i * step, 2)\n",
    "        w_hs  = round(1.0 - w_rgb - w_ms, 2)\n",
    "        if w_hs < 0:\n",
    "            continue\n",
    "\n",
    "        logits_fus = w_rgb * logits_rgb_val + w_ms * logits_ms_val + w_hs * logits_hs_val\n",
    "        preds = np.argmax(logits_fus, axis=1)\n",
    "        acc = accuracy_score(y_true, preds)\n",
    "        f1m = f1_score(y_true, preds, average=\"macro\")\n",
    "        results.append((w_rgb, w_ms, w_hs, acc, f1m))\n",
    "\n",
    "        if f1m > best_f1 or (f1m == best_f1 and acc > best_acc):\n",
    "            best_f1 = f1m\n",
    "            best_acc = acc\n",
    "            best_weights = (w_rgb, w_ms, w_hs)\n",
    "\n",
    "print(f\"Grid search done! {len(results)} combinations tested.\")\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"BEST WEIGHTS: RGB={best_weights[0]}, MS={best_weights[1]}, HS={best_weights[2]}\")\n",
    "print(f\"Best F1-macro: {best_f1:.4f} | Best Acc: {best_acc:.4f}\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# Show top 10\n",
    "results_sorted = sorted(results, key=lambda x: (-x[4], -x[3]))\n",
    "print(\"\\nTop 10 weight combinations (by F1-macro):\")\n",
    "print(f\"{'RGB':>6} {'MS':>6} {'HS':>6} {'Acc':>8} {'F1-macro':>10}\")\n",
    "for w_rgb, w_ms, w_hs, acc, f1m in results_sorted[:10]:\n",
    "    marker = \" <-- BEST\" if (w_rgb, w_ms, w_hs) == best_weights else \"\"\n",
    "    print(f\"{w_rgb:>6.2f} {w_ms:>6.2f} {w_hs:>6.2f} {acc:>8.4f} {f1m:>10.4f}{marker}\")\n",
    "\n",
    "# Eval best weights\n",
    "BEST_W_RGB, BEST_W_MS, BEST_W_HS = best_weights\n",
    "logits_best = BEST_W_RGB * logits_rgb_val + BEST_W_MS * logits_ms_val + BEST_W_HS * logits_hs_val\n",
    "p_fus_best = np.argmax(logits_best, axis=1)\n",
    "summarize(f\"Fusion BEST (RGB={BEST_W_RGB}, MS={BEST_W_MS}, HS={BEST_W_HS})\", y_true, p_fus_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8d15314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %% [code]\n",
    "# ====== Confusion matrices so sánh ======\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "titles_preds = [\n",
    "    (\"Equal Avg (1/3 each)\", np.argmax((logits_rgb_val + logits_ms_val + logits_hs_val)/3, axis=1)),\n",
    "    (f\"Manual (RGB={W_RGB}, MS={W_MS}, HS={W_HS})\", np.argmax(W_RGB*logits_rgb_val + W_MS*logits_ms_val + W_HS*logits_hs_val, axis=1)),\n",
    "    (f\"Grid Best (RGB={BEST_W_RGB}, MS={BEST_W_MS}, HS={BEST_W_HS})\", p_fus_best),\n",
    "]\n",
    "\n",
    "for ax, (title, preds) in zip(axes, titles_preds):\n",
    "    cm = confusion_matrix(y_true, preds)\n",
    "    f1m = f1_score(y_true, preds, average=\"macro\")\n",
    "    ax.imshow(cm, cmap=\"Blues\")\n",
    "    ax.set_title(f\"{title}\\nF1={f1m:.4f}\", fontsize=9)\n",
    "    ax.set_xticks(range(len(CLASSES)))\n",
    "    ax.set_xticklabels(CLASSES, rotation=30, fontsize=8)\n",
    "    ax.set_yticks(range(len(CLASSES)))\n",
    "    ax.set_yticklabels(CLASSES, fontsize=8)\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\", fontsize=11)\n",
    "    ax.set_xlabel(\"Pred\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29f344ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test files: RGB=300, MS=300, HS=300\n",
      "Test intersection keys (RGB∩MS∩HS): 300\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "# ====== KAGGLE SUBMISSION: Late Fusion (RGB + MS + HS) ======\n",
    "import pandas as pd\n",
    "\n",
    "# --- Config ---\n",
    "# Test data = val folder (không có label, dùng để nộp Kaggle)\n",
    "TEST_ROOT = r\"D:\\GitHub\\AI-for-Agriculture-2026\\dataset\\val\"\n",
    "TEST_RGB_DIR = os.path.join(TEST_ROOT, \"RGB\")\n",
    "TEST_MS_DIR  = os.path.join(TEST_ROOT, \"MS\")\n",
    "TEST_HS_DIR  = os.path.join(TEST_ROOT, \"HS\")\n",
    "\n",
    "OUT_SUB_PATH = r\"D:\\HocTap\\NCKH_ThayDoNhuTai\\Challenges\\Notebooks\\LateFusion\\submission_latefusion.csv\"\n",
    "\n",
    "# --- List test files ---\n",
    "test_rgb_files = sorted([f for f in os.listdir(TEST_RGB_DIR) if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))])\n",
    "test_ms_files  = sorted([f for f in os.listdir(TEST_MS_DIR)  if f.lower().endswith((\".tif\", \".tiff\"))])\n",
    "test_hs_files  = sorted([f for f in os.listdir(TEST_HS_DIR)  if f.lower().endswith((\".tif\", \".tiff\"))])\n",
    "\n",
    "test_rgb_map = {key_from_filename(f): f for f in test_rgb_files}\n",
    "test_ms_map  = {key_from_filename(f): f for f in test_ms_files}\n",
    "test_hs_map  = {key_from_filename(f): f for f in test_hs_files}\n",
    "\n",
    "test_keys = sorted(set(test_rgb_map.keys()) & set(test_ms_map.keys()) & set(test_hs_map.keys()))\n",
    "print(f\"Test files: RGB={len(test_rgb_files)}, MS={len(test_ms_files)}, HS={len(test_hs_files)}\")\n",
    "print(f\"Test intersection keys (RGB∩MS∩HS): {len(test_keys)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99309a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset: 300 samples\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "# --- Test Dataset (không có label) ---\n",
    "class TestFusionDataset(Dataset):\n",
    "    def __init__(self, keys, rgb_dir, ms_dir, hs_dir, rgb_map, ms_map, hs_map,\n",
    "                 img_size=64, hs_img_size=64,\n",
    "                 ms_mean=None, ms_std=None,\n",
    "                 hs_global_mean=None, hs_global_std=None,\n",
    "                 hs_selected_bands=None):\n",
    "        self.keys = keys\n",
    "        self.rgb_dir = rgb_dir\n",
    "        self.ms_dir = ms_dir\n",
    "        self.hs_dir = hs_dir\n",
    "        self.rgb_map = rgb_map\n",
    "        self.ms_map = ms_map\n",
    "        self.hs_map = hs_map\n",
    "        self.img_size = img_size\n",
    "        self.hs_img_size = hs_img_size\n",
    "        self.ms_mean = ms_mean\n",
    "        self.ms_std = ms_std\n",
    "        self.hs_global_mean = hs_global_mean\n",
    "        self.hs_global_std = hs_global_std\n",
    "        self.hs_selected_bands = hs_selected_bands\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "\n",
    "    def load_rgb(self, path):\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        img = img.resize((self.img_size, self.img_size), resample=Image.BILINEAR)\n",
    "        arr = np.array(img, dtype=np.float32) / 255.0\n",
    "        x = arr.transpose(2,0,1)\n",
    "        x = normalize_chw(x, RGB_MEAN, RGB_STD)\n",
    "        return x\n",
    "\n",
    "    def load_ms(self, path):\n",
    "        arr = tiff.imread(path)\n",
    "        if arr.ndim == 2:\n",
    "            arr = arr[None, :, :]\n",
    "        elif arr.ndim == 3:\n",
    "            if arr.shape[0] != 5 and arr.shape[-1] == 5:\n",
    "                arr = np.transpose(arr, (2,0,1))\n",
    "        else:\n",
    "            raise ValueError(f\"MS tif shape not supported: {arr.shape} | {path}\")\n",
    "        arr = arr.astype(np.float32) / 65535.0\n",
    "        arr = resize_np_chw(arr, self.img_size)\n",
    "        if self.ms_mean is not None and self.ms_std is not None:\n",
    "            arr = normalize_chw(arr, self.ms_mean, self.ms_std)\n",
    "        return arr\n",
    "\n",
    "    def load_hs(self, path):\n",
    "        \"\"\"Load HS theo pipeline TopK: 125 bands → resize → clip → Z-score → select 20 bands.\"\"\"\n",
    "        arr = tiff.imread(path).astype(np.float32)\n",
    "        arr = ensure_chw_hs(arr)\n",
    "        arr = fix_bands_125(arr)\n",
    "        arr = resize_np_chw(arr, self.hs_img_size)\n",
    "\n",
    "        # Clip per-band (quantile 1%-99%)\n",
    "        x = torch.from_numpy(arr)\n",
    "        x = clip_per_band(x, ql=0.01, qh=0.99)\n",
    "        arr = x.numpy()\n",
    "\n",
    "        # Global Z-score normalize (125 bands)\n",
    "        if self.hs_global_mean is not None and self.hs_global_std is not None:\n",
    "            arr = normalize_chw(arr, self.hs_global_mean, self.hs_global_std)\n",
    "\n",
    "        # Select 20 TopK bands\n",
    "        if self.hs_selected_bands is not None:\n",
    "            arr = arr[self.hs_selected_bands]\n",
    "\n",
    "        return arr\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        k = self.keys[idx]\n",
    "        x_rgb = self.load_rgb(os.path.join(self.rgb_dir, self.rgb_map[k]))\n",
    "        x_ms  = self.load_ms(os.path.join(self.ms_dir,  self.ms_map[k]))\n",
    "        x_hs  = self.load_hs(os.path.join(self.hs_dir,  self.hs_map[k]))\n",
    "        return (\n",
    "            torch.from_numpy(x_rgb).float(),\n",
    "            torch.from_numpy(x_ms).float(),\n",
    "            torch.from_numpy(x_hs).float(),\n",
    "            k\n",
    "        )\n",
    "\n",
    "test_ds = TestFusionDataset(\n",
    "    keys=test_keys,\n",
    "    rgb_dir=TEST_RGB_DIR, ms_dir=TEST_MS_DIR, hs_dir=TEST_HS_DIR,\n",
    "    rgb_map=test_rgb_map, ms_map=test_ms_map, hs_map=test_hs_map,\n",
    "    img_size=IMG_SIZE,\n",
    "    hs_img_size=HS_IMG_SIZE,\n",
    "    ms_mean=MS_MEAN, ms_std=MS_STD,\n",
    "    hs_global_mean=HS_GLOBAL_MEAN,\n",
    "    hs_global_std=HS_GLOBAL_STD,\n",
    "    hs_selected_bands=HS_SELECTED_BANDS\n",
    ")\n",
    "\n",
    "def test_collate_fn(batch):\n",
    "    x_rgb_list, x_ms_list, x_hs_list, k_list = [], [], [], []\n",
    "    for rgb, ms, hs, k in batch:\n",
    "        x_rgb_list.append(rgb)\n",
    "        x_ms_list.append(ms)\n",
    "        x_hs_list.append(hs)\n",
    "        k_list.append(k)\n",
    "    return torch.stack(x_rgb_list), torch.stack(x_ms_list), torch.stack(x_hs_list), k_list\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    collate_fn=test_collate_fn\n",
    ")\n",
    "\n",
    "print(f\"Test dataset: {len(test_ds)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8162ab42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using BEST weights: RGB=0.15, MS=0.75, HS=0.1\n",
      "Predictions: 300 samples\n",
      "Distribution: {'Health': 110, 'Other': 93, 'Rust': 97}\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "# --- Inference trên test set với BEST WEIGHTS ---\n",
    "@torch.no_grad()\n",
    "def predict_fusion(loader, model_rgb, model_ms, model_hs, device,\n",
    "                   w_rgb=0.3, w_ms=0.5, w_hs=0.2):\n",
    "    all_keys = []\n",
    "    all_preds = []\n",
    "\n",
    "    model_rgb.eval()\n",
    "    model_ms.eval()\n",
    "    model_hs.eval()\n",
    "\n",
    "    for x_rgb, x_ms, x_hs, keys in loader:\n",
    "        x_rgb = x_rgb.to(device, non_blocking=True)\n",
    "        x_ms  = x_ms.to(device, non_blocking=True)\n",
    "        x_hs  = x_hs.to(device, non_blocking=True)\n",
    "\n",
    "        logits_rgb = model_rgb(x_rgb)\n",
    "        logits_ms  = model_ms(x_ms)\n",
    "        logits_hs  = model_hs(x_hs)\n",
    "\n",
    "        # Weighted late fusion\n",
    "        logits_fus = w_rgb * logits_rgb + w_ms * logits_ms + w_hs * logits_hs\n",
    "        preds = torch.argmax(logits_fus, dim=1).cpu().numpy()\n",
    "\n",
    "        all_keys.extend(keys)\n",
    "        all_preds.extend(preds)\n",
    "\n",
    "    return all_keys, np.array(all_preds)\n",
    "\n",
    "# Dùng trọng số tối ưu từ grid search\n",
    "print(f\"Using BEST weights: RGB={BEST_W_RGB}, MS={BEST_W_MS}, HS={BEST_W_HS}\")\n",
    "\n",
    "test_keys_out, test_preds = predict_fusion(\n",
    "    test_loader, model_rgb, model_ms, model_hs, DEVICE,\n",
    "    w_rgb=BEST_W_RGB, w_ms=BEST_W_MS, w_hs=BEST_W_HS\n",
    ")\n",
    "print(f\"Predictions: {len(test_preds)} samples\")\n",
    "print(f\"Distribution: { {c: int((test_preds==i).sum()) for c,i in CLASS_TO_IDX.items()} }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9107014c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to: D:\\HocTap\\NCKH_ThayDoNhuTai\\Challenges\\Notebooks\\LateFusion\\submission_latefusion.csv\n",
      "Total rows: 300\n",
      "\n",
      "Distribution:\n",
      "Category\n",
      "Health    110\n",
      "Rust       97\n",
      "Other      93\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>val_000a83c1.tif</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val_00a704b1.tif</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>val_01dde030.tif</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>val_024df365.tif</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>val_02afcb0e.tif</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>val_03864ba6.tif</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>val_0537e324.tif</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>val_059983e0.tif</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>val_05cee914.tif</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>val_07af871a.tif</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Id Category\n",
       "0  val_000a83c1.tif   Health\n",
       "1  val_00a704b1.tif   Health\n",
       "2  val_01dde030.tif    Other\n",
       "3  val_024df365.tif   Health\n",
       "4  val_02afcb0e.tif   Health\n",
       "5  val_03864ba6.tif   Health\n",
       "6  val_0537e324.tif   Health\n",
       "7  val_059983e0.tif     Rust\n",
       "8  val_05cee914.tif    Other\n",
       "9  val_07af871a.tif     Rust"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% [code]\n",
    "# --- Tạo file submission CSV ---\n",
    "# Format Kaggle: columns = [\"Id\", \"Category\"]\n",
    "# Id = filename .tif (ưu tiên HS/MS), Category = Health/Rust/Other\n",
    "\n",
    "submission_rows = []\n",
    "for k, pred_idx in zip(test_keys_out, test_preds):\n",
    "    # Lấy filename .tif từ HS hoặc MS (Kaggle dùng .tif)\n",
    "    if k in test_hs_map:\n",
    "        file_id = test_hs_map[k]\n",
    "    elif k in test_ms_map:\n",
    "        file_id = test_ms_map[k]\n",
    "    else:\n",
    "        file_id = test_rgb_map[k]\n",
    "\n",
    "    label = IDX_TO_CLASS[int(pred_idx)]\n",
    "    submission_rows.append({\"Id\": file_id, \"Category\": label})\n",
    "\n",
    "sub_df = pd.DataFrame(submission_rows)\n",
    "sub_df = sub_df.sort_values(\"Id\").reset_index(drop=True)\n",
    "sub_df.to_csv(OUT_SUB_PATH, index=False)\n",
    "\n",
    "print(f\"Submission saved to: {OUT_SUB_PATH}\")\n",
    "print(f\"Total rows: {len(sub_df)}\")\n",
    "print(f\"\\nDistribution:\")\n",
    "print(sub_df[\"Category\"].value_counts())\n",
    "print(f\"\\nHead:\")\n",
    "sub_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
