"""
check_checkpoints.py - Kiá»ƒm tra metadata cá»§a checkpoints

Má»¥c Ä‘Ã­ch: Xem checkpoint lÆ°u gÃ¬, epoch nÃ o, accuracy bao nhiÃªu
"""

import torch
from pathlib import Path

print("\n" + "="*70)
print("ğŸ” KIá»‚M TRA CHECKPOINTS")
print("="*70)

# Check Step 1
checkpoint_path_step1 = Path('checkpoints/best_model_step1.pth')
if not checkpoint_path_step1.exists():
    print(f"\nâŒ {checkpoint_path_step1} khÃ´ng tá»“n táº¡i!")
else:
    print(f"\nğŸ“¦ Step 1 Checkpoint: {checkpoint_path_step1}")
    checkpoint_step1 = torch.load(checkpoint_path_step1, map_location='cpu')
    
    if isinstance(checkpoint_step1, dict):
        # Check for metadata
        if 'epoch' in checkpoint_step1:
            print(f"  âœ… Epoch: {checkpoint_step1['epoch']}")
        else:
            print(f"  âš ï¸ No epoch metadata")
            
        if 'accuracy' in checkpoint_step1:
            print(f"  âœ… Accuracy: {checkpoint_step1['accuracy']:.3f}")
        else:
            print(f"  âš ï¸ No accuracy metadata")
            
        if 'loss' in checkpoint_step1:
            print(f"  âœ… Loss: {checkpoint_step1['loss']:.3f}")
        else:
            print(f"  âš ï¸ No loss metadata")
        
        # Check state_dict
        if 'model_state_dict' in checkpoint_step1:
            print(f"  âœ… Format: Full checkpoint (with model_state_dict key)")
            state_dict = checkpoint_step1['model_state_dict']
        else:
            print(f"  âš ï¸ Format: state_dict only (no metadata)")
            state_dict = checkpoint_step1
        
        print(f"  ğŸ“Š Total parameter keys: {len(state_dict)}")
        print(f"  ğŸ“ First 5 parameter keys:")
        for i, key in enumerate(list(state_dict.keys())[:5]):
            shape = state_dict[key].shape if hasattr(state_dict[key], 'shape') else 'N/A'
            print(f"    {i+1}. {key}: {shape}")
    else:
        print("  âŒ Not a dict! Checkpoint format khÃ´ng Ä‘Ãºng!")

# Check Step 2
print("\n" + "-"*70)
checkpoint_path_step2 = Path('checkpoints/best_model_step2.pth')
if not checkpoint_path_step2.exists():
    print(f"\nâŒ {checkpoint_path_step2} khÃ´ng tá»“n táº¡i!")
else:
    print(f"\nğŸ“¦ Step 2 Checkpoint: {checkpoint_path_step2}")
    checkpoint_step2 = torch.load(checkpoint_path_step2, map_location='cpu')
    
    if isinstance(checkpoint_step2, dict):
        # Check for metadata
        if 'epoch' in checkpoint_step2:
            print(f"  âœ… Epoch: {checkpoint_step2['epoch']}")
        else:
            print(f"  âš ï¸ No epoch metadata")
            
        if 'accuracy' in checkpoint_step2:
            print(f"  âœ… Accuracy: {checkpoint_step2['accuracy']:.3f}")
        else:
            print(f"  âš ï¸ No accuracy metadata")
            
        if 'loss' in checkpoint_step2:
            print(f"  âœ… Loss: {checkpoint_step2['loss']:.3f}")
        else:
            print(f"  âš ï¸ No loss metadata")
        
        # Check state_dict
        if 'model_state_dict' in checkpoint_step2:
            print(f"  âœ… Format: Full checkpoint (with model_state_dict key)")
            state_dict = checkpoint_step2['model_state_dict']
        else:
            print(f"  âš ï¸ Format: state_dict only (no metadata)")
            state_dict = checkpoint_step2
        
        print(f"  ğŸ“Š Total parameter keys: {len(state_dict)}")
        print(f"  ğŸ“ First 5 parameter keys:")
        for i, key in enumerate(list(state_dict.keys())[:5]):
            shape = state_dict[key].shape if hasattr(state_dict[key], 'shape') else 'N/A'
            print(f"    {i+1}. {key}: {shape}")
    else:
        print("  âŒ Not a dict! Checkpoint format khÃ´ng Ä‘Ãºng!")

print("\n" + "="*70)
print("âœ… Check completed!")
print("="*70 + "\n")
