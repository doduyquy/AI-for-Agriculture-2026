================================================================================
GIáº¢I THÃCH CHI TIáº¾T KIáº¾N TRÃšC MODEL - PIPELINEV1_STAGE1
================================================================================

ğŸ“‹ Má»¤C Lá»¤C:
1. Tá»•ng quan chiáº¿n lÆ°á»£c Stage 1
2. Kiáº¿n trÃºc model chi tiáº¿t
3. LÃ½ do thiáº¿t káº¿ tá»«ng thÃ nh pháº§n
4. Chiáº¿n lÆ°á»£c training
5. Hyperparameters vÃ  lÃ½ do chá»n
6. Augmentation strategy
7. Loss function vÃ  class balancing

================================================================================
1. Tá»”NG QUAN CHIáº¾N LÆ¯á»¢C STAGE 1
================================================================================

ğŸ¯ Bá»I Cáº¢NH:
   - Dataset nhá»: Chá»‰ ~200 samples/class (tá»•ng ~600 samples)
   - 3 loáº¡i dá»¯ liá»‡u: RGB (3 bands), MS (5 bands), HS (125 bands)
   - 3 classes: Health, Rust, Other
   - Má»¥c tiÃªu: Train á»•n Ä‘á»‹nh, trÃ¡nh overfitting, kiá»ƒm chá»©ng pipeline

ğŸ¯ CHIáº¾N LÆ¯á»¢C:
   âœ… ÄÆ¡n giáº£n hÃ³a kiáº¿n trÃºc (bá» cÃ¡c module phá»©c táº¡p)
   âœ… Freeze pretrained backbone (ResNet18) Ä‘á»ƒ táº­n dá»¥ng ImageNet knowledge
   âœ… Chá»‰ train cÃ¡c module spectral (MS/HS) vÃ  fusion
   âœ… Light augmentation (trÃ¡nh há»c noise thay vÃ¬ pattern thá»±c)
   âœ… Class balancing (trÃ¡nh bias vá» class Ä‘Ã´ng nháº¥t)
   âœ… Early stopping aggressive (trÃ¡nh overfit)

================================================================================
2. KIáº¾N TRÃšC MODEL CHI TIáº¾T
================================================================================

ğŸ“ LUá»’NG Dá»® LIá»†U:

RGB (3, 224, 224) 
    â†“
[ResNet18 FROZEN] â†’ Feature maps (512, 7, 7) = F_rgb
                      â†“
                      â†“ (Äá»£i fusion)
                      â†“

MS (5, 224, 224)
    â†“
[MS Encoder] â†’ Feature maps (128, 7, 7) = F_ms
    â†“                                        â†“
    â†“                                        â†“
    â†“                                        â†“
HS (125, 224, 224)                          â†“
    â†“                                        â†“
[HS Encoder] â†’ Feature maps (128, 7, 7) = F_hs
                                            â†“
                                            â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
[Spectral Attention Fusion]
    F_ms (128) + F_hs (128) â†’ F_spec (256, 7, 7)
    â†“
[Projection 256â†’512] â†’ F_spec (512, 7, 7)
    â†“
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“                â†“
F_rgb (512)     F_spec (512)
    â†“                â†“
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
[Context Gated Fusion] â†’ F_fused (512, 7, 7)
             â†“
[Classification Head]
             â†“
    Logits (batch, 3)


ğŸ“Š CHI TIáº¾T CÃC MODULE:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ A. RGB BRANCH - RESNET18 (FROZEN)                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input:  RGB (batch, 3, 224, 224)                                     â”‚
â”‚ Model:  ResNet18 pretrained on ImageNet                              â”‚
â”‚ Output: Feature maps (batch, 512, 7, 7)                              â”‚
â”‚                                                                       â”‚
â”‚ ğŸ”’ FROZEN - KhÃ´ng train, chá»‰ extract features                        â”‚
â”‚                                                                       â”‚
â”‚ LÃ½ do:                                   8 Ä‘Ã£ há»c Ä‘Æ°á»£c texture,                              â”‚
â”‚  âœ“ ResNet1edges, patterns tá»« ImageNet        â”‚
â”‚  âœ“ Dataset quÃ¡ nhá» (600 samples) khÃ´ng Ä‘á»§ Ä‘á»ƒ train láº¡i backbone     â”‚
â”‚  âœ“ TrÃ¡nh catastrophic forgetting (máº¥t kiáº¿n thá»©c pretrain)            â”‚
â”‚  âœ“ Giáº£m sá»‘ parameters cáº§n train â†’ giáº£m overfitting                  â”‚
â”‚  âœ“ á»”n Ä‘á»‹nh gradient (khÃ´ng bá»‹ exploding/vanishing tá»« deep network)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ B. MS ENCODER (TRAINABLE)                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input:  MS (batch, 5, 224, 224)                                      â”‚
â”‚                                                                       â”‚
â”‚ Architecture:                                                         â”‚
â”‚   Conv2d(5â†’32, k=3, p=1) â†’ BN â†’ ReLU â†’ MaxPool(2)                   â”‚
â”‚   â†’ (32, 112, 112)                                                   â”‚
â”‚                                                                       â”‚
â”‚   Conv2d(32â†’64, k=3, p=1) â†’ BN â†’ ReLU â†’ MaxPool(2)                  â”‚
â”‚   â†’ (64, 56, 56)                                                     â”‚
â”‚                                                                       â”‚
â”‚   Conv2d(64â†’128, k=3, p=1) â†’ BN â†’ ReLU â†’ AdaptiveAvgPool(7,7)       â”‚
â”‚   â†’ (128, 7, 7)                                                      â”‚
â”‚                                                                       â”‚
â”‚ Output: F_ms (batch, 128, 7, 7)                                      â”‚
â”‚                                                                       â”‚
â”‚ LÃ½ do thiáº¿t káº¿:                                                       â”‚
â”‚  âœ“ 3 layers Ä‘á»§ Ä‘á»ƒ há»c spectral patterns tá»« 5 bands                  â”‚
â”‚  âœ“ Gradual channel increase (5â†’32â†’64â†’128) trÃ¡nh bottleneck          â”‚
â”‚  âœ“ MaxPool giáº£m spatial size, giá»¯ láº¡i features quan trá»ng           â”‚
â”‚  âœ“ AdaptiveAvgPool(7,7) Ä‘á»ƒ match spatial size vá»›i RGB               â”‚
â”‚  âœ“ BatchNorm giÃºp á»•n Ä‘á»‹nh training vá»›i data nhá»                     â”‚
â”‚  âœ“ 128 channels Ä‘á»§ Ä‘á»ƒ represent MS features mÃ  khÃ´ng quÃ¡ phá»©c táº¡p   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ C. HS ENCODER (TRAINABLE)                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input:  HS (batch, 125, 224, 224)                                    â”‚
â”‚                                                                       â”‚
â”‚ Architecture:                                                         â”‚
â”‚   Conv2d(125â†’64, k=3, p=1) â†’ BN â†’ ReLU â†’ MaxPool(2)                 â”‚
â”‚   â†’ (64, 112, 112)                                                   â”‚
â”‚                                                                       â”‚
â”‚   Conv2d(64â†’128, k=3, p=1) â†’ BN â†’ ReLU â†’ AdaptiveAvgPool(7,7)       â”‚
â”‚   â†’ (128, 7, 7)                                                      â”‚
â”‚                                                                       â”‚
â”‚ Output: F_hs (batch, 128, 7, 7)                                      â”‚
â”‚                                                                       â”‚
â”‚ LÃ½ do thiáº¿t káº¿:                                                       â”‚
â”‚  âœ“ HS cÃ³ 125 bands â†’ cáº§n reduce dimension máº¡nh (125â†’64 ngay layer 1)â”‚
â”‚  âœ“ Chá»‰ 2 layers (thay vÃ¬ 3 nhÆ° MS) vÃ¬ HS Ä‘Ã£ ráº¥t high-dim            â”‚
â”‚  âœ“ Output 128 channels GIá»NG MS Ä‘á»ƒ dá»… fusion                        â”‚
â”‚  âœ“ Shallow network trÃ¡nh overfit vá»›i 125-dim input vÃ  data nhá»      â”‚
â”‚  âœ“ AdaptiveAvgPool(7,7) Ä‘á»ƒ match spatial size                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ D. SPECTRAL ATTENTION FUSION (TRAINABLE)                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input:  F_ms (batch, 128, 7, 7) + F_hs (batch, 128, 7, 7)           â”‚
â”‚ Module: MultiHeadSpectralAttention                                   â”‚
â”‚   - num_heads: 4                                                     â”‚
â”‚   - dropout: 0.4                                                     â”‚
â”‚ Output: F_spec (batch, 256, 7, 7)                                    â”‚
â”‚                                                                       â”‚
â”‚ CÆ¡ cháº¿ hoáº¡t Ä‘á»™ng:                                                     â”‚
â”‚  1. Multi-head self-attention giá»¯a MS vÃ  HS                          â”‚
â”‚  2. Má»—i head há»c má»™t aspect cá»§a correlation                          â”‚
â”‚  3. Concatenate outputs tá»« 4 heads                                   â”‚
â”‚  4. Linear projection to 256 channels                                â”‚
â”‚                                                                       â”‚
â”‚ LÃ½ do dÃ¹ng Attention:                                                 â”‚
â”‚  âœ“ MS vÃ  HS cÃ¹ng capture spectral info nhÆ°ng á»Ÿ different ranges     â”‚
â”‚  âœ“ Attention há»c Ä‘Æ°á»£c "MS band X tÆ°Æ¡ng quan vá»›i HS band Y tháº¿ nÃ o"  â”‚
â”‚  âœ“ Adaptive fusion (khÃ´ng pháº£i simple concatenation)                â”‚
â”‚  âœ“ Multi-head cho phÃ©p há»c nhiá»u relationships khÃ¡c nhau            â”‚
â”‚  âœ“ Dropout 0.4 trÃ¡nh overfit (data nhá»)                             â”‚
â”‚                                                                       â”‚
â”‚ Sau Ä‘Ã³ Project 256â†’512:                                              â”‚
â”‚  Conv2d(256â†’512, k=1) â†’ BN â†’ ReLU â†’ Dropout2d(0.4)                  â”‚
â”‚                                                                       â”‚
â”‚  LÃ½ do: Match channels vá»›i F_rgb (512) Ä‘á»ƒ fusion tiáº¿p               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ E. CONTEXT GATED FUSION (TRAINABLE)                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input:  F_rgb (batch, 512, 7, 7) + F_spec (batch, 512, 7, 7)        â”‚
â”‚ Module: ContextGatedFusion                                           â”‚
â”‚ Output: F_fused (batch, 512, 7, 7)                                   â”‚
â”‚                                                                       â”‚
â”‚ CÆ¡ cháº¿ hoáº¡t Ä‘á»™ng (gated mechanism):                                  â”‚
â”‚  1. Concat F_rgb vÃ  F_spec â†’ (batch, 1024, 7, 7)                    â”‚
â”‚  2. Conv â†’ Sigmoid â†’ Gate G (batch, 512, 7, 7)                      â”‚
â”‚  3. F_fused = G * F_rgb + (1-G) * F_spec                            â”‚
â”‚                                                                       â”‚
â”‚  â†’ Gate tá»± há»c "khi nÃ o tin RGB, khi nÃ o tin Spectral"              â”‚
â”‚                                                                       â”‚
â”‚ LÃ½ do dÃ¹ng Context Gated Fusion:                                     â”‚
â”‚  âœ“ RGB tá»‘t cho texture, spatial patterns                            â”‚
â”‚  âœ“ Spectral tá»‘t cho chemical composition, disease signatures        â”‚
â”‚  âœ“ Gate há»c adaptive weighting theo context                         â”‚
â”‚  âœ“ VÃ­ dá»¥: Náº¿u leaf cÃ³ texture rÃµ â†’ gate Æ°u tiÃªn RGB                â”‚
â”‚           Náº¿u cáº§n detect subtle disease â†’ gate Æ°u tiÃªn Spectral     â”‚
â”‚  âœ“ Learnable, flexible hÆ¡n simple concatenation hoáº·c average        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ F. CLASSIFICATION HEAD (TRAINABLE)                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input:  F_fused (batch, 512, 7, 7)                                   â”‚
â”‚ Module: RobustWheatHead                                              â”‚
â”‚   - dropout: 0.5 (cao hÆ¡n 0.4 cá»§a encoders)                         â”‚
â”‚                                                                       â”‚
â”‚ Architecture (internal):                                             â”‚
â”‚   GlobalAvgPool(7,7 â†’ 1,1) â†’ (batch, 512)                           â”‚
â”‚   Dropout(0.5)                                                       â”‚
â”‚   Linear(512 â†’ 256) â†’ ReLU â†’ Dropout(0.5)                           â”‚
â”‚   Linear(256 â†’ 3)                                                    â”‚
â”‚                                                                       â”‚
â”‚ Output: Logits (batch, 3)                                            â”‚
â”‚                                                                       â”‚
â”‚ LÃ½ do thiáº¿t káº¿:                                                       â”‚
â”‚  âœ“ GlobalAvgPool: Robust hÆ¡n flatten, giáº£m overfitting              â”‚
â”‚  âœ“ Dropout 0.5: Cao nháº¥t trong model vÃ¬ head dá»… overfit nháº¥t        â”‚
â”‚  âœ“ 512â†’256â†’3: Gradual reduction trÃ¡nh information bottleneck        â”‚
â”‚  âœ“ ReLU giá»¯a cÃ¡c layers Ä‘á»ƒ non-linearity                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

================================================================================
3. LÃ DO THIáº¾T Káº¾ Tá»”NG THá»‚
================================================================================

â“ Táº I SAO KHÃ”NG DÃ™NG SOFT COMPETITION á» STAGE 1?

Soft Competition lÃ  module há»c "relative importance" giá»¯a cÃ¡c modalities.
CÆ¡ cháº¿: Há»c gates Ä‘á»ƒ Ä‘iá»u chá»‰nh contribution cá»§a RGB, MS, HS Ä‘á»™ng.

ğŸš« LÃ½ do Bá» á»Ÿ Stage 1:
   1. Cáº¦N NHIá»€U DATA: Soft Competition cáº§n data Ä‘á»§ lá»›n Ä‘á»ƒ há»c Ä‘Æ°á»£c
      "khi nÃ o modality X quan trá»ng hÆ¡n Y"
      
   2. RISK OVERFITTING: Vá»›i 600 samples, model cÃ³ thá»ƒ há»c "noise patterns"
      thay vÃ¬ "true importance patterns"
      
   3. NHIá»€U PARAMETERS: ThÃªm parameters â†’ tÄƒng risk overfit
   
   4. CHÆ¯A Cáº¦N THIáº¾T: Stage 1 focus vÃ o "model cÃ³ cháº¡y Ä‘Æ°á»£c khÃ´ng"
      Stage 2 má»›i optimize performance vá»›i full data
   
   âœ… Thay tháº¿: DÃ¹ng Attention + Context Gate (Ä‘Æ¡n giáº£n hÆ¡n, Ã­t params hÆ¡n)


â“ Táº I SAO FREEZE RESNET18?

ğŸ”’ LÃ½ do FREEZE:
   1. PRETRAINED KNOWLEDGE: ResNet18 Ä‘Ã£ há»c 1000 classes tá»« ImageNet
      â†’ Biáº¿t detect edges, textures, shapes, objects
      
   2. TRANSFER LEARNING: Wheat leaf features (edges, veins, spots) 
      tÆ°Æ¡ng tá»± ImageNet objects â†’ transfer tá»‘t
      
   3. DATA QUÃ NHá»: 600 samples KHÃ”NG Äá»¦ Ä‘á»ƒ retrain 11M parameters cá»§a ResNet18
      â†’ Náº¿u train sáº½ overfit náº·ng
      
   4. á»”N Äá»ŠNH GRADIENT: ResNet18 cÃ³ 18 layers, ráº¥t deep
      â†’ Náº¿u train cÃ³ thá»ƒ gáº·p vanishing/exploding gradients
      
   5. GIáº¢M MEMORY: Frozen layers khÃ´ng lÆ°u gradients
      â†’ Giáº£m GPU memory, train Ä‘Æ°á»£c batch size lá»›n hÆ¡n
   
   âœ… Káº¿t quáº£: Chá»‰ train 30-40% parameters â†’ giáº£m máº¡nh overfitting


â“ Táº I SAO DÃ™NG MULTI-HEAD ATTENTION?

ğŸ¯ LÃ½ do:
   1. MULTIPLE RELATIONSHIPS: MS-HS correlation phá»©c táº¡p
      - Head 1: Há»c "Red Edge trong MS â†” NIR trong HS"
      - Head 2: Há»c "Green trong MS â†” Visible range trong HS"
      - Head 3: Há»c spatial patterns
      - Head 4: Há»c spectral patterns
      
   2. FLEXIBLE FUSION: KhÃ´ng cá»‘ Ä‘á»‹nh weights, há»c adaptive
   
   3. PROVEN ARCHITECTURE: Multi-head attention lÃ  SOTA trong vision
      (ViT, DETR, etc.)
   
   4. 4 HEADS: Balance giá»¯a capacity vÃ  overfitting
      - 2 heads: QuÃ¡ Ã­t, khÃ´ng Ä‘á»§ represent relationships
      - 8 heads: QuÃ¡ nhiá»u, dá»… overfit vá»›i data nhá»
      - 4 heads: Vá»«a Ä‘á»§


â“ Táº I SAO OUTPUT 128 CHANNELS CHO MS VÃ€ HS?

ğŸ“Š LÃ½ do:
   1. BALANCE: RGB = 512, Spectral = 256 (128 MS + 128 HS)
      â†’ Tá»‰ lá»‡ 2:1 phÃ¹ há»£p (RGB quan trá»ng hÆ¡n má»™t chÃºt)
      
   2. KHÃ”NG QUÃ Lá»šN: 
      - 256 channels/branch â†’ quÃ¡ nhiá»u params vá»›i data nhá»
      - 64 channels/branch â†’ quÃ¡ Ã­t, máº¥t information
      - 128 channels â†’ sweet spot
      
   3. SYMMETRY: MS vÃ  HS cÃ¹ng 128 â†’ dá»… fusion báº±ng attention
      (Attention works best khi input dims tÆ°Æ¡ng Ä‘Æ°Æ¡ng)

================================================================================
4. CHIáº¾N LÆ¯á»¢C TRAINING
================================================================================

ğŸ“ TRAINING STRATEGY:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TRAINABLE vs FROZEN                                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ FROZEN (60-70% parameters):                                           â”‚
â”‚   â„ï¸ ResNet18 backbone (11M params)                                  â”‚
â”‚                                                                       â”‚
â”‚ TRAINABLE (30-40% parameters):                                        â”‚
â”‚   âœ… MS Encoder (~50K params)                                        â”‚
â”‚   âœ… HS Encoder (~100K params)                                       â”‚
â”‚   âœ… Spectral Attention (~200K params)                               â”‚
â”‚   âœ… Spectral Projection (~130K params)                              â”‚
â”‚   âœ… Context Gated Fusion (~500K params)                             â”‚
â”‚   âœ… Classification Head (~130K params)                              â”‚
â”‚                                                                       â”‚
â”‚ Total trainable: ~1.1M params (vs 11M náº¿u train toÃ n bá»™)            â”‚
â”‚                                                                       â”‚
â”‚ Lá»£i Ã­ch:                                                              â”‚
â”‚  âœ“ Giáº£m 10x sá»‘ parameters cáº§n há»c â†’ giáº£m máº¡nh overfitting           â”‚
â”‚  âœ“ Train nhanh hÆ¡n (Ã­t gradients cáº§n compute)                       â”‚
â”‚  âœ“ Cáº§n Ã­t GPU memory hÆ¡n                                             â”‚
â”‚  âœ“ á»”n Ä‘á»‹nh hÆ¡n (khÃ´ng cÃ³ deep network gradients)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OPTIMIZER: AdamW                                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Learning rate: 1e-4                                                   â”‚
â”‚ Weight decay: 1e-3                                                    â”‚
â”‚                                                                       â”‚
â”‚ LÃ½ do chá»n AdamW:                                                     â”‚
â”‚  âœ“ Adaptive learning rate per parameter                             â”‚
â”‚  âœ“ Works tá»‘t vá»›i small datasets                                     â”‚
â”‚  âœ“ Weight decay giÃºp regularization                                 â”‚
â”‚  âœ“ Ãt sensitive vá»›i hyperparams hÆ¡n SGD                             â”‚
â”‚                                                                       â”‚
â”‚ LÃ½ do lr=1e-4:                                                        â”‚
â”‚  âœ“ KhÃ´ng quÃ¡ lá»›n â†’ khÃ´ng overshoot minima                           â”‚
â”‚  âœ“ KhÃ´ng quÃ¡ nhá» â†’ train khÃ´ng quÃ¡ cháº­m                             â”‚
â”‚  âœ“ Safe default cho transfer learning                               â”‚
â”‚                                                                       â”‚
â”‚ LÃ½ do weight_decay=1e-3:                                              â”‚
â”‚  âœ“ L2 regularization ngáº§m                                            â”‚
â”‚  âœ“ Prevent large weights â†’ giáº£m overfitting                         â”‚
â”‚  âœ“ 1e-3 lÃ  moderate strength phÃ¹ há»£p small data                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SCHEDULER: ReduceLROnPlateau                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Mode: max (monitor validation accuracy)                              â”‚
â”‚ Factor: 0.5 (giáº£m LR xuá»‘ng 1/2)                                      â”‚
â”‚ Patience: 5 epochs                                                    â”‚
â”‚                                                                       â”‚
â”‚ Hoáº¡t Ä‘á»™ng:                                                            â”‚
â”‚  - Náº¿u val_acc khÃ´ng tÄƒng trong 5 epochs                            â”‚
â”‚  - â†’ Giáº£m LR: 1e-4 â†’ 5e-5 â†’ 2.5e-5 â†’ ...                           â”‚
â”‚                                                                       â”‚
â”‚ LÃ½ do:                                                                â”‚
â”‚  âœ“ Tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh LR khi plateau                                â”‚
â”‚  âœ“ GiÃºp escape local minima                                         â”‚
â”‚  âœ“ Fine-tuning á»Ÿ cuá»‘i training (LR nhá» â†’ cáº©n tháº­n hÆ¡n)              â”‚
â”‚  âœ“ KhÃ´ng cáº§n manual tuning schedule                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EARLY STOPPING                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Patience: 15 epochs                                                   â”‚
â”‚ Metric: Validation accuracy                                          â”‚
â”‚                                                                       â”‚
â”‚ Logic:                                                                â”‚
â”‚  - Save model khi val_acc tÄƒng                                       â”‚
â”‚  - Náº¿u val_acc khÃ´ng tÄƒng trong 15 epochs â†’ STOP                    â”‚
â”‚                                                                       â”‚
â”‚ LÃ½ do patience=15:                                                    â”‚
â”‚  âœ“ Dataset nhá» â†’ convergence cÃ³ thá»ƒ cháº­m                            â”‚
â”‚  âœ“ Cáº§n time Ä‘á»ƒ scheduler giáº£m LR vÃ  explore                         â”‚
â”‚  âœ“ KhÃ´ng quÃ¡ dÃ i (trÃ¡nh waste time khi model Ä‘Ã£ converge)           â”‚
â”‚                                                                       â”‚
â”‚ Táº¡i sao early stopping quan trá»ng:                                   â”‚
â”‚  âœ“ TrÃ¡nh overfit: Val acc giáº£m nhÆ°ng train acc tÄƒng = overfitting   â”‚
â”‚  âœ“ Save time: KhÃ´ng train 100 epochs náº¿u converge á»Ÿ epoch 40        â”‚
â”‚  âœ“ Best model: Restore weights táº¡i peak val acc                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

================================================================================
5. HYPERPARAMETERS VÃ€ LÃ DO CHá»ŒN
================================================================================

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BATCH SIZE: 16                                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LÃ½ do:                                                                â”‚
â”‚  âœ“ Dataset nhá» (600 samples) â†’ batch size nhá»                       â”‚
â”‚  âœ“ 16 lÃ  compromise giá»¯a:                                            â”‚
â”‚    - Stability (batch lá»›n hÆ¡n â†’ gradient á»•n Ä‘á»‹nh hÆ¡n)               â”‚
â”‚    - Generalization (batch nhá» hÆ¡n â†’ generalize tá»‘t hÆ¡n)            â”‚
â”‚  âœ“ Memory: 16 * (RGB + MS + HS) vá»«a Ä‘á»§ cho GPU 8GB                  â”‚
â”‚  âœ“ Náº¿u batch=32: QuÃ¡ lá»›n so vá»›i dataset, Ã­t updates/epoch           â”‚
â”‚  âœ“ Náº¿u batch=8: QuÃ¡ nhá», gradient noise, unstable training          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DROPOUT RATES                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Encoders (MS/HS): dropout=0.4                                        â”‚
â”‚ Head: dropout=0.5                                                     â”‚
â”‚                                                                       â”‚
â”‚ LÃ½ do phÃ¢n táº§ng:                                                      â”‚
â”‚  âœ“ Encoders: 0.4 (moderate) - vá»«a regularize vá»«a giá»¯ info          â”‚
â”‚  âœ“ Head: 0.5 (aggressive) - head dá»… overfit nháº¥t (fully connected) â”‚
â”‚                                                                       â”‚
â”‚ Táº¡i sao khÃ´ng dÃ¹ng dropout cao hÆ¡n:                                  â”‚
â”‚  âœ“ 0.6-0.7: QuÃ¡ máº¡nh, máº¥t quÃ¡ nhiá»u information                     â”‚
â”‚  âœ“ Model sáº½ underfit (khÃ´ng Ä‘á»§ capacity há»c patterns)               â”‚
â”‚                                                                       â”‚
â”‚ Táº¡i sao khÃ´ng dÃ¹ng dropout tháº¥p hÆ¡n:                                 â”‚
â”‚  âœ“ 0.2-0.3: QuÃ¡ yáº¿u, khÃ´ng Ä‘á»§ regularization                        â”‚
â”‚  âœ“ Model sáº½ overfit vá»›i dataset nhá»                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MAX EPOCHS: 100                                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LÃ½ do:                                                                â”‚
â”‚  âœ“ Upper bound, thÆ°á»ng stop sá»›m hÆ¡n do early stopping               â”‚
â”‚  âœ“ 100 Ä‘á»§ Ä‘á»ƒ model converge ngay cáº£ khi learn cháº­m                  â”‚
â”‚  âœ“ Vá»›i LR scheduler, epochs sau sáº½ cÃ³ LR nhá» Ä‘á»ƒ fine-tune          â”‚
â”‚                                                                       â”‚
â”‚ Thá»±c táº¿:                                                              â”‚
â”‚  - ThÆ°á»ng stop á»Ÿ epoch 40-60 do early stopping                      â”‚
â”‚  - Chá»‰ cháº¡y full 100 náº¿u model váº«n improve (hiáº¿m)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

================================================================================
6. AUGMENTATION STRATEGY
================================================================================

ğŸ¨ LIGHT AUGMENTATION CHO STAGE 1:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RGB AUGMENTATION                                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Training:                                                             â”‚
â”‚   1. Resize(256, 256)                                                â”‚
â”‚   2. HorizontalFlip(p=0.5)                                           â”‚
â”‚   3. VerticalFlip(p=0.5)                                             â”‚
â”‚   4. Rotate(limit=Â±15Â°, p=0.5)                                       â”‚
â”‚   5. RandomBrightnessContrast(limit=0.15, p=0.3)                    â”‚
â”‚   6. CenterCrop(224, 224)                                            â”‚
â”‚   7. Normalize(ImageNet mean/std)                                    â”‚
â”‚   8. ToTensor                                                         â”‚
â”‚                                                                       â”‚
â”‚ Validation:                                                           â”‚
â”‚   1. Resize(256, 256)                                                â”‚
â”‚   2. CenterCrop(224, 224)                                            â”‚
â”‚   3. Normalize(ImageNet mean/std)                                    â”‚
â”‚   4. ToTensor                                                         â”‚
â”‚   (NO augmentation - evaluate model as-is)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MS/HS AUGMENTATION                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Training:                                                             â”‚
â”‚   1. Resize(256, 256)                                                â”‚
â”‚   2. HorizontalFlip(p=0.5)                                           â”‚
â”‚   3. VerticalFlip(p=0.5)                                             â”‚
â”‚   4. Rotate(limit=Â±15Â°, p=0.5)                                       â”‚
â”‚   5. CenterCrop(224, 224)                                            â”‚
â”‚   6. Gaussian Noise (Ïƒ=0.01, p=0.3)                                 â”‚
â”‚   7. Band Dropout (1-2 bands, p=0.2)                                â”‚
â”‚                                                                       â”‚
â”‚ Validation:                                                           â”‚
â”‚   1. Resize(256, 256)                                                â”‚
â”‚   2. CenterCrop(224, 224)                                            â”‚
â”‚   (NO augmentation)                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“‹ LÃ DO Tá»ªNG AUGMENTATION:

âœ… HorizontalFlip + VerticalFlip (p=0.5):
   - Leaf cÃ³ thá»ƒ á»Ÿ má»i hÆ°á»›ng trong thá»±c táº¿
   - Flip táº¡o thÃªm 4x data (original, H, V, HV)
   - Safe: KhÃ´ng lÃ m thay Ä‘á»•i semantic (váº«n lÃ  Health/Rust/Other)

âœ… Rotate(Â±15Â°, p=0.5):
   - Leaf cÃ³ thá»ƒ nghiÃªng nháº¹
   - Â±15Â° vá»«a Ä‘á»§: KhÃ´ng quÃ¡ extreme (trÃ¡nh unrealistic angles)
   - GiÃºp model robust vá»›i orientation

âœ… RandomBrightnessContrast (limit=0.15, p=0.3):
   - Lighting conditions khÃ¡c nhau (shadow, bright sun)
   - 0.15 lÃ  nháº¹ nhÃ ng (khÃ´ng lÃ m biáº¿n dáº¡ng mÃ u quÃ¡ má»©c)
   - p=0.3 (khÃ´ng pháº£i má»i áº£nh) trÃ¡nh quÃ¡ nhiá»u noise

âœ… Gaussian Noise (Ïƒ=0.01):
   - Spectral data cÃ³ sensor noise
   - Ïƒ=0.01 ráº¥t nhá» (1% of max value) â†’ realistic
   - GiÃºp model robust vá»›i noisy sensors

âœ… Band Dropout:
   - Simulate missing/corrupted spectral bands
   - 1-2 bands out of 5 (MS) hoáº·c 125 (HS) â†’ small impact
   - Force model há»c tá»« subset of bands â†’ better generalization

ğŸš« KHÃ”NG DÃ™NG HEAVY AUGMENTATION:

âŒ Rotate(Â±90Â°): Unrealistic, leaf khÃ´ng bao giá» tháº³ng Ä‘á»©ng
âŒ CutOut/MixUp: Dataset quÃ¡ nhá», cÃ³ thá»ƒ táº¡o meaningless samples
âŒ Heavy color jitter: LÃ m máº¥t spectral signatures (critical for disease)
âŒ Elastic transform: KhÃ´ng phÃ¹ há»£p vá»›i wheat leaf structure

================================================================================
7. LOSS FUNCTION VÃ€ CLASS BALANCING
================================================================================

ğŸ“Š WEIGHTED CROSS-ENTROPY LOSS:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LOSS FUNCTION                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Formula: L = - Î£ w_i * y_i * log(p_i)                               â”‚
â”‚                                                                       â”‚
â”‚ Trong Ä‘Ã³:                                                             â”‚
â”‚   - w_i: Class weight (computed tá»« class distribution)              â”‚
â”‚   - y_i: Ground truth (one-hot)                                     â”‚
â”‚   - p_i: Predicted probability (sau softmax)                        â”‚
â”‚                                                                       â”‚
â”‚ Class weights computation:                                            â”‚
â”‚   w_i = n_samples / (n_classes * n_samples_class_i)                 â”‚
â”‚                                                                       â”‚
â”‚ VÃ­ dá»¥ vá»›i dataset:                                                    â”‚
â”‚   - Total: 600 samples                                               â”‚
â”‚   - Health: 250 samples â†’ w_0 = 600/(3*250) = 0.8                   â”‚
â”‚   - Rust: 200 samples â†’ w_1 = 600/(3*200) = 1.0                     â”‚
â”‚   - Other: 150 samples â†’ w_2 = 600/(3*150) = 1.33                   â”‚
â”‚                                                                       â”‚
â”‚   â†’ Class Ã­t sample hÆ¡n cÃ³ weight cao hÆ¡n                           â”‚
â”‚   â†’ Model penalty náº·ng hÆ¡n khi misclassify rare class               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â“ Táº I SAO DÃ™NG WEIGHTED LOSS?

ğŸ¯ Problem: Class Imbalance
   - Náº¿u Health=250, Rust=200, Other=150
   - Model cÃ³ thá»ƒ bias vá» Health (vÃ¬ nhiá»u sample nháº¥t)
   - Predict "táº¥t cáº£ lÃ  Health" â†’ 250/600 = 41.7% accuracy (mÃ  khÃ´ng há»c gÃ¬!)

âœ… Solution: Weighted Loss
   - TÄƒng penalty cho misclassification cá»§a rare class (Other)
   - Giáº£m penalty cho common class (Health)
   - Force model há»c táº¥t cáº£ cÃ¡c classes EQUALLY

ğŸ“ˆ Impact:
   - Balanced accuracy across classes
   - KhÃ´ng bá»‹ dominated bá»Ÿi majority class
   - Critical cho applications: Cáº§n detect RUST (rare) khÃ´ng kÃ©m HEALTH

â“ Táº I SAO KHÃ”NG DÃ™NG FOCAL LOSS?

ğŸ” Focal Loss:
   FL = - Î± * (1-p)^Î³ * log(p)
   
   - Î±: Class weight (giá»‘ng weighted CE)
   - Î³: Focusing parameter (typically 2)
   - (1-p)^Î³: Down-weight easy examples

ğŸš« LÃ½ do KHÃ”NG dÃ¹ng á»Ÿ Stage 1:
   1. OVERKILL: Dataset nhá», khÃ´ng cÃ³ quÃ¡ nhiá»u easy examples
   2. UNSTABLE: Focal loss khÃ³ tune (Î³ hyperparameter thÃªm)
   3. DESIGNED FOR: Extreme imbalance (1:100, 1:1000)
      â†’ Wheat dataset imbalance vá»«a pháº£i (1:1.5:1.7)
   4. SIMPLE IS BETTER: Vá»›i data nhá», weighted CE Ä‘á»§ vÃ  stable hÆ¡n

âœ… Káº¿t luáº­n: Weighted CE lÃ  best choice cho Stage 1

================================================================================
8. DATA SPLIT STRATEGY
================================================================================

ğŸ“‚ DATA ORGANIZATION:

Original:
   Data/
      train/  (~600 samples)
         RGB/, MS/, HS/
      val/    (cÃ³ thá»ƒ rá»—ng hoáº·c quÃ¡ Ã­t)
         RGB/, MS/, HS/

Strategy:
   - Náº¿u val/ rá»—ng hoáº·c < 50 samples:
     â†’ Split from train: 80% train, 20% val
     â†’ Stratified split (giá»¯ tá»‰ lá»‡ classes)
   
   - Náº¿u val/ Ä‘á»§ lá»›n (â‰¥50 samples):
     â†’ DÃ¹ng luÃ´n val/ cÃ³ sáºµn

LÃ½ do stratified split:
   âœ“ Giá»¯ class distribution giá»‘ng nhau á»Ÿ train vÃ  val
   âœ“ Train: Health 40%, Rust 35%, Other 25%
     Val:   Health 40%, Rust 35%, Other 25% (SAME)
   âœ“ Evaluation cÃ´ng báº±ng, khÃ´ng bias

================================================================================
9. Táº I SAO Cáº¦N FILE GIáº¢I THÃCH NÃ€Y?
================================================================================

ğŸ“ Má»¤C ÄÃCH:

1. DOCUMENTATION:
   âœ“ Ghi láº¡i decision-making process
   âœ“ Ai Ä‘á»c code cÅ©ng hiá»ƒu "táº¡i sao lÃ m váº­y"
   âœ“ Dá»… maintain vÃ  extend sau nÃ y

2. LEARNING:
   âœ“ Há»c Ä‘Æ°á»£c rationale Ä‘áº±ng sau má»—i design choice
   âœ“ Hiá»ƒu trade-offs (táº¡i sao chá»n X khÃ´ng chá»n Y)
   âœ“ Apply principles cho projects khÃ¡c

3. DEBUGGING:
   âœ“ Khi model fail, biáº¿t nÆ¡i nÃ o cáº§n check
   âœ“ Hiá»ƒu assumptions â†’ validate assumptions
   âœ“ Modify systematically, khÃ´ng random tuning

4. COMMUNICATION:
   âœ“ Explain cho teammates/managers
   âœ“ Write technical reports
   âœ“ Justify design trong interviews/presentations

5. REPRODUCIBILITY:
   âœ“ Ai cÅ©ng cÃ³ thá»ƒ recreate model vá»›i same rationale
   âœ“ KhÃ´ng phá»¥ thuá»™c vÃ o tribal knowledge
   âœ“ Science-based ML, khÃ´ng pháº£i magic/luck

================================================================================
10. ROADMAP: STAGE 1 â†’ STAGE 2 â†’ PRODUCTION
================================================================================

ğŸ“ CURRENT: STAGE 1 (Limited Data)
   âœ… Simple architecture
   âœ… Frozen backbone
   âœ… Light augmentation
   âœ… Proof of concept

â¡ï¸ NEXT: STAGE 2 (Full Data - ~2000+ samples/class)
   ğŸ¯ Unfreeze ResNet18 (fine-tune backbone)
   ğŸ¯ Add Soft Competition module
   ğŸ¯ Heavier augmentation (CutOut, MixUp)
   ğŸ¯ Focal Loss (náº¿u imbalance severe)
   ğŸ¯ Ensemble multiple models
   ğŸ¯ Test Time Augmentation (TTA)

â¡ï¸ FUTURE: PRODUCTION
   ğŸš€ Model compression (pruning, quantization)
   ğŸš€ ONNX/TensorRT deployment
   ğŸš€ Real-time inference (<100ms)
   ğŸš€ Edge deployment (Jetson Nano)
   ğŸš€ A/B testing vá»›i old model
   ğŸš€ Monitoring vÃ  retraining pipeline

================================================================================
11. KEY TAKEAWAYS
================================================================================

ğŸ“ NHá»®NG BÃ€I Há»ŒC QUAN TRá»ŒNG:

1. START SIMPLE:
   - Stage 1 khÃ´ng cáº§n fancy techniques
   - Simple + well-executed > Complex + buggy
   - Validate pipeline trÆ°á»›c, optimize sau

2. TRANSFER LEARNING:
   - Pretrained model = goldmine vá»›i small data
   - Freeze khi data < 1000 samples
   - Fine-tune khi data > 5000 samples

3. REGULARIZATION IS KEY:
   - Dropout, weight decay, early stopping
   - Augmentation nháº¹ nhÃ ng vÃ  realistic
   - Class balancing trÃ¡nh bias

4. UNDERSTAND TRADE-OFFS:
   - Capacity vs Overfitting
   - Accuracy vs Inference speed
   - Complexity vs Maintainability

5. DOCUMENT EVERYTHING:
   - Why not just what
   - Future you will thank you
   - Make ML reproducible

================================================================================
Káº¾T LUáº¬N
================================================================================

Model Stage 1 Ä‘Æ°á»£c thiáº¿t káº¿ vá»›i triáº¿t lÃ½:
   "SIMPLE, STABLE, SCALABLE"

âœ… SIMPLE:
   - Bá» Soft Competition
   - Freeze backbone
   - Standard losses vÃ  optimizers

âœ… STABLE:
   - Light augmentation
   - Class balancing
   - Early stopping
   - Dropout regularization

âœ… SCALABLE:
   - Modular architecture
   - Easy to add components (Stage 2)
   - Clear upgrade path

Má»¥c tiÃªu KHÃ”NG PHáº¢I maximize accuracy á»Ÿ Stage 1.
Má»¥c tiÃªu LÃ€: VALIDATE pipeline, PREVENT overfitting, BUILD foundation.

Stage 2 vá»›i full data sáº½ push performance cao hÆ¡n.

================================================================================
END OF DOCUMENT
================================================================================
TÃ¡c giáº£: AI Assistant
NgÃ y táº¡o: 2026-02-05
Má»¥c Ä‘Ã­ch: Giáº£i thÃ­ch chi tiáº¿t kiáº¿n trÃºc vÃ  lÃ½ do thiáº¿t káº¿ PipelineV1_Stage1
