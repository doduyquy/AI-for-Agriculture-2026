"""
analyze_errors.py - PH√ÇN T√çCH CHI TI·∫æT C√ÅC D·ª∞ ƒêO√ÅN SAI

üéØ M·ª•c ƒë√≠ch:
  - Ph√¢n t√≠ch predictions.csv ƒë·ªÉ t√¨m pattern l·ªói
  - Identify c√°c lo·∫°i l·ªói ph·ªï bi·∫øn nh·∫•t
  - ƒê∆∞a ra khuy·∫øn ngh·ªã c·∫£i thi·ªán model

üìä Output:
  - Confusion matrix
  - Error breakdown by class
  - Top error patterns
  - List of misclassified images
"""

import pandas as pd
import numpy as np
from collections import Counter
from pathlib import Path

# Load predictions
predictions_file = Path('predictions.csv')

if not predictions_file.exists():
    print("‚ùå File predictions.csv kh√¥ng t·ªìn t·∫°i!")
    print("   H√£y ch·∫°y PipelineV1_Stage1_TwoStep_Inference.py tr∆∞·ªõc")
    exit(1)

df = pd.read_csv(predictions_file)

print("\n" + "="*70)
print("üìä PH√ÇN T√çCH CHI TI·∫æT C√ÅC D·ª∞ ƒêO√ÅN SAI")
print("="*70)

# ==================== T·ªîNG QUAN ====================
total = len(df)
correct_count = (df['Correct'] == 'Yes').sum()
incorrect_count = (df['Correct'] == 'No').sum()

print(f"\nüìà T·ªîNG QUAN:")
print(f"  Total samples: {total}")
print(f"  ‚úÖ Correct: {correct_count} ({correct_count/total*100:.1f}%)")
print(f"  ‚ùå Incorrect: {incorrect_count} ({incorrect_count/total*100:.1f}%)")
print(f"  üéØ Accuracy: {correct_count/total:.3f}")

# ==================== PH√ÇN T√çCH THEO TRUE CLASS ====================
print(f"\n" + "="*70)
print("‚ùå PH√ÇN T√çCH L·ªñI THEO TRUE CLASS")
print("="*70)

for true_class in ['Health', 'Rust', 'Other']:
    class_df = df[df['True_Class'] == true_class]
    class_correct = class_df[class_df['Correct'] == 'Yes']
    class_wrong = class_df[class_df['Correct'] == 'No']
    
    print(f"\nüîπ {true_class.upper()} (Total: {len(class_df)})")
    print(f"  ‚úÖ Correct: {len(class_correct):3d} ({len(class_correct)/len(class_df)*100:5.1f}%)")
    print(f"  ‚ùå Wrong:   {len(class_wrong):3d} ({len(class_wrong)/len(class_df)*100:5.1f}%)")
    
    if len(class_wrong) > 0:
        # Nh·∫ßm th√†nh class n√†o?
        wrong_as = class_wrong['Predicted_Class'].value_counts()
        print(f"  üìä Nh·∫ßm th√†nh:")
        for pred_class, count in wrong_as.items():
            pct = count/len(class_wrong)*100
            print(f"      ‚Üí {pred_class:8s}: {count:2d} samples ({pct:5.1f}% of errors)")

# ==================== CONFUSION MATRIX ====================
print(f"\n" + "="*70)
print("üìä CONFUSION MATRIX")
print("="*70)

confusion = pd.crosstab(
    df['True_Class'], 
    df['Predicted_Class'], 
    rownames=['True'], 
    colnames=['Predicted'],
    margins=True
)
print(confusion)

# T√≠nh metrics chi ti·∫øt
print(f"\nüìà PER-CLASS METRICS:")
print("-"*70)

for true_class in ['Health', 'Rust', 'Other']:
    tp = len(df[(df['True_Class'] == true_class) & (df['Predicted_Class'] == true_class)])
    fp = len(df[(df['True_Class'] != true_class) & (df['Predicted_Class'] == true_class)])
    fn = len(df[(df['True_Class'] == true_class) & (df['Predicted_Class'] != true_class)])
    tn = len(df[(df['True_Class'] != true_class) & (df['Predicted_Class'] != true_class)])
    
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
    
    print(f"\n{true_class}:")
    print(f"  Precision: {precision:.3f}")
    print(f"  Recall:    {recall:.3f}")
    print(f"  F1-Score:  {f1:.3f}")

# ==================== TOP ERROR PATTERNS ====================
print(f"\n" + "="*70)
print("üî• TOP ERROR PATTERNS (MOST COMMON MISTAKES)")
print("="*70)

wrong_df = df[df['Correct'] == 'No']
error_patterns = wrong_df.groupby(['True_Class', 'Predicted_Class']).size().sort_values(ascending=False)

print(f"\nRanking:")
for i, ((true_c, pred_c), count) in enumerate(error_patterns.items(), 1):
    pct = count / incorrect_count * 100
    print(f"  {i}. {true_c:8s} ‚Üí {pred_c:8s}: {count:3d} samples ({pct:5.1f}% of all errors)")

# ==================== STEP 1 vs STEP 2 ANALYSIS ====================
print(f"\n" + "="*70)
print("üîç STEP 1 (Healthy vs Diseased) ANALYSIS")
print("="*70)

# Step 1: Healthy vs Diseased
df['True_Step1'] = df['True_Label'].apply(lambda x: 'Healthy' if x == 0 else 'Diseased')
df['Pred_Step1'] = df['Predicted_Label'].apply(lambda x: 'Healthy' if x == 0 else 'Diseased')

step1_correct = (df['True_Step1'] == df['Pred_Step1']).sum()
step1_total = len(df)

print(f"\nStep 1 Accuracy: {step1_correct}/{step1_total} = {step1_correct/step1_total:.3f}")

# Step 1 confusion
step1_confusion = pd.crosstab(df['True_Step1'], df['Pred_Step1'], margins=True)
print(f"\nStep 1 Confusion Matrix:")
print(step1_confusion)

# Step 1 errors
print(f"\nStep 1 Errors:")
healthy_as_diseased = len(df[(df['True_Step1'] == 'Healthy') & (df['Pred_Step1'] == 'Diseased')])
diseased_as_healthy = len(df[(df['True_Step1'] == 'Diseased') & (df['Pred_Step1'] == 'Healthy')])

print(f"  Healthy ‚Üí Diseased: {healthy_as_diseased} ({healthy_as_diseased/40*100:.1f}% of Healthy)")
print(f"  Diseased ‚Üí Healthy: {diseased_as_healthy} ({diseased_as_healthy/80*100:.1f}% of Diseased)")

print(f"\n" + "="*70)
print("üîç STEP 2 (Rust vs Other) ANALYSIS")
print("="*70)

# Step 2: Only for Diseased samples
diseased_df = df[df['True_Label'] > 0]

if len(diseased_df) > 0:
    step2_correct = len(diseased_df[diseased_df['Correct'] == 'Yes'])
    step2_total = len(diseased_df)
    
    print(f"\nStep 2 Accuracy (on diseased only): {step2_correct}/{step2_total} = {step2_correct/step2_total:.3f}")
    
    # Step 2 confusion (Rust vs Other)
    diseased_true = diseased_df['True_Class'].replace({'Rust': 'Rust', 'Other': 'Other'})
    diseased_pred = diseased_df['Predicted_Class'].replace({'Rust': 'Rust', 'Other': 'Other'})
    step2_confusion = pd.crosstab(diseased_true, diseased_pred, margins=True)
    print(f"\nStep 2 Confusion Matrix:")
    print(step2_confusion)

# ==================== DANH S√ÅCH FILE SAI ====================
print(f"\n" + "="*70)
print("üìÅ DANH S√ÅCH C√ÅC FILE B·ªä D·ª∞ ƒêO√ÅN SAI")
print("="*70)

print(f"\nüî¥ Health b·ªã nh·∫ßm th√†nh Rust ({len(df[(df['True_Class'] == 'Health') & (df['Predicted_Class'] == 'Rust')])} files):")
health_as_rust = wrong_df[(wrong_df['True_Class'] == 'Health') & (wrong_df['Predicted_Class'] == 'Rust')]
for idx, row in health_as_rust.iterrows():
    print(f"    - {row['Image_Path']}")

print(f"\nüî¥ Health b·ªã nh·∫ßm th√†nh Other ({len(df[(df['True_Class'] == 'Health') & (df['Predicted_Class'] == 'Other')])} files):")
health_as_other = wrong_df[(wrong_df['True_Class'] == 'Health') & (wrong_df['Predicted_Class'] == 'Other')]
for idx, row in health_as_other.iterrows():
    print(f"    - {row['Image_Path']}")

print(f"\nüî¥ Rust b·ªã nh·∫ßm th√†nh Health ({len(df[(df['True_Class'] == 'Rust') & (df['Predicted_Class'] == 'Health')])} files):")
rust_as_health = wrong_df[(wrong_df['True_Class'] == 'Rust') & (wrong_df['Predicted_Class'] == 'Health')]
for idx, row in rust_as_health.iterrows():
    print(f"    - {row['Image_Path']}")

print(f"\nüî¥ Rust b·ªã nh·∫ßm th√†nh Other ({len(df[(df['True_Class'] == 'Rust') & (df['Predicted_Class'] == 'Other')])} files):")
rust_as_other = wrong_df[(wrong_df['True_Class'] == 'Rust') & (wrong_df['Predicted_Class'] == 'Other')]
for idx, row in rust_as_other.iterrows():
    print(f"    - {row['Image_Path']}")

print(f"\nüî¥ Other b·ªã nh·∫ßm th√†nh Health ({len(df[(df['True_Class'] == 'Other') & (df['Predicted_Class'] == 'Health')])} files):")
other_as_health = wrong_df[(wrong_df['True_Class'] == 'Other') & (wrong_df['Predicted_Class'] == 'Health')]
for idx, row in other_as_health.iterrows():
    print(f"    - {row['Image_Path']}")

print(f"\nüî¥ Other b·ªã nh·∫ßm th√†nh Rust ({len(df[(df['True_Class'] == 'Other') & (df['Predicted_Class'] == 'Rust')])} files):")
other_as_rust = wrong_df[(wrong_df['True_Class'] == 'Other') & (wrong_df['Predicted_Class'] == 'Rust')]
for idx, row in other_as_rust.iterrows():
    print(f"    - {row['Image_Path']}")

# ==================== KHUY·∫æN NGH·ªä C·∫¢I THI·ªÜN ====================
print(f"\n" + "="*70)
print("üí° KHUY·∫æN NGH·ªä C·∫¢I THI·ªÜN MODEL")
print("="*70)

# Ph√¢n t√≠ch ƒë·ªÉ ƒë∆∞a ra khuy·∫øn ngh·ªã
healthy_recall = len(df[(df['True_Class'] == 'Health') & (df['Predicted_Class'] == 'Health')]) / len(df[df['True_Class'] == 'Health'])
diseased_as_healthy_pct = diseased_as_healthy / 80 * 100

print(f"\nüéØ ∆Øu ti√™n c·∫£i thi·ªán:")

if healthy_recall < 0.6:
    print(f"\n1Ô∏è‚É£ CRITICAL: Healthy Recall = {healthy_recall:.1%} (< 60%)")
    print(f"   ‚ùå V·∫•n ƒë·ªÅ: {healthy_as_diseased}/40 Healthy b·ªã nh·∫ßm Diseased")
    print(f"   üíä Gi·∫£i ph√°p:")
    print(f"      - TƒÉng Focal Loss alpha: 3.0 ‚Üí 4.5")
    print(f"      - TƒÉng Oversample: 2x ‚Üí 4x")
    print(f"      - Add MixUp augmentation cho Healthy")
    print(f"      - Tune threshold: 0.5 ‚Üí 0.3-0.35")

if diseased_as_healthy_pct > 15:
    print(f"\n2Ô∏è‚É£ HIGH: Diseased‚ÜíHealthy = {diseased_as_healthy_pct:.1f}% (> 15%)")
    print(f"   ‚ùå V·∫•n ƒë·ªÅ: {diseased_as_healthy}/80 c√¢y b·ªánh b·ªã b·ªè s√≥t")
    print(f"   üíä Gi·∫£i ph√°p:")
    print(f"      - TƒÉng RGB handcrafted features (th√™m Gabor, CCV)")
    print(f"      - TƒÉng spectral attention heads: 4 ‚Üí 8")
    print(f"      - Add hard negative mining")

# Step 2 analysis
if len(diseased_df) > 0:
    rust_recall = len(diseased_df[(diseased_df['True_Class'] == 'Rust') & (diseased_df['Predicted_Class'] == 'Rust')]) / len(diseased_df[diseased_df['True_Class'] == 'Rust'])
    other_recall = len(diseased_df[(diseased_df['True_Class'] == 'Other') & (diseased_df['Predicted_Class'] == 'Other')]) / len(diseased_df[diseased_df['True_Class'] == 'Other'])
    
    if rust_recall < 0.7 or other_recall < 0.7:
        print(f"\n3Ô∏è‚É£ MEDIUM: Step 2 Performance")
        print(f"   Rust Recall: {rust_recall:.1%}")
        print(f"   Other Recall: {other_recall:.1%}")
        print(f"   üíä Gi·∫£i ph√°p:")
        print(f"      - TƒÉng Spectral weight trong Step 2: 70% ‚Üí 80%")
        print(f"      - Add spectral augmentation (SpecAugment)")
        print(f"      - TƒÉng HS encoder depth")

print(f"\n4Ô∏è‚É£ ADVANCED TECHNIQUES:")
print(f"   - Test-Time Augmentation (TTA): +2-4% accuracy")
print(f"   - Ensemble 3 models: +4-6% accuracy")
print(f"   - Pseudo-labeling unlabeled data")

print("\n" + "="*70)
print("‚úÖ PH√ÇN T√çCH HO√ÄN T·∫§T!")
print("="*70)

# Save error report to file
output_file = Path('error_analysis_report.txt')
print(f"\nüíæ Saving detailed report to: {output_file}")

with open(output_file, 'w', encoding='utf-8') as f:
    f.write("="*70 + "\n")
    f.write("ERROR ANALYSIS REPORT\n")
    f.write("="*70 + "\n\n")
    
    f.write(f"Total samples: {total}\n")
    f.write(f"Accuracy: {correct_count/total:.3f}\n\n")
    
    f.write("Files with errors:\n")
    f.write("-"*70 + "\n")
    for idx, row in wrong_df.iterrows():
        f.write(f"{row['Image_Path']}: True={row['True_Class']}, Pred={row['Predicted_Class']}\n")

print(f"‚úÖ Report saved successfully!\n")
