{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94e28eec",
   "metadata": {},
   "source": [
    "# Beyond Visible Spectrum: AI for Agriculture 2026\n",
    "> Beyond the limit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4378309",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9252d23a",
   "metadata": {},
   "source": [
    "Solve problems: 'Wheat Disease Recognition', use 3 type of images: \n",
    "- RGB: normal picture (3 kernels)\n",
    "- MS: multispectral image (5 kernels)\n",
    "- HS: hyperspectral image (128 kernels), after processing: ~101 kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5677322f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T01:39:08.365887Z",
     "iopub.status.busy": "2026-01-02T01:39:08.365611Z",
     "iopub.status.idle": "2026-01-02T01:39:22.850506Z",
     "shell.execute_reply": "2026-01-02T01:39:22.849875Z"
    },
    "papermill": {
     "duration": 14.490758,
     "end_time": "2026-01-02T01:39:22.852279",
     "exception": false,
     "start_time": "2026-01-02T01:39:08.361521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os, re, random\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Optional, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import tifffile as tiff\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import timm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6005ec20",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd662ef7",
   "metadata": {},
   "source": [
    "- HS has 125 bands, but after removing noisy bands (first: 10, last: 14), we use 101 bands.\n",
    "- Resize all images to 224x224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3745882f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T01:39:22.858280Z",
     "iopub.status.busy": "2026-01-02T01:39:22.857442Z",
     "iopub.status.idle": "2026-01-02T01:39:22.864471Z",
     "shell.execute_reply": "2026-01-02T01:39:22.863771Z"
    },
    "papermill": {
     "duration": 0.011325,
     "end_time": "2026-01-02T01:39:22.865875",
     "exception": false,
     "start_time": "2026-01-02T01:39:22.854550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CFG:\n",
    "    ROOT: str = \"/kaggle/input/beyond-visible-spectrum-ai-for-agriculture-2026/Kaggle_Prepared\"  \n",
    "    TRAIN_DIR: str = \"train\"\n",
    "    VAL_DIR: str = \"val\"\n",
    "\n",
    "    USE_RGB: bool = True\n",
    "    USE_MS: bool  = True\n",
    "    USE_HS: bool  = True\n",
    "\n",
    "    IMG_SIZE: int = 224     # Resize all image: 224x224\n",
    "\n",
    "    BATCH_SIZE: int = 32  \n",
    "    EPOCHS: int = 20\n",
    "    LR: float = 3e-4        # Learning rate\n",
    "    WD: float = 1e-4        # Weight decay or Norm2 regularization\n",
    "\n",
    "    NUM_WORKERS: int = 4\n",
    "    SEED: int = 3557\n",
    "\n",
    "    RGB_BACKBONE: str = \"convnext_base\"  \n",
    "    AMP: bool = True\n",
    "\n",
    "    HS_DROP_FIRST: int = 10\n",
    "    HS_DROP_LAST: int = 14\n",
    "\n",
    "    OUT_DIR: str = \"/kaggle/working/\"\n",
    "    BEST_CKPT: str = \"best.pt\"\n",
    "\n",
    "\n",
    "LABELS = [\"Health\", \"Rust\", \"Other\"]\n",
    "LBL2ID = {k: i for i, k in enumerate(LABELS)}\n",
    "ID2LBL = {i: k for k, i in LBL2ID.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157388a5",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1578596c",
   "metadata": {},
   "source": [
    "- Indexing: \n",
    "```\n",
    "{\n",
    "    \"Health_hyper_1\": {\n",
    "        \"rgb\": \"train/RGB/Health_hyper_1.png\",\n",
    "        \"ms\":  \"train/MS/Health_hyper_1.tif\",\n",
    "        \"hs\":  \"train/HS/Health_hyper_1.tif\"\n",
    "    },\n",
    "    \"Rust_hyper_5\": {\n",
    "        \"rgb\": \"train/RGB/Rust_hyper_5.png\",\n",
    "        \"ms\":  \"train/MS/Rust_hyper_5.tif\",\n",
    "        \"hs\":  \"train/HS/Rust_hyper_5.tif\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "- Create DataFrame: \n",
    "```\n",
    "[base_id, label, rgb, ms, hs]\n",
    "[\n",
    "    [Health_hyper_1, Health, Health_hyper_1.png, Health_hyper_1.tif, Health_hyper_1.tif],\n",
    "    [Rust_hyper_5, Rust, Rust_hyper_5.png, Rust_hyper_5.tif, Rust_hyper_5.tif]\n",
    "]\n",
    "```\n",
    "\n",
    "- Stratified holdout: \n",
    "    - Train: 90%\n",
    "    - Validation: 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6457f1ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T01:39:22.870939Z",
     "iopub.status.busy": "2026-01-02T01:39:22.870683Z",
     "iopub.status.idle": "2026-01-02T01:39:22.882273Z",
     "shell.execute_reply": "2026-01-02T01:39:22.881677Z"
    },
    "papermill": {
     "duration": 0.015812,
     "end_time": "2026-01-02T01:39:22.883608",
     "exception": false,
     "start_time": "2026-01-02T01:39:22.867796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def list_files(folder: str, exts: Tuple[str, ...]) -> List[str]:\n",
    "    if not os.path.isdir(folder):\n",
    "        return []\n",
    "    out = []\n",
    "    for fn in os.listdir(folder):\n",
    "        if fn.lower().endswith(exts):\n",
    "            out.append(os.path.join(folder, fn))\n",
    "    return sorted(out)\n",
    "\n",
    "def base_id(path: str) -> str:\n",
    "    return os.path.splitext(os.path.basename(path))[0]\n",
    "\n",
    "def parse_label_from_train_name(bid: str) -> Optional[str]:\n",
    "    m = re.match(r\"^(Health|Rust|Other)_\", bid)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "def build_index(root: str, split: str) -> Dict[str, Dict[str, str]]:\n",
    "    split_dir = os.path.join(root, split)\n",
    "    rgb_dir = os.path.join(split_dir, \"RGB\")\n",
    "    ms_dir  = os.path.join(split_dir, \"MS\")\n",
    "    hs_dir  = os.path.join(split_dir, \"HS\")\n",
    "\n",
    "    rgb_files = list_files(rgb_dir, (\".png\", \".jpg\", \".jpeg\"))\n",
    "    ms_files  = list_files(ms_dir, (\".tif\", \".tiff\"))\n",
    "    hs_files  = list_files(hs_dir, (\".tif\", \".tiff\"))\n",
    "\n",
    "    idx: Dict[str, Dict[str, str]] = {}\n",
    "    for p in rgb_files:\n",
    "        idx.setdefault(base_id(p), {})[\"rgb\"] = p\n",
    "    for p in ms_files:\n",
    "        idx.setdefault(base_id(p), {})[\"ms\"] = p\n",
    "    for p in hs_files:\n",
    "        idx.setdefault(base_id(p), {})[\"hs\"] = p\n",
    "    return idx\n",
    "\n",
    "def make_train_df(train_idx: Dict[str, Dict[str, str]]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for bid, paths in train_idx.items():\n",
    "        lab = parse_label_from_train_name(bid)\n",
    "        if lab is None:\n",
    "            continue\n",
    "        rows.append({\n",
    "            \"base_id\": bid,\n",
    "            \"label\": lab,\n",
    "            \"rgb\": paths.get(\"rgb\"),\n",
    "            \"ms\":  paths.get(\"ms\"),\n",
    "            \"hs\":  paths.get(\"hs\"),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def make_val_df(val_idx: Dict[str, Dict[str, str]]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for bid, paths in val_idx.items():\n",
    "        rows.append({\n",
    "            \"base_id\": bid,\n",
    "            \"rgb\": paths.get(\"rgb\"),\n",
    "            \"ms\":  paths.get(\"ms\"),\n",
    "            \"hs\":  paths.get(\"hs\"),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def stratified_holdout(df: pd.DataFrame, frac: float = 0.1, seed: int = 42) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    df = df.sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
    "    parts = []\n",
    "    for lab, g in df.groupby(\"label\"):\n",
    "        n = max(1, int(len(g) * frac))\n",
    "        parts.append(g.iloc[:n])\n",
    "    df_va = pd.concat(parts).drop_duplicates(\"base_id\")\n",
    "    df_tr = df[~df[\"base_id\"].isin(df_va[\"base_id\"])].reset_index(drop=True)\n",
    "    df_va = df_va.reset_index(drop=True)\n",
    "    return df_tr, df_va"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4473aa5",
   "metadata": {},
   "source": [
    "## Read data and pre-processing images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31f8448",
   "metadata": {},
   "source": [
    "- Read image: \n",
    "1. RGB: original (H, W, 3) unit8 [0-255]\n",
    "    - -> BGR to RGB\n",
    "    - -> normalize to [0-1]\n",
    "    - -> Permute: (3, H, W)\n",
    "    - -> ImageNet normalization\n",
    "\n",
    "-> Output: Tensor (3, H, W) or (3, 224, 224), float32\n",
    "\n",
    "2. MS: original (H, W, 5) unit8 [0-255]\n",
    "    - -> normalize to [0-1]\n",
    "    - -> Permute: (5, H, W)\n",
    "\n",
    "3. HS: original (H, W, 125) unit16 [0-65535]\n",
    "    - -> Remove noisy bands (first 10, last 14) -> (H, W, 101)\n",
    "    - -> normalize to [0-1]\n",
    "    - -> Permute: (101, H, W)\n",
    "\n",
    "- Resize: 224x224 for all images\n",
    "- Padding/Cropping: ensure all HS images have 101 bands\n",
    "\n",
    "- Data augmentation: RandomHorizontalFlip, RandomVerticalFlip, RandomRotation(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30436477",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T01:39:22.888430Z",
     "iopub.status.busy": "2026-01-02T01:39:22.888143Z",
     "iopub.status.idle": "2026-01-02T01:39:22.902653Z",
     "shell.execute_reply": "2026-01-02T01:39:22.901975Z"
    },
    "papermill": {
     "duration": 0.018569,
     "end_time": "2026-01-02T01:39:22.904038",
     "exception": false,
     "start_time": "2026-01-02T01:39:22.885469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "IMAGENET_STD  = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "\n",
    "def fix_channels(x: torch.Tensor, target_c: int) -> torch.Tensor:\n",
    "    # x: (C,H,W) -> (target_c,H,W) by crop or zero-pad\n",
    "    c, h, w = x.shape\n",
    "    if c == target_c:\n",
    "        return x\n",
    "    if c > target_c:\n",
    "        return x[:target_c]\n",
    "    pad = torch.zeros((target_c - c, h, w), dtype=x.dtype)\n",
    "    return torch.cat([x, pad], dim=0)\n",
    "    \n",
    "def read_rgb(path: str) -> torch.Tensor:\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "    x = torch.from_numpy(img).permute(2, 0, 1)  # (H, W, C) -> (C, H, W) = (3,H,W)\n",
    "    x = (x - IMAGENET_MEAN) / IMAGENET_STD      # ImageNet normalization \n",
    "    return x\n",
    "\n",
    "def read_tiff_multiband(path: str) -> np.ndarray:\n",
    "    arr = tiff.imread(path)  # (H,W,C) or (C,H,W)\n",
    "    if arr.ndim != 3:\n",
    "        raise ValueError(f\"Expected 3D TIFF, got {arr.shape} for {path}\")\n",
    "    if arr.shape[0] < arr.shape[1] and arr.shape[0] < arr.shape[2]:\n",
    "        arr = np.transpose(arr, (1, 2, 0))  # -> (H,W,C)\n",
    "    return arr\n",
    "\n",
    "def normalize_per_band_minmax(x: np.ndarray, eps: float = 1e-6) -> np.ndarray:\n",
    "    x = np.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32)\n",
    "    H, W, C = x.shape\n",
    "    flat = x.reshape(-1, C)\n",
    "    mn = flat.min(axis=0)\n",
    "    mx = flat.max(axis=0)\n",
    "    denom = (mx - mn)\n",
    "    denom[denom < eps] = 1.0\n",
    "    x = (x - mn.reshape(1, 1, C)) / denom.reshape(1, 1, C)\n",
    "    return np.clip(x, 0.0, 1.0)\n",
    "\n",
    "def read_ms(path: str) -> torch.Tensor:\n",
    "    arr = read_tiff_multiband(path)           # (H,W,5)\n",
    "    arr = normalize_per_band_minmax(arr)\n",
    "    return torch.from_numpy(arr).permute(2, 0, 1)  # (5,H,W)\n",
    "\n",
    "def read_hs(path: str, drop_first: int, drop_last: int) -> torch.Tensor:\n",
    "    arr = read_tiff_multiband(path)           # (H,W,B)\n",
    "    B = arr.shape[2]\n",
    "    if B > (drop_first + drop_last + 1):\n",
    "        arr = arr[:, :, drop_first:B - drop_last]\n",
    "    arr = normalize_per_band_minmax(arr)\n",
    "    return torch.from_numpy(arr).permute(2, 0, 1)  # (B',H,W)\n",
    "\n",
    "def resize_tensor(x: torch.Tensor, size: int) -> torch.Tensor:\n",
    "    # x: (C,H,W) -> (C,size,size)\n",
    "    return F.interpolate(x.unsqueeze(0), size=(size, size), mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "\n",
    "def apply_joint_aug(x_rgb, x_ms, x_hs):\n",
    "    k = random.randint(0, 3)\n",
    "    do_h = random.random() < 0.5\n",
    "    do_v = random.random() < 0.5\n",
    "\n",
    "    def _tf(x):\n",
    "        if x is None:\n",
    "            return None\n",
    "        if k:\n",
    "            x = torch.rot90(x, k, dims=(1, 2))\n",
    "        if do_h:\n",
    "            x = torch.flip(x, dims=(2,))\n",
    "        if do_v:\n",
    "            x = torch.flip(x, dims=(1,))\n",
    "        return x\n",
    "\n",
    "    return _tf(x_rgb), _tf(x_ms), _tf(x_hs)\n",
    "\n",
    "def infer_hs_in_ch(df_train: pd.DataFrame, df_val: pd.DataFrame, cfg: CFG) -> int:\n",
    "    for df in (df_train, df_val):\n",
    "        if \"hs\" in df.columns:\n",
    "            for p in df[\"hs\"].dropna().tolist():\n",
    "                if p and os.path.exists(p):\n",
    "                    x = read_hs(p, cfg.HS_DROP_FIRST, cfg.HS_DROP_LAST)\n",
    "                    return int(x.shape[0])\n",
    "    return 101"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b901c3",
   "metadata": {},
   "source": [
    "## Handle missing modality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9299ae",
   "metadata": {},
   "source": [
    "- Sample missing modality -> tensor zeros\n",
    "- Mask vector [m_rgb, m_ms, m_hs]: 1 - available, 0 - missing\n",
    "    - [1, 1, 1]: all available\n",
    "    - [1, 1, 0]: missing HS\n",
    "    - [1, 0, 1]: missing MS\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f0f7b59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T01:39:22.908824Z",
     "iopub.status.busy": "2026-01-02T01:39:22.908440Z",
     "iopub.status.idle": "2026-01-02T01:39:22.917094Z",
     "shell.execute_reply": "2026-01-02T01:39:22.916414Z"
    },
    "papermill": {
     "duration": 0.012607,
     "end_time": "2026-01-02T01:39:22.918491",
     "exception": false,
     "start_time": "2026-01-02T01:39:22.905884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WheatMultiModalDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, cfg: CFG, hs_in_ch: int, train: bool):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.cfg = cfg\n",
    "        self.hs_in_ch = hs_in_ch\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, i: int):\n",
    "        row = self.df.iloc[i]\n",
    "        bid = row[\"base_id\"]\n",
    "\n",
    "        x_rgb = x_ms = x_hs = None\n",
    "        m_rgb = m_ms = m_hs = 0.0\n",
    "\n",
    "        if self.cfg.USE_RGB and row.get(\"rgb\") is not None:\n",
    "            x_rgb = read_rgb(row[\"rgb\"])\n",
    "            x_rgb = resize_tensor(x_rgb, self.cfg.IMG_SIZE)\n",
    "            m_rgb = 1.0\n",
    "\n",
    "        if self.cfg.USE_MS and row.get(\"ms\") is not None:\n",
    "            x_ms = read_ms(row[\"ms\"])\n",
    "            x_ms = resize_tensor(x_ms, self.cfg.IMG_SIZE)\n",
    "            m_ms = 1.0\n",
    "\n",
    "\n",
    "        if self.cfg.USE_HS and isinstance(row.get(\"hs\"), str) and row[\"hs\"]:\n",
    "            x_hs = read_hs(row[\"hs\"], self.cfg.HS_DROP_FIRST, self.cfg.HS_DROP_LAST)\n",
    "            x_hs = fix_channels(x_hs, self.hs_in_ch) \n",
    "            x_hs = resize_tensor(x_hs, self.cfg.IMG_SIZE)\n",
    "            m_hs = 1.0\n",
    "    \n",
    "        if self.train:\n",
    "            x_rgb, x_ms, x_hs = apply_joint_aug(x_rgb, x_ms, x_hs)\n",
    "\n",
    "        if self.cfg.USE_RGB and x_rgb is None:\n",
    "            x_rgb = torch.zeros(3, self.cfg.IMG_SIZE, self.cfg.IMG_SIZE, dtype=torch.float32)\n",
    "        if self.cfg.USE_MS and x_ms is None:\n",
    "            x_ms = torch.zeros(5, self.cfg.IMG_SIZE, self.cfg.IMG_SIZE, dtype=torch.float32)\n",
    "        if self.cfg.USE_HS and x_hs is None:\n",
    "            x_hs = torch.zeros(self.hs_in_ch, self.cfg.IMG_SIZE, self.cfg.IMG_SIZE, dtype=torch.float32)\n",
    "\n",
    "        mask = torch.tensor([m_rgb, m_ms, m_hs], dtype=torch.float32)\n",
    "\n",
    "        if \"label\" in row:\n",
    "            y = LBL2ID[row[\"label\"]]\n",
    "            return {\"id\": bid, \"rgb\": x_rgb, \"ms\": x_ms, \"hs\": x_hs, \"mask\": mask, \"y\": torch.tensor(y, dtype=torch.long)}\n",
    "        else:\n",
    "            return {\"id\": bid, \"rgb\": x_rgb, \"ms\": x_ms, \"hs\": x_hs, \"mask\": mask}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8d03aa",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beddca55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T01:39:22.923808Z",
     "iopub.status.busy": "2026-01-02T01:39:22.923558Z",
     "iopub.status.idle": "2026-01-02T01:39:22.934394Z",
     "shell.execute_reply": "2026-01-02T01:39:22.933768Z"
    },
    "papermill": {
     "duration": 0.015346,
     "end_time": "2026-01-02T01:39:22.935807",
     "exception": false,
     "start_time": "2026-01-02T01:39:22.920461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SmallSpectralEncoder(nn.Module):\n",
    "    def __init__(self, in_ch: int, emb_dim: int = 256):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, 32, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(128, 128, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, emb_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.block(x)\n",
    "        return self.head(x)\n",
    "\n",
    "class MultiModalNet(nn.Module):\n",
    "    def __init__(self, cfg: CFG, hs_in_ch: int, n_classes: int = 3):\n",
    "        super().__init__()\n",
    "        self.use_rgb = cfg.USE_RGB\n",
    "        self.use_ms  = cfg.USE_MS\n",
    "        self.use_hs  = cfg.USE_HS\n",
    "\n",
    "        feat_dims = []\n",
    "\n",
    "        if self.use_rgb:\n",
    "            self.rgb_enc = timm.create_model(cfg.RGB_BACKBONE, pretrained=True, num_classes=0, global_pool=\"avg\")\n",
    "            rgb_dim = self.rgb_enc.num_features\n",
    "            feat_dims.append(rgb_dim)\n",
    "        else:\n",
    "            self.rgb_enc = None\n",
    "\n",
    "        if self.use_ms:\n",
    "            self.ms_enc = SmallSpectralEncoder(in_ch=5, emb_dim=256)\n",
    "            feat_dims.append(256)\n",
    "        else:\n",
    "            self.ms_enc = None\n",
    "\n",
    "        if self.use_hs:\n",
    "            self.hs_enc = SmallSpectralEncoder(in_ch=hs_in_ch, emb_dim=256)\n",
    "            feat_dims.append(256)\n",
    "        else:\n",
    "            self.hs_enc = None\n",
    "\n",
    "        fusion_dim = sum(feat_dims)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(fusion_dim, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, rgb, ms, hs, mask):\n",
    "        feats = []\n",
    "        if self.use_rgb:\n",
    "            feats.append(self.rgb_enc(rgb) * mask[:, 0:1])\n",
    "        if self.use_ms:\n",
    "            feats.append(self.ms_enc(ms) * mask[:, 1:2])\n",
    "        if self.use_hs:\n",
    "            feats.append(self.hs_enc(hs) * mask[:, 2:3])\n",
    "\n",
    "        f = torch.cat(feats, dim=1)\n",
    "        return self.classifier(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4179af4d",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac24c36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T01:39:22.941019Z",
     "iopub.status.busy": "2026-01-02T01:39:22.940780Z",
     "iopub.status.idle": "2026-01-02T01:39:22.951735Z",
     "shell.execute_reply": "2026-01-02T01:39:22.951034Z"
    },
    "papermill": {
     "duration": 0.015275,
     "end_time": "2026-01-02T01:39:22.953177",
     "exception": false,
     "start_time": "2026-01-02T01:39:22.937902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total, correct = 0, 0\n",
    "    conf = np.zeros((3, 3), dtype=np.int64)\n",
    "\n",
    "    for batch in loader:\n",
    "        rgb  = batch[\"rgb\"].to(device)\n",
    "        ms   = batch[\"ms\"].to(device)\n",
    "        hs   = batch[\"hs\"].to(device)\n",
    "        mask = batch[\"mask\"].to(device)\n",
    "        y    = batch[\"y\"].to(device)\n",
    "\n",
    "        logits = model(rgb, ms, hs, mask)\n",
    "        pred = logits.argmax(dim=1)\n",
    "\n",
    "        total += y.size(0)\n",
    "        correct += (pred == y).sum().item()\n",
    "\n",
    "        yt = y.cpu().numpy()\n",
    "        yp = pred.cpu().numpy()\n",
    "        for t, p in zip(yt, yp):\n",
    "            conf[t, p] += 1\n",
    "\n",
    "    acc = correct / max(1, total)\n",
    "\n",
    "    f1s = []\n",
    "    for c in range(3):\n",
    "        tp = conf[c, c]\n",
    "        fp = conf[:, c].sum() - tp\n",
    "        fn = conf[c, :].sum() - tp\n",
    "        prec = tp / max(1, (tp + fp))\n",
    "        rec  = tp / max(1, (tp + fn))\n",
    "        f1 = 0.0 if (prec + rec) == 0 else (2 * prec * rec / (prec + rec))\n",
    "        f1s.append(f1)\n",
    "\n",
    "    return {\"acc\": float(acc), \"macro_f1\": float(np.mean(f1s))}\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    total_loss, n = 0.0, 0\n",
    "\n",
    "    for batch in loader:\n",
    "        rgb  = batch[\"rgb\"].to(device)\n",
    "        ms   = batch[\"ms\"].to(device)\n",
    "        hs   = batch[\"hs\"].to(device)\n",
    "        mask = batch[\"mask\"].to(device)\n",
    "        y    = batch[\"y\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
    "            logits = model(rgb, ms, hs, mask)\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        if scaler is not None:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        bs = y.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        n += bs\n",
    "\n",
    "    return total_loss / max(1, n)\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(model, loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    ids = []\n",
    "    for batch in loader:\n",
    "        rgb  = batch[\"rgb\"].to(device)\n",
    "        ms   = batch[\"ms\"].to(device)\n",
    "        hs   = batch[\"hs\"].to(device)\n",
    "        mask = batch[\"mask\"].to(device)\n",
    "\n",
    "        logits = model(rgb, ms, hs, mask)\n",
    "        p = logits.argmax(dim=1).cpu().numpy().tolist()\n",
    "        preds.extend([ID2LBL[x] for x in p])\n",
    "        ids.extend(batch[\"id\"])\n",
    "    return ids, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb31d04f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T01:39:22.958912Z",
     "iopub.status.busy": "2026-01-02T01:39:22.958505Z",
     "iopub.status.idle": "2026-01-02T01:57:10.637315Z",
     "shell.execute_reply": "2026-01-02T01:57:10.636464Z"
    },
    "papermill": {
     "duration": 1067.683836,
     "end_time": "2026-01-02T01:57:10.639135",
     "exception": false,
     "start_time": "2026-01-02T01:39:22.955299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Backbone: convnext_base\n",
      "Indexed train IDs: 600 | usable labeled train rows: 600\n",
      "Indexed val IDs:   300   | val rows: 300\n",
      "Inferred HS channels after trimming: 101\n",
      "Train split: 540 | Holdout split: 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0987dfbb1c034b6e848698949de9e174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/354M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25/4082396797.py:41: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(cfg.AMP and device.type == \"cuda\"))\n",
      "/tmp/ipykernel_25/640892646.py:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | loss=1.1012 | val_acc=0.5333 | val_macroF1=0.4256\n",
      "  -> saved best to /kaggle/working/best.pt\n",
      "Epoch 02 | loss=0.9305 | val_acc=0.4833 | val_macroF1=0.4221\n",
      "Epoch 03 | loss=0.8868 | val_acc=0.5500 | val_macroF1=0.4722\n",
      "  -> saved best to /kaggle/working/best.pt\n",
      "Epoch 04 | loss=0.8713 | val_acc=0.6667 | val_macroF1=0.6275\n",
      "  -> saved best to /kaggle/working/best.pt\n",
      "Epoch 05 | loss=0.8296 | val_acc=0.5000 | val_macroF1=0.4389\n",
      "Epoch 06 | loss=0.7708 | val_acc=0.6000 | val_macroF1=0.5703\n",
      "Epoch 07 | loss=0.7763 | val_acc=0.6500 | val_macroF1=0.5239\n",
      "Epoch 08 | loss=0.7569 | val_acc=0.5667 | val_macroF1=0.4872\n",
      "Epoch 09 | loss=0.7066 | val_acc=0.4500 | val_macroF1=0.3864\n",
      "Epoch 10 | loss=0.6471 | val_acc=0.6500 | val_macroF1=0.6210\n",
      "Epoch 11 | loss=0.6246 | val_acc=0.6667 | val_macroF1=0.6738\n",
      "  -> saved best to /kaggle/working/best.pt\n",
      "Epoch 12 | loss=0.6703 | val_acc=0.5500 | val_macroF1=0.5062\n",
      "Epoch 13 | loss=0.6115 | val_acc=0.6167 | val_macroF1=0.6048\n",
      "Epoch 14 | loss=0.5953 | val_acc=0.6167 | val_macroF1=0.5322\n",
      "Epoch 15 | loss=0.4828 | val_acc=0.6833 | val_macroF1=0.6643\n",
      "Epoch 16 | loss=0.4288 | val_acc=0.6500 | val_macroF1=0.6303\n",
      "Epoch 17 | loss=0.4645 | val_acc=0.4833 | val_macroF1=0.4689\n",
      "Epoch 18 | loss=0.5335 | val_acc=0.5500 | val_macroF1=0.5301\n",
      "Epoch 19 | loss=0.3914 | val_acc=0.6500 | val_macroF1=0.6395\n",
      "Epoch 20 | loss=0.2834 | val_acc=0.6000 | val_macroF1=0.5913\n"
     ]
    }
   ],
   "source": [
    "cfg = CFG()\n",
    "seed_everything(cfg.SEED)\n",
    "os.makedirs(cfg.OUT_DIR, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "print(\"Backbone:\", cfg.RGB_BACKBONE)\n",
    "\n",
    "train_idx = build_index(cfg.ROOT, cfg.TRAIN_DIR)\n",
    "val_idx   = build_index(cfg.ROOT, cfg.VAL_DIR)\n",
    "\n",
    "train_df = make_train_df(train_idx)\n",
    "val_df   = make_val_df(val_idx)\n",
    "\n",
    "print(f\"Indexed train IDs: {len(train_idx)} | usable labeled train rows: {len(train_df)}\")\n",
    "print(f\"Indexed val IDs:   {len(val_idx)}   | val rows: {len(val_df)}\")\n",
    "\n",
    "if len(train_df) == 0:\n",
    "    raise RuntimeError(\"No training samples found. Check ROOT/train and filename label pattern (Health_/Rust_/Other_).\")\n",
    "\n",
    "hs_in_ch = infer_hs_in_ch(train_df, val_df, cfg)\n",
    "print(\"Inferred HS channels after trimming:\", hs_in_ch)\n",
    "\n",
    "df_tr, df_va = stratified_holdout(train_df, frac=0.1, seed=cfg.SEED)\n",
    "print(f\"Train split: {len(df_tr)} | Holdout split: {len(df_va)}\")\n",
    "\n",
    "ds_tr = WheatMultiModalDataset(df_tr, cfg, hs_in_ch=hs_in_ch, train=True)\n",
    "ds_va = WheatMultiModalDataset(df_va, cfg, hs_in_ch=hs_in_ch, train=False)\n",
    "ds_te = WheatMultiModalDataset(val_df, cfg, hs_in_ch=hs_in_ch, train=False)\n",
    "\n",
    "dl_tr = DataLoader(ds_tr, batch_size=cfg.BATCH_SIZE, shuffle=True,\n",
    "                   num_workers=cfg.NUM_WORKERS, pin_memory=True, drop_last=True)\n",
    "dl_va = DataLoader(ds_va, batch_size=cfg.BATCH_SIZE, shuffle=False,\n",
    "                   num_workers=cfg.NUM_WORKERS, pin_memory=True)\n",
    "dl_te = DataLoader(ds_te, batch_size=cfg.BATCH_SIZE, shuffle=False,\n",
    "                   num_workers=cfg.NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "model = MultiModalNet(cfg, hs_in_ch=hs_in_ch, n_classes=3).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.LR, weight_decay=cfg.WD)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(cfg.AMP and device.type == \"cuda\"))\n",
    "\n",
    "best_f1 = -1.0\n",
    "best_path = os.path.join(cfg.OUT_DIR, cfg.BEST_CKPT)\n",
    "\n",
    "for ep in range(1, cfg.EPOCHS + 1):\n",
    "    tr_loss = train_one_epoch(model, dl_tr, optimizer, scaler if scaler.is_enabled() else None, device)\n",
    "    metrics = evaluate(model, dl_va, device)\n",
    "    print(f\"Epoch {ep:02d} | loss={tr_loss:.4f} | val_acc={metrics['acc']:.4f} | val_macroF1={metrics['macro_f1']:.4f}\")\n",
    "\n",
    "    if metrics[\"macro_f1\"] > best_f1:\n",
    "        best_f1 = metrics[\"macro_f1\"]\n",
    "        torch.save({\"model\": model.state_dict(), \"hs_in_ch\": hs_in_ch, \"cfg\": cfg.__dict__}, best_path)\n",
    "        print(f\"  -> saved best to {best_path}\")\n",
    "\n",
    "ckpt = torch.load(best_path, map_location=device)\n",
    "model.load_state_dict(ckpt[\"model\"], strict=True)\n",
    "\n",
    "pred_ids, pred_labels = predict(model, dl_te, device)\n",
    "\n",
    "\n",
    "sub_ids = []\n",
    "for _, r in val_df.iterrows():\n",
    "    if isinstance(r.get(\"hs\"), str) and r.get(\"hs\"):\n",
    "        sub_ids.append(os.path.basename(r[\"hs\"]))\n",
    "    elif isinstance(r.get(\"ms\"), str) and r.get(\"ms\"):\n",
    "        sub_ids.append(os.path.basename(r[\"ms\"]))\n",
    "    else:\n",
    "        sub_ids.append(os.path.basename(r[\"rgb\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d933db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T01:57:10.647010Z",
     "iopub.status.busy": "2026-01-02T01:57:10.646707Z",
     "iopub.status.idle": "2026-01-02T01:57:10.661913Z",
     "shell.execute_reply": "2026-01-02T01:57:10.661341Z"
    },
    "papermill": {
     "duration": 0.021073,
     "end_time": "2026-01-02T01:57:10.663406",
     "exception": false,
     "start_time": "2026-01-02T01:57:10.642333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({\"Id\": sub_ids, \"Category\": pred_labels})\n",
    "out_csv = os.path.join(cfg.OUT_DIR, \"submission.csv\")\n",
    "sub.to_csv(out_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96afd4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T01:57:10.671110Z",
     "iopub.status.busy": "2026-01-02T01:57:10.670827Z",
     "iopub.status.idle": "2026-01-02T01:57:10.688378Z",
     "shell.execute_reply": "2026-01-02T01:57:10.687640Z"
    },
    "papermill": {
     "duration": 0.023179,
     "end_time": "2026-01-02T01:57:10.689803",
     "exception": false,
     "start_time": "2026-01-02T01:57:10.666624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>val_000a83c1.tif</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val_00a704b1.tif</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>val_01dde030.tif</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Id Category\n",
       "0  val_000a83c1.tif     Rust\n",
       "1  val_00a704b1.tif   Health\n",
       "2  val_01dde030.tif   Health"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head(3)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14953781,
     "sourceId": 126119,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1089.830514,
   "end_time": "2026-01-02T01:57:15.579194",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-02T01:39:05.748680",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01538f8b0d494be6bdcba477549c6e36": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6992e165311a4f75b08532675fc5c0e2",
       "placeholder": "​",
       "style": "IPY_MODEL_76893b4c677d4bcab95b508e4359195b",
       "tabbable": null,
       "tooltip": null,
       "value": " 354M/354M [00:01&lt;00:00, 385MB/s]"
      }
     },
     "0987dfbb1c034b6e848698949de9e174": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_132c65fa3f2c4a7f946a7c8684b0c57c",
        "IPY_MODEL_5d3cb4a8b2e844b7826dff303af1b6da",
        "IPY_MODEL_01538f8b0d494be6bdcba477549c6e36"
       ],
       "layout": "IPY_MODEL_d3dc7b2a42da4df786936e3fb868fdea",
       "tabbable": null,
       "tooltip": null
      }
     },
     "132c65fa3f2c4a7f946a7c8684b0c57c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3b840cc4a9844413870078a2701269c0",
       "placeholder": "​",
       "style": "IPY_MODEL_b4da53446b984941833bacd6f6ed0c72",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "3b840cc4a9844413870078a2701269c0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "513bb3c0c3504aa6853c6155213a61af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5d3cb4a8b2e844b7826dff303af1b6da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7cb5936990d44411b656efd799be7fe2",
       "max": 354400320,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_513bb3c0c3504aa6853c6155213a61af",
       "tabbable": null,
       "tooltip": null,
       "value": 354400320
      }
     },
     "6992e165311a4f75b08532675fc5c0e2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "76893b4c677d4bcab95b508e4359195b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7cb5936990d44411b656efd799be7fe2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b4da53446b984941833bacd6f6ed0c72": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d3dc7b2a42da4df786936e3fb868fdea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
