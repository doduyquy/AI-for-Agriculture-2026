{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7e1db667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tifffile as tiff\n",
    "import torchvision.models as models\n",
    "import wandb\n",
    "import torch.optim as optim\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ===== PATHS =====\n",
    "HS_DIR = r\"D:\\HocTap\\NCKH_ThayDoNhuTai\\Challenges\\data\\raw\\train\\HS\"\n",
    "TEST_HS_DIR = r\"D:\\HocTap\\NCKH_ThayDoNhuTai\\Challenges\\data\\raw\\val\\HS\"\n",
    "CHECKPOINT_DIR = r\"D:\\HocTap\\NCKH_ThayDoNhuTai\\Challenges\\checkpoints\"\n",
    "CKPT_PATH = os.path.join(CHECKPOINT_DIR, \"best_hs125_resnet18_topK.pth\")\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# ===== DATA SETTINGS =====\n",
    "TARGET_BANDS = 125\n",
    "TARGET_HW = (64, 64)       # Resizing to 64x64 for consistency\n",
    "\n",
    "# ===== SPLIT =====\n",
    "VAL_RATIO = 0.2\n",
    "SEED = 42\n",
    "\n",
    "# ===== TRAIN =====\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "LR = 1e-4\n",
    "WD = 0.1\n",
    "NUM_WORKERS = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8e4ac766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Random seed set to 42 for reproducibility\n"
     ]
    }
   ],
   "source": [
    "# ===== REPRODUCIBILITY =====\n",
    "import random\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Set seed for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # for multi-GPU\n",
    "    \n",
    "    # Make PyTorch deterministic\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # Set environment variable for CUDA\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "    print(f\"✓ Random seed set to {seed} for reproducibility\")\n",
    "\n",
    "# Apply seed\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0c996475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS classes: ['Health', 'Other', 'Rust']\n",
      "NUM_CLASSES = 3\n"
     ]
    }
   ],
   "source": [
    "prefixes = sorted({\n",
    "    fn.split(\"_\")[0]\n",
    "    for fn in os.listdir(HS_DIR)\n",
    "    if fn.endswith(\".tif\")\n",
    "})\n",
    "\n",
    "print(\"MS classes:\", prefixes)\n",
    "print(\"NUM_CLASSES =\", len(prefixes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "new_cell_46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# ===============================================================\n",
    "# Robust CHW conversion  (dùng chung cho stats / train / test)\n",
    "# ===============================================================\n",
    "def ensure_chw(arr: np.ndarray, expected_bands: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Đảm bảo array có dạng (C, H, W).\n",
    "    Quy tắc:\n",
    "      - 2-D  -> (1, H, W)\n",
    "      - 3-D  -> so sánh shape[0] vs shape[2]:\n",
    "          * Nếu shape[2] == expected_bands            -> HWC, transpose\n",
    "          * Nếu shape[0] == expected_bands            -> đã CHW\n",
    "          * Nếu cả 2 != expected_bands                -> chọn dim nhỏ nhất làm C\n",
    "    \"\"\"\n",
    "    if arr.ndim == 2:\n",
    "        return arr[None, :, :]\n",
    "\n",
    "    if arr.ndim != 3:\n",
    "        raise ValueError(f\"Expected 2-D or 3-D array, got {arr.ndim}-D\")\n",
    "\n",
    "    d0, d1, d2 = arr.shape\n",
    "\n",
    "    # Trường hợp rõ ràng\n",
    "    if d2 == expected_bands and d0 != expected_bands:\n",
    "        return np.transpose(arr, (2, 0, 1))         # HWC -> CHW\n",
    "    if d0 == expected_bands and d2 != expected_bands:\n",
    "        return arr                                    # CHW rồi\n",
    "\n",
    "    # Cả 2 chiều == expected_bands (vuông): ưu tiên CHW (dim-0 = C)\n",
    "    if d0 == expected_bands and d2 == expected_bands:\n",
    "        return arr  # giữ nguyên, coi dim-0 là C\n",
    "\n",
    "    # Không chiều nào == expected_bands: chọn dim nhỏ nhất làm C\n",
    "    dims = [d0, d1, d2]\n",
    "    c_axis = int(np.argmin(dims))\n",
    "    if c_axis == 2:\n",
    "        return np.transpose(arr, (2, 0, 1))\n",
    "    elif c_axis == 1:\n",
    "        return np.transpose(arr, (1, 0, 2))\n",
    "    else:\n",
    "        return arr\n",
    "\n",
    "\n",
    "def fix_bands(arr: np.ndarray, target_bands: int) -> np.ndarray:\n",
    "    \"\"\"Cắt hoặc pad bands. Pad bằng mean spatial (tránh tín hiệu giả).\"\"\"\n",
    "    c = arr.shape[0]\n",
    "    if c > target_bands:\n",
    "        return arr[:target_bands]\n",
    "    if c < target_bands:\n",
    "        pad = np.repeat(\n",
    "            arr.mean(axis=0, keepdims=True),    # mean spatial\n",
    "            target_bands - c, axis=0\n",
    "        ).astype(arr.dtype)\n",
    "        return np.concatenate([arr, pad], axis=0)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def clip_per_band(x: torch.Tensor, ql=0.01, qh=0.99) -> torch.Tensor:\n",
    "    \"\"\"Clip mỗi band theo quantile q1/q99. Input/output: (C, H, W).\"\"\"\n",
    "    C = x.shape[0]\n",
    "    flat = x.view(C, -1)\n",
    "    lo = torch.quantile(flat, ql, dim=1).view(-1, 1, 1)\n",
    "    hi = torch.quantile(flat, qh, dim=1).view(-1, 1, 1)\n",
    "    return torch.clamp(x, lo, hi)\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# Compute global stats  (match pipeline: ensure_chw → fix_bands\n",
    "#                         → resize → clip_per_band → accumulate)\n",
    "# ===============================================================\n",
    "@torch.no_grad()\n",
    "def compute_global_stats_matched(\n",
    "    img_dir,\n",
    "    file_list,\n",
    "    target_bands=125,\n",
    "    target_hw=(64, 64),\n",
    "    clip_q=(0.01, 0.99),\n",
    "    eps=1e-8,\n",
    "    max_files=None,\n",
    "):\n",
    "    ql, qh = clip_q\n",
    "    sum_c   = torch.zeros(target_bands, dtype=torch.float64)\n",
    "    sumsq_c = torch.zeros(target_bands, dtype=torch.float64)\n",
    "    count   = 0\n",
    "\n",
    "    files = file_list if max_files is None else file_list[:max_files]\n",
    "\n",
    "    for fname in tqdm(files, desc=\"Computing stats\"):\n",
    "        path = os.path.join(img_dir, fname)\n",
    "        arr = tiff.imread(path).astype(np.float32)\n",
    "\n",
    "        arr = ensure_chw(arr, target_bands)\n",
    "        arr = fix_bands(arr, target_bands)\n",
    "\n",
    "        x = torch.from_numpy(arr)  # (C, H, W)\n",
    "\n",
    "        # Resize\n",
    "        if x.shape[1:] != target_hw:\n",
    "            x = F.interpolate(x.unsqueeze(0), size=target_hw,\n",
    "                              mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "\n",
    "        # Clip per-band\n",
    "        x = clip_per_band(x, ql, qh)\n",
    "\n",
    "        # Accumulate\n",
    "        sum_c   += x.sum(dim=(1, 2), dtype=torch.float64)\n",
    "        sumsq_c += (x * x).sum(dim=(1, 2), dtype=torch.float64)\n",
    "        count   += x.shape[1] * x.shape[2]\n",
    "\n",
    "    mean = (sum_c / (count + eps)).to(torch.float32)\n",
    "    var  = (sumsq_c / (count + eps) - mean.double()**2).clamp_min(0.0).to(torch.float32)\n",
    "    std  = torch.sqrt(var + eps)\n",
    "\n",
    "    return mean.cpu().numpy(), std.cpu().numpy()\n",
    "\n",
    "\n",
    "def label_from_filename(fname: str) -> str:\n",
    "    return os.path.basename(fname).split(\"_\")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c68a2322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import tifffile as tiff\n",
    "\n",
    "TARGET_BANDS = 125\n",
    "\n",
    "def to_chw(arr: np.ndarray, expected_bands: int = 125) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Đưa ảnh về dạng (C,H,W) từ các dạng phổ biến:\n",
    "    - (H,W,C)\n",
    "    - (C,H,W)\n",
    "    - (H,W) (hiếm)\n",
    "    \"\"\"\n",
    "    if arr.ndim == 2:\n",
    "        # (H,W) -> (1,H,W)\n",
    "        return arr[None, :, :]\n",
    "\n",
    "    if arr.ndim != 3:\n",
    "        raise ValueError(f\"Unsupported ndim={arr.ndim}, shape={arr.shape}\")\n",
    "\n",
    "    a, b, c = arr.shape\n",
    "\n",
    "    # Nếu đang HWC và C khớp expected hoặc rất gần expected\n",
    "    if c == expected_bands or c == expected_bands + 1 or c == expected_bands - 1:\n",
    "        return np.transpose(arr, (2, 0, 1))  # HWC -> CHW\n",
    "\n",
    "    # Nếu đang CHW và C khớp expected hoặc gần expected\n",
    "    if a == expected_bands or a == expected_bands + 1 or a == expected_bands - 1:\n",
    "        return arr  # đã CHW\n",
    "\n",
    "    # Heuristic: chọn chiều nhỏ nhất làm channel (thường C nhỏ hơn H,W nếu ảnh lớn)\n",
    "    # Nhưng với case 32x32x125 thì C=125 lại lớn hơn 32 -> heuristic này không dùng được.\n",
    "    # Nên ta ưu tiên nếu có chiều đúng/near expected ở trên; nếu không có thì fallback:\n",
    "    # Nếu một chiều <= 256 và hai chiều còn lại bằng nhau (ví dụ 32x32x125), khả năng C là chiều còn lại.\n",
    "    if a == b and c <= 256:\n",
    "        # arr là (H,W,C)\n",
    "        return np.transpose(arr, (2, 0, 1))\n",
    "    if b == c and a <= 256:\n",
    "        # arr là (C,H,W) nhưng H=W?\n",
    "        return arr\n",
    "    if a == c and b <= 256:\n",
    "        # hiếm, nhưng vẫn xử lý\n",
    "        return np.transpose(arr, (1, 0, 2))  # -> (H,C,W) rồi sẽ lỗi; để an toàn, raise\n",
    "    # Nếu vẫn mơ hồ:\n",
    "    raise ValueError(f\"Ambiguous shape {arr.shape}: can't infer channel dim safely.\")\n",
    "\n",
    "def fix_bands_chw(x_chw: np.ndarray, target_bands: int = 125, pad_mode: str = \"mean\") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    x_chw: (C,H,W) -> trả về (125,H,W)\n",
    "    - C > 125: cắt\n",
    "    - C == 126: cắt bỏ band cuối (thường là band thừa)\n",
    "    - C < 125: pad thêm band\n",
    "    \"\"\"\n",
    "    C, H, W = x_chw.shape\n",
    "\n",
    "    if C == target_bands:\n",
    "        return x_chw\n",
    "\n",
    "    if C > target_bands:\n",
    "        return x_chw[:target_bands, :, :]\n",
    "\n",
    "    # C < target_bands: pad\n",
    "    if pad_mode == \"mean\":\n",
    "        band_mean = x_chw.mean(axis=(1, 2), keepdims=True)  # (C,1,1)\n",
    "        pad_C = target_bands - C\n",
    "        # lặp mean của toàn ảnh theo từng band cuối cùng (hoặc dùng global mean chung)\n",
    "        # Cách đơn giản: dùng mean chung của toàn tensor\n",
    "        global_mean = x_chw.mean(keepdims=True)  # (1,1,1)\n",
    "        pad = np.repeat(global_mean, pad_C, axis=0)  # (pad_C,1,1) -> sẽ broadcast sai\n",
    "        # sửa cho đúng shape (pad_C,H,W)\n",
    "        pad = np.repeat(global_mean, pad_C, axis=0)\n",
    "        pad = np.repeat(pad, H, axis=1)\n",
    "        pad = np.repeat(pad, W, axis=2)\n",
    "        return np.concatenate([x_chw, pad], axis=0)\n",
    "\n",
    "    elif pad_mode == \"zero\":\n",
    "        pad_C = target_bands - C\n",
    "        pad = np.zeros((pad_C, H, W), dtype=x_chw.dtype)\n",
    "        return np.concatenate([x_chw, pad], axis=0)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"pad_mode must be 'mean' or 'zero'\")\n",
    "\n",
    "def load_hs_as_125(path: str, target_hw=(64, 64), target_bands: int = 125) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Đọc tif -> CHW -> fix bands -> resize -> tensor float32\n",
    "    \"\"\"\n",
    "    arr = tiff.imread(path).astype(np.float32)\n",
    "\n",
    "    x = to_chw(arr, expected_bands=target_bands)          # (C,H,W)\n",
    "    x = fix_bands_chw(x, target_bands=target_bands)       # (125,H,W)\n",
    "\n",
    "    x = torch.from_numpy(x)                               # (C,H,W)\n",
    "    x = x.unsqueeze(0)                                    # (1,C,H,W)\n",
    "    x = F.interpolate(x, size=target_hw, mode=\"bilinear\", align_corners=False)\n",
    "    x = x.squeeze(0)                                      # (C,H,W)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "new_cell_73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HSDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Hyperspectral Dataset with Global Z-score Normalization.\n",
    "    Pipeline: load → ensure_chw → fix_bands → resize → clip_per_band → z-score → augment\n",
    "    \"\"\"\n",
    "    def __init__(self, img_dir, file_list=None, target_bands=125, target_hw=(64, 64),\n",
    "                 augment=False, mean=None, std=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.target_bands = target_bands\n",
    "        self.target_hw = target_hw\n",
    "        self.augment = augment\n",
    "\n",
    "        # Normalization stats (per-band)\n",
    "        self.mean = (torch.tensor(mean).view(target_bands, 1, 1).float()\n",
    "                     if mean is not None else torch.zeros(target_bands, 1, 1))\n",
    "        self.std  = (torch.tensor(std).view(target_bands, 1, 1).float()\n",
    "                     if std is not None else torch.ones(target_bands, 1, 1))\n",
    "\n",
    "        if file_list is not None:\n",
    "            self.files = file_list\n",
    "        else:\n",
    "            self.files = sorted([f for f in os.listdir(img_dir)\n",
    "                                 if f.lower().endswith((\".tif\", \".tiff\"))])\n",
    "\n",
    "        # Label mapping\n",
    "        labels = sorted({label_from_filename(f) for f in self.files})\n",
    "        self.class_to_idx = {c: i for i, c in enumerate(labels)}\n",
    "        self.idx_to_class = {i: c for c, i in self.class_to_idx.items()}\n",
    "        self.y = [self.class_to_idx[label_from_filename(f)] for f in self.files]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.files[idx]\n",
    "        label = self.y[idx]\n",
    "        path  = os.path.join(self.img_dir, fname)\n",
    "\n",
    "        # 1. Load\n",
    "        arr = tiff.imread(path).astype(np.float32)\n",
    "\n",
    "        # 2. Ensure CHW (ƯU TIÊN case HWC = (32,32,125/126))\n",
    "        if arr.ndim != 3:\n",
    "            raise ValueError(f\"Invalid shape {arr.shape} | file={fname}\")\n",
    "\n",
    "        # Nếu là HWC (rất phổ biến với HS)\n",
    "        if arr.shape[2] in (125, 126):\n",
    "            arr = np.transpose(arr, (2, 0, 1))  # HWC -> CHW\n",
    "\n",
    "        # Nếu là CHW\n",
    "        elif arr.shape[0] in (125, 126):\n",
    "            pass  # đã đúng CHW\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Cannot infer channel dim: {arr.shape} | file={fname}\")\n",
    "\n",
    "        # 3. Fix bands → LUÔN về 125\n",
    "        C, H, W = arr.shape\n",
    "\n",
    "        if C == 126:\n",
    "            arr = arr[:125]          # cắt band thừa\n",
    "        elif C == 125:\n",
    "            pass                     # ok\n",
    "        elif C < 125:\n",
    "            # pad bằng spatial mean (rất hiếm với dataset này)\n",
    "            pad_c = 125 - C\n",
    "            mean_band = arr.mean(axis=(1, 2), keepdims=True).mean(axis=0)\n",
    "            pad = np.repeat(mean_band, pad_c, axis=0)\n",
    "            arr = np.concatenate([arr, pad], axis=0)\n",
    "        else:\n",
    "            arr = arr[:125]\n",
    "\n",
    "        x = torch.from_numpy(arr)    # (125,H,W)\n",
    "        assert x.shape[0] == 125, f\"Band mismatch {x.shape} | file={fname}\"\n",
    "\n",
    "        # 4. Resize\n",
    "        if x.shape[1:] != self.target_hw:\n",
    "            x = F.interpolate(\n",
    "                x.unsqueeze(0),\n",
    "                size=self.target_hw,\n",
    "                mode=\"bilinear\",\n",
    "                align_corners=False\n",
    "            ).squeeze(0)\n",
    "\n",
    "        # 5. Clip per-band (LUÔN chạy)\n",
    "        x = clip_per_band(x, 0.01, 0.99)\n",
    "\n",
    "        # 6. Z-score normalize\n",
    "        x = (x - self.mean) / (self.std + 1e-8)\n",
    "\n",
    "        # 7. Augmentation (spatial only – OK cho HS)\n",
    "        if self.augment:\n",
    "            if torch.rand(1) > 0.5:\n",
    "                x = torch.flip(x, dims=[2])  # horizontal\n",
    "            if torch.rand(1) > 0.5:\n",
    "                x = torch.flip(x, dims=[1])  # vertical\n",
    "            k = torch.randint(0, 4, (1,)).item()\n",
    "            x = torch.rot90(x, k, dims=[1, 2])\n",
    "\n",
    "        return x, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "25085bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Output bands after preprocessing ===\n",
      "125 577\n",
      "\n",
      "Non-125 or error samples: 0\n",
      "First 10: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "HS_DIR = r\"D:\\GitHub\\AI-for-Agriculture-2026\\dataset\\train\\HS\"  # sửa đúng path của bạn\n",
    "\n",
    "# Nếu bạn chưa có mean/std thì cho None để chỉ check shape\n",
    "ds = HSDataset(\n",
    "    img_dir=HS_DIR,\n",
    "    target_bands=125,\n",
    "    target_hw=(64, 64),\n",
    "    augment=False,\n",
    "    mean=None,   # hoặc mean_stats\n",
    "    std=None     # hoặc std_stats\n",
    ")\n",
    "\n",
    "counter = Counter()\n",
    "bad = []\n",
    "\n",
    "for i in range(len(ds)):\n",
    "    try:\n",
    "        x, y = ds[i]\n",
    "        counter[int(x.shape[0])] += 1\n",
    "        if x.shape[0] != 125:\n",
    "            bad.append((i, ds.files[i], tuple(x.shape)))\n",
    "    except Exception as e:\n",
    "        bad.append((i, ds.files[i], f\"ERROR: {e}\"))\n",
    "\n",
    "print(\"=== Output bands after preprocessing ===\")\n",
    "for k in sorted(counter.keys()):\n",
    "    print(k, counter[k])\n",
    "\n",
    "print(\"\\nNon-125 or error samples:\", len(bad))\n",
    "print(\"First 10:\", bad[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "new_cell_28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shared split loaded from: D:\\HocTap\\NCKH_ThayDoNhuTai\\Challenges\\Notebooks\\split\\splits\n",
      "  Total aligned samples: 577\n",
      "  Train: 461 | Val: 116\n",
      "  ✓ All files exist in D:\\GitHub\\AI-for-Agriculture-2026\\dataset\\train\\HS\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ============================================================\n",
    "# Load SHARED SPLIT (công bằng giữa RGB / MS / HS)\n",
    "# ============================================================\n",
    "SPLIT_DIR = r\"D:\\HocTap\\NCKH_ThayDoNhuTai\\Challenges\\Notebooks\\split\\splits\"\n",
    "\n",
    "df_master = pd.read_csv(os.path.join(SPLIT_DIR, \"samples_master.csv\"))\n",
    "train_idx_shared = np.load(os.path.join(SPLIT_DIR, \"train_idx.npy\"))\n",
    "val_idx_shared   = np.load(os.path.join(SPLIT_DIR, \"val_idx.npy\"))\n",
    "\n",
    "df_train = df_master.iloc[train_idx_shared].reset_index(drop=True)\n",
    "df_val   = df_master.iloc[val_idx_shared].reset_index(drop=True)\n",
    "\n",
    "# Lấy filename từ hs_path (basename, không phụ thuộc root)\n",
    "train_files = [os.path.basename(p) for p in df_train[\"hs_path\"]]\n",
    "val_files   = [os.path.basename(p) for p in df_val[\"hs_path\"]]\n",
    "\n",
    "print(f\"Shared split loaded from: {SPLIT_DIR}\")\n",
    "print(f\"  Total aligned samples: {len(df_master)}\")\n",
    "print(f\"  Train: {len(train_files)} | Val: {len(val_files)}\")\n",
    "\n",
    "# Verify files exist in HS_DIR\n",
    "missing = [f for f in train_files + val_files if not os.path.exists(os.path.join(HS_DIR, f))]\n",
    "if missing:\n",
    "    print(f\"  ⚠️ Missing {len(missing)} files! First 5: {missing[:5]}\")\n",
    "else:\n",
    "    print(f\"  ✓ All files exist in {HS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1050c6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating stats (TRAIN only)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing stats: 100%|██████████| 461/461 [00:21<00:00, 21.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean[0:5]: [581.4699  626.0004  649.4432  662.0995  669.45667]\n",
      "Std [0:5]: [1885.0404 1878.6755 1874.7366 1871.2903 1868.411 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 3) Tính stats trên TRAIN\n",
    "# =========================\n",
    "print(\"Calculating stats (TRAIN only)...\")\n",
    "mean_stats, std_stats = compute_global_stats_matched(\n",
    "    HS_DIR, train_files,\n",
    "    target_bands=TARGET_BANDS,\n",
    "    target_hw=TARGET_HW,\n",
    "    clip_q=(0.01, 0.99)\n",
    ")\n",
    "\n",
    "print(\"Mean[0:5]:\", mean_stats[:5])\n",
    "print(\"Std [0:5]:\", std_stats[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "70f05448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 461 | Val: 116\n",
      "Batch shape: torch.Size([32, 125, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 4) Dataset + DataLoader\n",
    "# =========================\n",
    "train_ds = HSDataset(\n",
    "    HS_DIR, file_list=train_files,\n",
    "    target_bands=TARGET_BANDS, target_hw=TARGET_HW,\n",
    "    augment=True, mean=mean_stats, std=std_stats\n",
    ")\n",
    "\n",
    "val_ds = HSDataset(\n",
    "    HS_DIR, file_list=val_files,\n",
    "    target_bands=TARGET_BANDS, target_hw=TARGET_HW,\n",
    "    augment=False, mean=mean_stats, std=std_stats\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "print(f\"Train: {len(train_ds)} | Val: {len(val_ds)}\")\n",
    "xb, yb = next(iter(train_loader))\n",
    "print(\"Batch shape:\", xb.shape)  # kỳ vọng: [B, 125, 64, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "34213c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     x, y = dataset[i]\n",
    "#     print(x.shape, x.min().item(), x.max().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "503d4a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape : torch.Size([32, 125, 64, 64])\n",
      "dtype       : torch.float32\n",
      "Min / Max   : -0.9381 / 1.7339\n",
      "Mean / Std  : -0.0584 / 0.3752\n",
      "Còn giá trị thô (>1000)? KHÔNG ✓\n",
      "\n",
      "Trước clip  : min=527.5  max=3091.5\n",
      "Sau clip    : min=581.2  max=3010.9\n",
      "Sau z-score : min=-0.32  max=0.69\n"
     ]
    }
   ],
   "source": [
    "# ====== Sanity check: giá trị 65535 (uint16 max) không nên còn sau pipeline ======\n",
    "xb, yb = next(iter(train_loader))\n",
    "print(f\"Batch shape : {xb.shape}\")          # expect [B, 125, 64, 64]\n",
    "print(f\"dtype       : {xb.dtype}\")\n",
    "print(f\"Min / Max   : {xb.min():.4f} / {xb.max():.4f}\")\n",
    "print(f\"Mean / Std  : {xb.mean():.4f} / {xb.std():.4f}\")\n",
    "\n",
    "has_raw = (xb.abs() > 1000).any().item()\n",
    "print(f\"Còn giá trị thô (>1000)? {'CÓ ⚠️' if has_raw else 'KHÔNG ✓'}\")\n",
    "\n",
    "# Check 1 sample riêng (trước z-score) để xác nhận clip hoạt động\n",
    "sample_arr = tiff.imread(os.path.join(HS_DIR, train_files[0])).astype(np.float32)\n",
    "sample_arr = ensure_chw(sample_arr, TARGET_BANDS)\n",
    "sample_arr = fix_bands(sample_arr, TARGET_BANDS)\n",
    "xs = torch.from_numpy(sample_arr)\n",
    "if xs.shape[1:] != TARGET_HW:\n",
    "    xs = F.interpolate(xs.unsqueeze(0), size=TARGET_HW, mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "print(f\"\\nTrước clip  : min={xs.min():.1f}  max={xs.max():.1f}\")\n",
    "xs = clip_per_band(xs, 0.01, 0.99)\n",
    "print(f\"Sau clip    : min={xs.min():.1f}  max={xs.max():.1f}\")\n",
    "xs = (xs - torch.tensor(mean_stats).view(-1,1,1)) / (torch.tensor(std_stats).view(-1,1,1) + 1e-8)\n",
    "print(f\"Sau z-score : min={xs.min():.2f}  max={xs.max():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "163fd228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class GatedResNet18(nn.Module):\n",
    "    def __init__(self, num_bands=125, num_classes=3):\n",
    "        super().__init__()\n",
    "\n",
    "        # gate: để dương và dễ ổn định -> dùng sigmoid\n",
    "        self.gate_logits = nn.Parameter(0.01 * torch.randn(num_bands))  # thay vì zeros\n",
    "\n",
    "        base = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "        # sửa conv1 nhận num_bands\n",
    "        old_conv = base.conv1\n",
    "        base.conv1 = nn.Conv2d(num_bands, old_conv.out_channels,\n",
    "                               kernel_size=old_conv.kernel_size,\n",
    "                               stride=old_conv.stride,\n",
    "                               padding=old_conv.padding,\n",
    "                               bias=False)\n",
    "\n",
    "        # init conv1: lấy mean weight RGB rồi lặp lại\n",
    "        with torch.no_grad():\n",
    "            base.conv1.weight[:] = old_conv.weight.mean(dim=1, keepdim=True).repeat(1, num_bands, 1, 1)\n",
    "\n",
    "        base.fc = nn.Linear(base.fc.in_features, num_classes)\n",
    "        self.backbone = base\n",
    "\n",
    "    def forward(self, x):\n",
    "        g = torch.sigmoid(self.gate_logits)          # (C,)\n",
    "        x = x * g.view(1, -1, 1, 1)                  # nhân theo band\n",
    "        return self.backbone(x)\n",
    "\n",
    "    def gate(self):\n",
    "        return torch.sigmoid(self.gate_logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "new_cell_19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(train_ds.class_to_idx)\n",
    "model = GatedResNet18(num_bands=TARGET_BANDS, num_classes=num_classes).to(device)\n",
    "\n",
    "\n",
    "# # Adjust first conv for 125 channels\n",
    "# old_conv = model.conv1\n",
    "# model.conv1 = nn.Conv2d(TARGET_BANDS, old_conv.out_channels, \n",
    "#                         kernel_size=old_conv.kernel_size, stride=old_conv.stride, \n",
    "#                         padding=old_conv.padding, bias=False)\n",
    "\n",
    "# # Init weights: average RGB weights and replicate\n",
    "# with torch.no_grad():\n",
    "#     model.conv1.weight[:] = old_conv.weight.mean(dim=1, keepdim=True).repeat(1, TARGET_BANDS, 1, 1)\n",
    "\n",
    "# model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Move entire model to GPU after all modifications\n",
    "model = model.to(device)\n",
    "print(f\"Model on device: {next(model.parameters()).device}\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "gate_params = [model.gate_logits]\n",
    "other_params = [p for n,p in model.named_parameters() if n != \"gate_logits\"]\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {\"params\": other_params, \"lr\": 1e-4, \"weight_decay\": 0.1},\n",
    "    {\"params\": gate_params,  \"lr\": 1e-2, \"weight_decay\": 0.0},  # lr cao hơn cho gate\n",
    "])\n",
    "\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "56a98ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from collections import Counter\n",
    "# import tifffile as tiff\n",
    "# import numpy as np\n",
    "\n",
    "# HS_DIR = r\"D:\\GitHub\\AI-for-Agriculture-2026\\dataset\\train\\HS\"  # sửa lại đúng path của bạn\n",
    "\n",
    "# def infer_num_bands(arr: np.ndarray) -> int:\n",
    "#     if arr.ndim != 3:\n",
    "#         return -1  # lỗi shape\n",
    "#     # ưu tiên nếu có chiều 125/126 rõ ràng\n",
    "#     if arr.shape[2] in (125, 126):\n",
    "#         return arr.shape[2]       # HWC\n",
    "#     if arr.shape[0] in (125, 126):\n",
    "#         return arr.shape[0]       # CHW\n",
    "#     # fallback: lấy chiều lớn nhất làm C (case 32x32x125 -> 125 là lớn nhất)\n",
    "#     return max(arr.shape)\n",
    "\n",
    "# band_counter = Counter()\n",
    "# shape_counter = Counter()\n",
    "# bad_files = []\n",
    "\n",
    "# for fn in os.listdir(HS_DIR):\n",
    "#     if not fn.lower().endswith((\".tif\", \".tiff\")):\n",
    "#         continue\n",
    "#     path = os.path.join(HS_DIR, fn)\n",
    "#     try:\n",
    "#         arr = tiff.imread(path)\n",
    "#         shape_counter[str(arr.shape)] += 1\n",
    "#         b = infer_num_bands(arr)\n",
    "#         band_counter[b] += 1\n",
    "#     except Exception as e:\n",
    "#         bad_files.append((fn, str(e)))\n",
    "\n",
    "# print(\"=== Band counts ===\")\n",
    "# for k in sorted(band_counter.keys()):\n",
    "#     print(f\"{k}: {band_counter[k]}\")\n",
    "\n",
    "# print(\"\\n=== Top shapes ===\")\n",
    "# for s, c in shape_counter.most_common(10):\n",
    "#     print(f\"{s}: {c}\")\n",
    "\n",
    "# if bad_files:\n",
    "#     print(\"\\n=== Bad files (first 10) ===\")\n",
    "#     for x in bad_files[:10]:\n",
    "#         print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "64723bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([32, 125, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "x, y = batch\n",
    "print(\"Batch shape:\", x.shape)  # phải là [B, 125, H, W]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5168b9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# # 1) Tạo INSTANCE dataset (đúng như bạn dùng để train)\n",
    "# dataset = HSDataset(\n",
    "#     img_dir=HS_DIR,          # ví dụ: r\"D:\\GitHub\\AI-for-Agriculture-2026\\dataset\\train\\HS\"\n",
    "#     files=train_files,       # nếu bạn có split; nếu không thì bỏ tham số này\n",
    "#     mean=mean_stats,         # tensor/np shape (125,) hoặc (125,1,1) tuỳ bạn thiết kế\n",
    "#     std=std_stats,\n",
    "#     target_bands=125,\n",
    "#     target_hw=(64,64),\n",
    "#     augment=False            # để check ổn định\n",
    "# )\n",
    "\n",
    "# counter = Counter()\n",
    "# bad = []\n",
    "\n",
    "# for i in range(len(dataset)):\n",
    "#     try:\n",
    "#         x, y = dataset[i]  # <-- đúng: index instance\n",
    "#         counter[int(x.shape[0])] += 1\n",
    "#         if x.shape[0] != 125:\n",
    "#             bad.append((i, dataset.files[i], tuple(x.shape)))\n",
    "#     except Exception as e:\n",
    "#         bad.append((i, dataset.files[i], f\"ERROR: {e}\"))\n",
    "\n",
    "# print(\"=== Output bands after preprocessing ===\")\n",
    "# for k in sorted(counter.keys()):\n",
    "#     print(k, counter[k])\n",
    "\n",
    "# print(\"\\nNon-125 or error samples:\", len(bad))\n",
    "# print(\"First 10:\", bad[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf6b73e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "new_cell_45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# wandb.init(project=\"beyond-visible-spectrum\", name=\"baseline_hs125_resnet\")\n",
    "\n",
    "LAMBDA_L1 = 0.5  # bạn có thể thử 5e-4, 1e-3, 2e-3\n",
    "\n",
    "def train_one_epoch(loader):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(x)\n",
    "        ce = criterion(out, y)\n",
    "\n",
    "        # L1 trên gate (sau sigmoid)\n",
    "        K = 20\n",
    "        LAMBDA_K = 0.5\n",
    "        g = model.gate()\n",
    "        k_pen = (g.sum() - K) ** 2\n",
    "        loss = ce + LAMBDA_K * k_pen\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        # print(\"grad None?\", model.gate_logits.grad is None,\n",
    "        # \"grad mean abs:\", None if model.gate_logits.grad is None else model.gate_logits.grad.abs().mean().item())\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        correct += (out.argmax(1) == y).sum().item()\n",
    "        total += x.size(0)\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        correct += (out.argmax(1) == y).sum().item()\n",
    "        total += x.size(0)\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "# best_acc = 0.0\n",
    "# for epoch in range(1, EPOCHS+1):\n",
    "#     train_loss, train_acc = train_one_epoch(train_loader)\n",
    "#     val_loss, val_acc = evaluate(val_loader)\n",
    "#     scheduler.step(val_acc)\n",
    "    \n",
    "#     print(f\"Epoch {epoch} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "#     # wandb.log({\"train_loss\": train_loss, \"train_acc\": train_acc, \"val_loss\": val_loss, \"val_acc\": val_acc})\n",
    "    \n",
    "#     if val_acc > best_acc:\n",
    "#         best_acc = val_acc\n",
    "#         torch.save(model.state_dict(), CKPT_PATH)\n",
    "#         print(f\"Saved best model: {val_acc:.4f}\")\n",
    "\n",
    "# wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2a8ba2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ gate grad = None\n"
     ]
    }
   ],
   "source": [
    "if model.gate_logits.grad is None:\n",
    "    print(\"❌ gate grad = None\")\n",
    "else:\n",
    "    print(\"gate grad mean abs:\", model.gate_logits.grad.abs().mean().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "267b4428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Acc: 0.6855 | Val Acc: 0.5862 | gate_sum=44.30 std=0.0018 min/max=(0.350,0.359)\n",
      "✅ Saved BEST checkpoint @epoch 1 | best_acc=0.5862 -> D:\\HocTap\\NCKH_ThayDoNhuTai\\Challenges\\checkpoints\\best_hs125_resnet18_topK.pth\n",
      "Epoch 02 | Train Acc: 0.7397 | Val Acc: 0.5776 | gate_sum=41.24 std=0.0017 min/max=(0.325,0.335)\n",
      "Epoch 03 | Train Acc: 0.6833 | Val Acc: 0.5776 | gate_sum=38.59 std=0.0016 min/max=(0.304,0.313)\n",
      "Epoch 04 | Train Acc: 0.7657 | Val Acc: 0.5603 | gate_sum=36.30 std=0.0016 min/max=(0.286,0.295)\n",
      "Epoch 05 | Train Acc: 0.7852 | Val Acc: 0.5862 | gate_sum=34.32 std=0.0015 min/max=(0.271,0.278)\n",
      "Epoch 06 | Train Acc: 0.8069 | Val Acc: 0.5862 | gate_sum=33.45 std=0.0014 min/max=(0.264,0.271)\n",
      "Epoch 07 | Train Acc: 0.8069 | Val Acc: 0.6466 | gate_sum=32.63 std=0.0014 min/max=(0.257,0.265)\n",
      "✅ Saved BEST checkpoint @epoch 7 | best_acc=0.6466 -> D:\\HocTap\\NCKH_ThayDoNhuTai\\Challenges\\checkpoints\\best_hs125_resnet18_topK.pth\n",
      "Epoch 08 | Train Acc: 0.8677 | Val Acc: 0.6379 | gate_sum=31.87 std=0.0014 min/max=(0.251,0.259)\n",
      "Epoch 09 | Train Acc: 0.8351 | Val Acc: 0.6034 | gate_sum=31.14 std=0.0013 min/max=(0.246,0.253)\n",
      "Epoch 10 | Train Acc: 0.8850 | Val Acc: 0.5862 | gate_sum=30.45 std=0.0013 min/max=(0.240,0.247)\n",
      "Done. Best Val Acc = 0.6466 at epoch 7\n"
     ]
    }
   ],
   "source": [
    "best_acc = -1.0\n",
    "best_epoch = -1\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss, train_acc = train_one_epoch(train_loader)\n",
    "    val_loss, val_acc = evaluate(val_loader)\n",
    "    scheduler.step(val_acc)\n",
    "\n",
    "    # log thêm gate để biết nó có thưa không\n",
    "    with torch.no_grad():\n",
    "        g = model.gate().detach()\n",
    "        gate_sum = g.sum().item()\n",
    "        gate_min = g.min().item()\n",
    "        gate_max = g.max().item()\n",
    "        gate_std = g.std().item()\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | \"\n",
    "        f\"Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f} | \"\n",
    "        f\"gate_sum={gate_sum:.2f} std={gate_std:.4f} min/max=({gate_min:.3f},{gate_max:.3f})\"\n",
    "    )\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_epoch = epoch\n",
    "\n",
    "        ckpt = {\n",
    "            \"epoch\": epoch,\n",
    "            \"best_acc\": best_acc,\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"optimizer_state\": optimizer.state_dict(),\n",
    "            \"scheduler_state\": scheduler.state_dict(),\n",
    "            \"config\": {\n",
    "                \"EPOCHS\": EPOCHS,\n",
    "                \"LR\": LR,\n",
    "                \"WD\": WD,\n",
    "                \"LAMBDA_L1\": LAMBDA_L1,\n",
    "            },\n",
    "        }\n",
    "        torch.save(ckpt, CKPT_PATH)\n",
    "        print(f\"✅ Saved BEST checkpoint @epoch {epoch} | best_acc={best_acc:.4f} -> {CKPT_PATH}\")\n",
    "\n",
    "print(f\"Done. Best Val Acc = {best_acc:.4f} at epoch {best_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb84f265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from epoch 2 | best_acc=0.6293103448275862\n",
      "Model on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# ===== Load best checkpoint =====\n",
    "ckpt = torch.load(CKPT_PATH, map_location=device, weights_only=True)\n",
    "\n",
    "# Nếu checkpoint lưu dict đầy đủ (có key \"model_state\")\n",
    "if isinstance(ckpt, dict) and \"model_state\" in ckpt:\n",
    "    model.load_state_dict(ckpt[\"model_state\"])\n",
    "    print(f\"Loaded checkpoint from epoch {ckpt.get('epoch', '?')} | best_acc={ckpt.get('best_acc', '?')}\")\n",
    "else:\n",
    "    # Nếu checkpoint chỉ lưu state_dict trực tiếp\n",
    "    model.load_state_dict(ckpt)\n",
    "    print(\"Loaded state_dict directly\")\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "print(f\"Model on device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de38bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "  GATE ANALYSIS  (Total bands = 125, K = 20)\n",
      "============================================================\n",
      "  Gate sum   : 62.16\n",
      "  Gate mean  : 0.4973\n",
      "  Gate std   : 0.0020\n",
      "  Gate min   : 0.4920  (band 10)\n",
      "  Gate max   : 0.5027  (band 41)\n",
      "============================================================\n",
      "\n",
      "  TOP-20 BANDS (highest gate values):\n",
      "    Band    Gate Value\n",
      "  --------------------\n",
      "      41      0.502746\n",
      "      95      0.502545\n",
      "      21      0.502119\n",
      "     122      0.501854\n",
      "      65      0.501766\n",
      "      57      0.500829\n",
      "      43      0.500530\n",
      "      16      0.500378\n",
      "      18      0.499956\n",
      "     108      0.499791\n",
      "       4      0.499773\n",
      "      49      0.499748\n",
      "      66      0.499731\n",
      "      42      0.499623\n",
      "      97      0.499550\n",
      "       2      0.499481\n",
      "      85      0.499397\n",
      "     102      0.499298\n",
      "      80      0.499281\n",
      "     106      0.499263\n",
      "\n",
      "  Top-20 band indices (sorted): [2, 4, 16, 18, 21, 41, 42, 43, 49, 57, 65, 66, 80, 85, 95, 97, 102, 106, 108, 122]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Plot saved to D:\\HocTap\\NCKH_ThayDoNhuTai\\Challenges\\checkpoints\\gate_analysis_topK.png\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===== 1. Lấy gate values =====\n",
    "with torch.no_grad():\n",
    "    gate_vals = model.gate().detach().cpu().numpy()  # (125,)\n",
    "\n",
    "K = 20  # Số band muốn chọn\n",
    "\n",
    "# ===== 2. Sắp xếp theo gate value (cao → thấp) =====\n",
    "sorted_idx = np.argsort(gate_vals)[::-1]  # descending\n",
    "topK_idx = sorted_idx[:K]\n",
    "topK_vals = gate_vals[topK_idx]\n",
    "bottomK_idx = sorted_idx[-K:]\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"  GATE ANALYSIS  (Total bands = {len(gate_vals)}, K = {K})\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"  Gate sum   : {gate_vals.sum():.2f}\")\n",
    "print(f\"  Gate mean  : {gate_vals.mean():.4f}\")\n",
    "print(f\"  Gate std   : {gate_vals.std():.4f}\")\n",
    "print(f\"  Gate min   : {gate_vals.min():.4f}  (band {gate_vals.argmin()})\")\n",
    "print(f\"  Gate max   : {gate_vals.max():.4f}  (band {gate_vals.argmax()})\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\n  TOP-{K} BANDS (highest gate values):\")\n",
    "print(f\"  {'Band':>6s}  {'Gate Value':>12s}\")\n",
    "print(f\"  {'-'*20}\")\n",
    "for i, (band, val) in enumerate(zip(topK_idx, topK_vals)):\n",
    "    print(f\"  {band:>6d}  {val:>12.6f}\")\n",
    "\n",
    "print(f\"\\n  Top-{K} band indices (sorted): {sorted(topK_idx.tolist())}\")\n",
    "\n",
    "# ===== 3. Visualize =====\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# (a) Bar chart - all 125 bands\n",
    "ax1 = axes[0]\n",
    "colors = ['#e74c3c' if i in topK_idx else '#3498db' for i in range(len(gate_vals))]\n",
    "ax1.bar(range(len(gate_vals)), gate_vals, color=colors, alpha=0.8, width=1.0)\n",
    "ax1.set_xlabel(\"Band Index\")\n",
    "ax1.set_ylabel(\"Gate Value (sigmoid)\")\n",
    "ax1.set_title(f\"Gate Values per Band (Red = Top-{K})\")\n",
    "ax1.axhline(y=gate_vals.mean(), color='green', linestyle='--', alpha=0.7, label=f'Mean={gate_vals.mean():.4f}')\n",
    "ax1.legend()\n",
    "\n",
    "# (b) Sorted gate values\n",
    "ax2 = axes[1]\n",
    "sorted_vals = gate_vals[sorted_idx]\n",
    "colors_sorted = ['#e74c3c' if i < K else '#95a5a6' for i in range(len(sorted_vals))]\n",
    "ax2.bar(range(len(sorted_vals)), sorted_vals, color=colors_sorted, alpha=0.8, width=1.0)\n",
    "ax2.set_xlabel(\"Rank (high → low)\")\n",
    "ax2.set_ylabel(\"Gate Value (sigmoid)\")\n",
    "ax2.set_title(f\"Sorted Gate Values (Red = Top-{K})\")\n",
    "ax2.axvline(x=K-0.5, color='black', linestyle='--', alpha=0.5, label=f'K={K} cutoff')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(CHECKPOINT_DIR, \"gate_analysis_topK.png\"), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"\\n📊 Plot saved to {os.path.join(CHECKPOINT_DIR, 'gate_analysis_topK.png')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d9385e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Top-20 band info saved to: D:\\HocTap\\NCKH_ThayDoNhuTai\\Challenges\\checkpoints\\topK_band_info.json\n",
      "\n",
      "📌 Dùng bands này cho pipeline tiếp theo:\n",
      "   SELECTED_BANDS = [2, 4, 16, 18, 21, 41, 42, 43, 49, 57, 65, 66, 80, 85, 95, 97, 102, 106, 108, 122]\n",
      "\n",
      " Threshold |   #Bands > threshold\n",
      "-----------------------------------\n",
      "     0.300 |                  125\n",
      "     0.400 |                  125\n",
      "     0.450 |                  125\n",
      "     0.490 |                  125\n",
      "     0.495 |                  109\n",
      "     0.500 |                    8\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# ===== Lưu Top-K band info =====\n",
    "topK_info = {\n",
    "    \"K\": int(K),\n",
    "    \"topK_band_indices\": sorted(topK_idx.tolist()),\n",
    "    \"topK_band_indices_by_importance\": topK_idx.tolist(),\n",
    "    \"topK_gate_values\": topK_vals.tolist(),\n",
    "    \"gate_stats\": {\n",
    "        \"sum\": float(gate_vals.sum()),\n",
    "        \"mean\": float(gate_vals.mean()),\n",
    "        \"std\": float(gate_vals.std()),\n",
    "        \"min\": float(gate_vals.min()),\n",
    "        \"max\": float(gate_vals.max()),\n",
    "    },\n",
    "    \"all_gate_values\": gate_vals.tolist(),\n",
    "    \"source_checkpoint\": CKPT_PATH,\n",
    "}\n",
    "\n",
    "topK_info_path = os.path.join(CHECKPOINT_DIR, \"topK_band_info.json\")\n",
    "with open(topK_info_path, \"w\") as f:\n",
    "    json.dump(topK_info, f, indent=2)\n",
    "\n",
    "print(f\"✅ Top-{K} band info saved to: {topK_info_path}\")\n",
    "print(f\"\\n📌 Dùng bands này cho pipeline tiếp theo:\")\n",
    "print(f\"   SELECTED_BANDS = {sorted(topK_idx.tolist())}\")\n",
    "\n",
    "# ===== Threshold-based selection (thay vì hard K) =====\n",
    "thresholds = [0.3, 0.4, 0.45, 0.49, 0.495, 0.5]\n",
    "print(f\"\\n{'Threshold':>10s} | {'#Bands > threshold':>20s}\")\n",
    "print(\"-\" * 35)\n",
    "for t in thresholds:\n",
    "    n = (gate_vals > t).sum()\n",
    "    print(f\"{t:>10.3f} | {n:>20d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f17adec",
   "metadata": {},
   "source": [
    "## ⚠️ Lưu ý về Gate Training\n",
    "\n",
    "Nếu gate values đều gần **0.5** (std rất nhỏ), điều đó có nghĩa là gate chưa học được band nào quan trọng hơn. \n",
    "\n",
    "**Nguyên nhân thường gặp:**\n",
    "1. **Train chưa đủ epoch** — cần train thêm (20-50 epochs)\n",
    "2. **LAMBDA_K quá nhỏ** — tăng lên 0.1-0.5 để ép gate thưa hơn\n",
    "3. **Learning rate cho gate quá nhỏ** — thử tách lr riêng cho gate (lr = 1e-2)\n",
    "\n",
    "**Gợi ý cải thiện:**\n",
    "```python\n",
    "# Tách optimizer cho gate với lr cao hơn\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {\"params\": other_params, \"lr\": 1e-4, \"weight_decay\": 0.1},\n",
    "    {\"params\": gate_params,  \"lr\": 1e-2, \"weight_decay\": 0.0},  # lr cao hơn cho gate\n",
    "])\n",
    "\n",
    "# Tăng K penalty\n",
    "LAMBDA_K = 0.5  # thay vì 0.05\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178becf1",
   "metadata": {},
   "source": [
    "---\n",
    "# 🔬 Hard-Concrete / L0 Gate — Band Selection\n",
    "\n",
    "## 1. Vấn đề với Sigmoid Gate đơn giản\n",
    "\n",
    "Sigmoid gate ở trên có **vấn đề**: gradient của sigmoid rất phẳng ở vùng gần 0 và 1, nên:\n",
    "- Gate khó **collapse về 0** (tắt band) hoặc **lên 1** (giữ band)\n",
    "- Tất cả gate đều \"kẹt\" quanh 0.5 → **không phân biệt** band quan trọng / không quan trọng\n",
    "- Penalty $(g_{sum} - K)^2$ ép **tổng** giảm nhưng mỗi gate giảm **đều nhau** (không thưa)\n",
    "\n",
    "## 2. Hard-Concrete Distribution (Louizos et al., 2018)\n",
    "\n",
    "> **Paper**: *\"Learning Sparse Neural Networks through L0 Regularization\"* — ICLR 2018\n",
    "\n",
    "### Ý tưởng chính:\n",
    "Thay vì `sigmoid(logit)` liên tục trong $(0, 1)$, Hard-Concrete tạo ra gate có thể **chính xác = 0** hoặc **chính xác = 1**.\n",
    "\n",
    "### Công thức:\n",
    "\n",
    "**Khi TRAIN** (stochastic — có noise để gradient chạy được):\n",
    "\n",
    "$$u \\sim \\text{Uniform}(0, 1)$$\n",
    "$$s = \\sigma\\left(\\frac{\\log u - \\log(1-u) + \\log\\alpha}{\\beta}\\right) \\quad \\text{(Binary Concrete)}$$\n",
    "$$\\bar{s} = s \\cdot (\\zeta - \\gamma) + \\gamma \\quad \\text{(Stretch ra ngoài [0,1])}$$\n",
    "$$z = \\min(1, \\max(0, \\bar{s})) \\quad \\text{(Hard clamp)}$$\n",
    "\n",
    "Trong đó:\n",
    "- $\\log\\alpha$ : **learnable parameter** (1 per band) — quyết định band on/off\n",
    "- $\\beta = 2/3$ : temperature (cố định)\n",
    "- $\\gamma = -0.1, \\zeta = 1.1$ : stretch interval → cho phép $\\bar{s}$ rơi ngoài $[0,1]$ → **clamp tạo exact 0/1**\n",
    "\n",
    "**Khi EVAL** (deterministic — không sample):\n",
    "\n",
    "$$z = \\min\\left(1, \\max\\left(0, \\sigma(\\log\\alpha) \\cdot (\\zeta - \\gamma) + \\gamma\\right)\\right)$$\n",
    "\n",
    "### L0 Regularization:\n",
    "\n",
    "$$\\mathcal{L}_{L0} = \\sum_{i=1}^{C} \\sigma\\left(\\log\\alpha_i - \\beta \\cdot \\log\\frac{-\\gamma}{\\zeta}\\right)$$\n",
    "\n",
    "Đây là **xác suất band $i$ được bật** ($P(z_i \\neq 0)$). Minimize L0 = ép nhiều band tắt.\n",
    "\n",
    "### Loss tổng:\n",
    "\n",
    "$$\\mathcal{L} = \\mathcal{L}_{CE} + \\lambda_{L0} \\cdot \\mathcal{L}_{L0}$$\n",
    "\n",
    "## 3. Tại sao tốt hơn Sigmoid Gate?\n",
    "\n",
    "| | Sigmoid Gate | Hard-Concrete |\n",
    "|---|---|---|\n",
    "| Gate values | Liên tục $(0, 1)$, khó = 0 | Có thể **chính xác = 0 hoặc 1** |\n",
    "| Sparsity | Ép bằng penalty gián tiếp | L0 penalty = đếm #bands bật |\n",
    "| Gradient | Vanishing ở 0 và 1 | Reparameterization trick → gradient ok |\n",
    "| Kết quả | Gate đều ~0.25, không phân biệt | Gate rõ ràng: 0 (tắt) vs 1 (bật) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c271f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import confusion_matrix, f1_score, classification_report, accuracy_score\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def get_preds_labels(model, loader, device):\n",
    "#     model.eval()\n",
    "#     all_preds, all_labels = [], []\n",
    "#     for x, y in loader:\n",
    "#         x = x.to(device)\n",
    "#         y = y.to(device)\n",
    "#         logits = model(x)\n",
    "#         preds = torch.argmax(logits, dim=1)\n",
    "#         all_preds.append(preds.detach().cpu().numpy())\n",
    "#         all_labels.append(y.detach().cpu().numpy())\n",
    "#     all_preds = np.concatenate(all_preds)\n",
    "#     all_labels = np.concatenate(all_labels)\n",
    "#     return all_preds, all_labels\n",
    "\n",
    "# # 1) Lấy dự đoán + nhãn thật\n",
    "# preds, labels = get_preds_labels(model, val_loader, device)\n",
    "\n",
    "# # 2) Accuracy + F1\n",
    "# acc = accuracy_score(labels, preds)\n",
    "# f1_macro = f1_score(labels, preds, average=\"macro\")\n",
    "# f1_weighted = f1_score(labels, preds, average=\"weighted\")\n",
    "\n",
    "# print(f\"Accuracy:     {acc:.4f}\")\n",
    "# print(f\"F1-macro:     {f1_macro:.4f}\")\n",
    "# print(f\"F1-weighted:  {f1_weighted:.4f}\")\n",
    "\n",
    "# # 3) Confusion matrix\n",
    "# cm = confusion_matrix(labels, preds)\n",
    "# print(\"\\nConfusion Matrix (rows=true, cols=pred):\\n\", cm)\n",
    "\n",
    "# # 4) Report theo từng lớp\n",
    "# # Nếu bạn có mapping idx_to_class thì in tên lớp cho đẹp\n",
    "# if hasattr(val_loader.dataset, \"idx_to_class\"):\n",
    "#     target_names = [val_loader.dataset.idx_to_class[i] for i in range(len(val_loader.dataset.idx_to_class))]\n",
    "#     print(\"\\nClassification Report:\\n\")\n",
    "#     print(classification_report(labels, preds, target_names=target_names, digits=4))\n",
    "# else:\n",
    "#     print(\"\\nClassification Report:\\n\")\n",
    "#     print(classification_report(labels, preds, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e814c1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_confusion_matrix(cm, class_names=None, title=\"Confusion Matrix\"):\n",
    "#     plt.figure(figsize=(6, 5))\n",
    "#     plt.imshow(cm, interpolation=\"nearest\")\n",
    "#     plt.title(title)\n",
    "#     plt.colorbar()\n",
    "#     tick_marks = np.arange(len(cm))\n",
    "#     if class_names is None:\n",
    "#         class_names = [str(i) for i in range(len(cm))]\n",
    "#     plt.xticks(tick_marks, class_names, rotation=45, ha=\"right\")\n",
    "#     plt.yticks(tick_marks, class_names)\n",
    "\n",
    "#     thresh = cm.max() / 2.0 if cm.max() > 0 else 0.5\n",
    "#     for i in range(cm.shape[0]):\n",
    "#         for j in range(cm.shape[1]):\n",
    "#             plt.text(j, i, format(cm[i, j], \"d\"),\n",
    "#                      ha=\"center\", va=\"center\",\n",
    "#                      color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "#     plt.ylabel(\"True label\")\n",
    "#     plt.xlabel(\"Predicted label\")\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# class_names = None\n",
    "# if hasattr(val_loader.dataset, \"idx_to_class\"):\n",
    "#     class_names = [val_loader.dataset.idx_to_class[i] for i in range(len(val_loader.dataset.idx_to_class))]\n",
    "\n",
    "# plot_confusion_matrix(cm, class_names=class_names, title=\"Val Confusion Matrix\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "new_cell_57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class HSTestDataset(Dataset):\n",
    "#     \"\"\"\n",
    "#     Test dataset — pipeline PHẢI khớp HSDataset (trừ augment & label):\n",
    "#     load → ensure_chw → fix_bands → resize → clip_per_band → z-score\n",
    "#     \"\"\"\n",
    "#     def __init__(self, img_dir, target_bands=125, target_hw=(64, 64), mean=None, std=None):\n",
    "#         self.img_dir = img_dir\n",
    "#         self.target_bands = target_bands\n",
    "#         self.target_hw = target_hw\n",
    "#         self.mean = (torch.tensor(mean).view(target_bands, 1, 1).float()\n",
    "#                      if mean is not None else torch.zeros(target_bands, 1, 1))\n",
    "#         self.std  = (torch.tensor(std).view(target_bands, 1, 1).float()\n",
    "#                      if std is not None else torch.ones(target_bands, 1, 1))\n",
    "#         self.files = sorted([f for f in os.listdir(img_dir)\n",
    "#                              if f.lower().endswith(('.tif', '.tiff'))])\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.files)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         fname = self.files[idx]\n",
    "#         path  = os.path.join(self.img_dir, fname)\n",
    "\n",
    "#         # 1. Load\n",
    "#         arr = tiff.imread(path).astype(np.float32)\n",
    "\n",
    "#         # 2. Ensure CHW  (cùng hàm với train)\n",
    "#         arr = ensure_chw(arr, self.target_bands)\n",
    "\n",
    "#         # 3. Fix bands  (pad spatial-mean, KHÔNG pad 0)\n",
    "#         arr = fix_bands(arr, self.target_bands)\n",
    "\n",
    "#         x = torch.from_numpy(arr)  # (C, H, W)\n",
    "\n",
    "#         # 4. Resize\n",
    "#         if x.shape[1:] != self.target_hw:\n",
    "#             x = F.interpolate(x.unsqueeze(0), size=self.target_hw,\n",
    "#                               mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "\n",
    "#         # 5. Clip per-band  (TRƯỚC ĐÂY BỊ THIẾU → khiến z-score sai)\n",
    "#         x = clip_per_band(x, 0.01, 0.99)\n",
    "\n",
    "#         # 6. Z-score normalize\n",
    "#         x = (x - self.mean) / (self.std + 1e-8)\n",
    "\n",
    "#         return x, fname\n",
    "\n",
    "\n",
    "# if os.path.exists(TEST_HS_DIR):\n",
    "#     # Load best checkpoint for test prediction\n",
    "#     model.load_state_dict(torch.load(CKPT_PATH, map_location=device, weights_only=True))\n",
    "#     model = model.to(device)\n",
    "#     model.eval()\n",
    "#     print(f\"Loaded checkpoint: {CKPT_PATH}\")\n",
    "#     print(f\"Model on device: {next(model.parameters()).device}\")\n",
    "\n",
    "#     test_ds = HSTestDataset(TEST_HS_DIR, TARGET_BANDS, TARGET_HW,\n",
    "#                             mean=mean_stats, std=std_stats)\n",
    "#     test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "#     preds = []\n",
    "#     ids = []\n",
    "#     class_names = [train_ds.idx_to_class[i] for i in range(num_classes)]\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for x, fname in tqdm(test_loader, desc=\"Predicting\"):\n",
    "#             x = x.to(device)\n",
    "#             out = model(x)\n",
    "#             p_idx = out.argmax(1).cpu().numpy()\n",
    "#             preds.extend([class_names[i] for i in p_idx])\n",
    "#             ids.extend(fname)\n",
    "\n",
    "#     import pandas as pd\n",
    "\n",
    "#     df = pd.DataFrame({\"Id\": ids, \"Category\": preds})\n",
    "\n",
    "#     df.to_csv(os.path.join(CHECKPOINT_DIR, \"submission_hs.csv\"), index=False)    \n",
    "#     print(\"Saved submission_hs.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ocr311)",
   "language": "python",
   "name": "ocr311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
